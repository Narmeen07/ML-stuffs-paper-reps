{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CustomMultiheadAttention(nn.MultiheadAttention):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(CustomMultiheadAttention, self).__init__(*args, **kwargs)\n",
        "        self.attention_weights = None\n",
        "\n",
        "    def forward(self, query, key, value, key_padding_mask=None, need_weights=True):\n",
        "        self.attention_weights = None  # Reset the attention weights before each forward pass\n",
        "        output, attention_weights = super(CustomMultiheadAttention, self).forward(\n",
        "            query, key, value, key_padding_mask=key_padding_mask, need_weights=need_weights\n",
        "        )\n",
        "        self.attention_weights = attention_weights\n",
        "        return output, attention_weights\n",
        "\n",
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_heads):\n",
        "        super(TransformerModel, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.custom_multihead_attention = CustomMultiheadAttention(embed_dim=hidden_size, num_heads=num_heads)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        src = self.embedding(src)\n",
        "        tgt = self.embedding(tgt)\n",
        "\n",
        "        # Assume self-attention for simplicity\n",
        "        output, attention_weights = self.custom_multihead_attention(tgt, tgt, tgt)\n",
        "\n",
        "        output = F.relu(output.mean(dim=1))  # Aggregate over sequence length\n",
        "        output = self.fc(output)\n",
        "        return output, attention_weights\n",
        "\n",
        "# Dummy dataset for illustration purposes\n",
        "def generate_dummy_data(num_samples, seq_length, vocab_size):\n",
        "    src = torch.randint(0, vocab_size, (num_samples, seq_length))\n",
        "    tgt = torch.randint(0, vocab_size, (num_samples, seq_length))\n",
        "    labels = torch.randint(0, 2, (num_samples,))\n",
        "    return src, tgt, labels\n",
        "\n",
        "# Set hyperparameters\n",
        "input_size = 100  # Vocabulary size\n",
        "hidden_size = 256\n",
        "num_heads = 4\n",
        "output_size = 2\n",
        "batch_size = 32\n",
        "learning_rate = 0.001\n",
        "num_epochs = 10\n",
        "\n",
        "# Create the model, loss function, and optimizer\n",
        "model = TransformerModel(input_size, hidden_size, num_heads)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Generate dummy data\n",
        "num_samples = 1000\n",
        "seq_length = 20\n",
        "vocab_size = input_size\n",
        "src, tgt, labels = generate_dummy_data(num_samples, seq_length, vocab_size)\n",
        "\n",
        "# Create DataLoader\n",
        "dataset = TensorDataset(src, tgt, labels)\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    for batch_src, batch_tgt, batch_labels in dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs, attention_weights = model(batch_src, batch_tgt)\n",
        "        loss = criterion(outputs, batch_labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Print or log the development of attention heads during training\n",
        "        print(\"Epoch {epoch + 1} Loss\", epoch)\n",
        "        print(loss.item())\n",
        "        print(\"one attention pattern developping during training\")\n",
        "        print(attention_weights[0])\n",
        "\n",
        "# After training, you can use the trained model for prediction on new data\n",
        "# and analyze attention heads as needed.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxHzUzI9gH5N",
        "outputId": "7d1ddf02-3773-4c71-ac97-7b9f4ecb0aad"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch {epoch + 1} Loss 0\n",
            "0.6909310817718506\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0437, 0.0215, 0.0197,  ..., 0.0377, 0.0504, 0.0384],\n",
            "        [0.0295, 0.0433, 0.0296,  ..., 0.0281, 0.0301, 0.0375],\n",
            "        [0.0338, 0.0215, 0.0280,  ..., 0.0326, 0.0216, 0.0337],\n",
            "        ...,\n",
            "        [0.0175, 0.0524, 0.0405,  ..., 0.0259, 0.0401, 0.0385],\n",
            "        [0.0327, 0.0349, 0.0289,  ..., 0.0227, 0.0386, 0.0402],\n",
            "        [0.0297, 0.0388, 0.0364,  ..., 0.0246, 0.0405, 0.0298]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 0\n",
            "0.6813976764678955\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0359, 0.0359, 0.0320,  ..., 0.0183, 0.0183, 0.0286],\n",
            "        [0.0322, 0.0281, 0.0254,  ..., 0.0392, 0.0392, 0.0348],\n",
            "        [0.0395, 0.0303, 0.0341,  ..., 0.0494, 0.0494, 0.0302],\n",
            "        ...,\n",
            "        [0.0375, 0.0412, 0.0288,  ..., 0.0202, 0.0202, 0.0224],\n",
            "        [0.0375, 0.0412, 0.0288,  ..., 0.0202, 0.0202, 0.0224],\n",
            "        [0.0210, 0.0283, 0.0329,  ..., 0.0390, 0.0390, 0.0291]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 0\n",
            "0.6761466860771179\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0274, 0.0285, 0.0353,  ..., 0.0341, 0.0285, 0.0299],\n",
            "        [0.0366, 0.0408, 0.0224,  ..., 0.0564, 0.0408, 0.0425],\n",
            "        [0.0326, 0.0307, 0.0364,  ..., 0.0346, 0.0307, 0.0330],\n",
            "        ...,\n",
            "        [0.0326, 0.0371, 0.0288,  ..., 0.0231, 0.0371, 0.0390],\n",
            "        [0.0366, 0.0408, 0.0224,  ..., 0.0564, 0.0408, 0.0425],\n",
            "        [0.0449, 0.0229, 0.0300,  ..., 0.0248, 0.0229, 0.0280]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 0\n",
            "0.6502550840377808\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0387, 0.0330, 0.0264,  ..., 0.0261, 0.0283, 0.0234],\n",
            "        [0.0389, 0.0277, 0.0367,  ..., 0.0188, 0.0363, 0.0466],\n",
            "        [0.0327, 0.0295, 0.0385,  ..., 0.0425, 0.0216, 0.0420],\n",
            "        ...,\n",
            "        [0.0138, 0.0435, 0.0222,  ..., 0.0471, 0.0307, 0.0291],\n",
            "        [0.0286, 0.0244, 0.0441,  ..., 0.0370, 0.0377, 0.0414],\n",
            "        [0.0392, 0.0264, 0.0227,  ..., 0.0301, 0.0297, 0.0296]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 0\n",
            "0.796006977558136\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0358, 0.0462, 0.0314,  ..., 0.0336, 0.0152, 0.0286],\n",
            "        [0.0304, 0.0210, 0.0184,  ..., 0.0212, 0.0353, 0.0350],\n",
            "        [0.0215, 0.0307, 0.0325,  ..., 0.0315, 0.0229, 0.0302],\n",
            "        ...,\n",
            "        [0.0237, 0.0254, 0.0446,  ..., 0.0281, 0.0476, 0.0358],\n",
            "        [0.0251, 0.0234, 0.0418,  ..., 0.0303, 0.0273, 0.0166],\n",
            "        [0.0308, 0.0256, 0.0347,  ..., 0.0374, 0.0254, 0.0556]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 0\n",
            "0.7959364056587219\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0257, 0.0317, 0.0204,  ..., 0.0364, 0.0271, 0.0259],\n",
            "        [0.0385, 0.0190, 0.0178,  ..., 0.0183, 0.0503, 0.0283],\n",
            "        [0.0299, 0.0206, 0.0205,  ..., 0.0272, 0.0556, 0.0349],\n",
            "        ...,\n",
            "        [0.0382, 0.0321, 0.0494,  ..., 0.0262, 0.0455, 0.0316],\n",
            "        [0.0257, 0.0220, 0.0531,  ..., 0.0385, 0.0276, 0.0374],\n",
            "        [0.0231, 0.0204, 0.0188,  ..., 0.0219, 0.0356, 0.0583]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 0\n",
            "0.773854672908783\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0323, 0.0319, 0.0268,  ..., 0.0222, 0.0523, 0.0320],\n",
            "        [0.0236, 0.0305, 0.0380,  ..., 0.0236, 0.0308, 0.0394],\n",
            "        [0.0370, 0.0303, 0.0382,  ..., 0.0241, 0.0346, 0.0465],\n",
            "        ...,\n",
            "        [0.0263, 0.0256, 0.0322,  ..., 0.0268, 0.0222, 0.0529],\n",
            "        [0.0228, 0.0400, 0.0445,  ..., 0.0235, 0.0570, 0.0287],\n",
            "        [0.0240, 0.0214, 0.0278,  ..., 0.0292, 0.0522, 0.0278]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 0\n",
            "0.7120224237442017\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0303, 0.0307, 0.0240,  ..., 0.0156, 0.0330, 0.0360],\n",
            "        [0.0189, 0.0301, 0.0277,  ..., 0.0304, 0.0208, 0.0324],\n",
            "        [0.0185, 0.0277, 0.0274,  ..., 0.0227, 0.0275, 0.0306],\n",
            "        ...,\n",
            "        [0.0268, 0.0228, 0.0295,  ..., 0.0323, 0.0209, 0.0440],\n",
            "        [0.0320, 0.0532, 0.0304,  ..., 0.0226, 0.0318, 0.0283],\n",
            "        [0.0259, 0.0356, 0.0387,  ..., 0.0292, 0.0222, 0.0199]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 0\n",
            "0.7165904641151428\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0255, 0.0447, 0.0212,  ..., 0.0364, 0.0253, 0.0347],\n",
            "        [0.0352, 0.0197, 0.0320,  ..., 0.0318, 0.0246, 0.0196],\n",
            "        [0.0406, 0.0457, 0.0336,  ..., 0.0271, 0.0348, 0.0227],\n",
            "        ...,\n",
            "        [0.0328, 0.0209, 0.0281,  ..., 0.0204, 0.0319, 0.0212],\n",
            "        [0.0329, 0.0211, 0.0339,  ..., 0.0346, 0.0307, 0.0262],\n",
            "        [0.0322, 0.0550, 0.0317,  ..., 0.0486, 0.0253, 0.0310]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 0\n",
            "0.6934608221054077\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0262, 0.0448, 0.0382,  ..., 0.0262, 0.0288, 0.0256],\n",
            "        [0.0246, 0.0260, 0.0354,  ..., 0.0246, 0.0330, 0.0610],\n",
            "        [0.0326, 0.0378, 0.0332,  ..., 0.0326, 0.0309, 0.0280],\n",
            "        ...,\n",
            "        [0.0262, 0.0448, 0.0382,  ..., 0.0262, 0.0288, 0.0256],\n",
            "        [0.0333, 0.0192, 0.0254,  ..., 0.0333, 0.0415, 0.0343],\n",
            "        [0.0207, 0.0254, 0.0243,  ..., 0.0207, 0.0268, 0.0239]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 0\n",
            "0.6949439644813538\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0239, 0.0344, 0.0319,  ..., 0.0346, 0.0329, 0.0166],\n",
            "        [0.0247, 0.0484, 0.0273,  ..., 0.0206, 0.0312, 0.0250],\n",
            "        [0.0270, 0.0221, 0.0216,  ..., 0.0251, 0.0212, 0.0187],\n",
            "        ...,\n",
            "        [0.0221, 0.0299, 0.0276,  ..., 0.0188, 0.0265, 0.0258],\n",
            "        [0.0207, 0.0390, 0.0482,  ..., 0.0340, 0.0261, 0.0221],\n",
            "        [0.0394, 0.0328, 0.0413,  ..., 0.0289, 0.0264, 0.0385]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 0\n",
            "0.7017236351966858\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0351, 0.0505, 0.0269,  ..., 0.0351, 0.0249, 0.0483],\n",
            "        [0.0361, 0.0428, 0.0240,  ..., 0.0361, 0.0323, 0.0315],\n",
            "        [0.0400, 0.0225, 0.0281,  ..., 0.0400, 0.0402, 0.0245],\n",
            "        ...,\n",
            "        [0.0351, 0.0505, 0.0269,  ..., 0.0351, 0.0249, 0.0483],\n",
            "        [0.0494, 0.0203, 0.0252,  ..., 0.0494, 0.0208, 0.0284],\n",
            "        [0.0248, 0.0312, 0.0245,  ..., 0.0248, 0.0358, 0.0409]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 0\n",
            "0.6860138177871704\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0305, 0.0228, 0.0262,  ..., 0.0262, 0.0280, 0.0458],\n",
            "        [0.0290, 0.0456, 0.0400,  ..., 0.0190, 0.0199, 0.0344],\n",
            "        [0.0317, 0.0368, 0.0330,  ..., 0.0236, 0.0310, 0.0212],\n",
            "        ...,\n",
            "        [0.0340, 0.0306, 0.0235,  ..., 0.0769, 0.0164, 0.0341],\n",
            "        [0.0431, 0.0263, 0.0304,  ..., 0.0374, 0.0212, 0.0329],\n",
            "        [0.0323, 0.0234, 0.0261,  ..., 0.0254, 0.0233, 0.0607]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 0\n",
            "0.6906123161315918\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0432, 0.0305, 0.0207,  ..., 0.0261, 0.0207, 0.0335],\n",
            "        [0.0361, 0.0328, 0.0287,  ..., 0.0402, 0.0284, 0.0318],\n",
            "        [0.0253, 0.0183, 0.0260,  ..., 0.0480, 0.0301, 0.0375],\n",
            "        ...,\n",
            "        [0.0458, 0.0201, 0.0405,  ..., 0.0196, 0.0245, 0.0373],\n",
            "        [0.0236, 0.0330, 0.0282,  ..., 0.0350, 0.0264, 0.0207],\n",
            "        [0.0320, 0.0331, 0.0417,  ..., 0.0393, 0.0264, 0.0206]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 0\n",
            "0.718776285648346\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0423, 0.0267, 0.0340,  ..., 0.0250, 0.0463, 0.0215],\n",
            "        [0.0366, 0.0363, 0.0355,  ..., 0.0289, 0.0346, 0.0302],\n",
            "        [0.0453, 0.0366, 0.0280,  ..., 0.0351, 0.0267, 0.0233],\n",
            "        ...,\n",
            "        [0.0531, 0.0437, 0.0213,  ..., 0.0332, 0.0239, 0.0403],\n",
            "        [0.0411, 0.0206, 0.0225,  ..., 0.0345, 0.0417, 0.0423],\n",
            "        [0.0222, 0.0309, 0.0274,  ..., 0.0370, 0.0376, 0.0210]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 0\n",
            "0.6887701153755188\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0223, 0.0307, 0.0341,  ..., 0.0372, 0.0443, 0.0297],\n",
            "        [0.0140, 0.0500, 0.0298,  ..., 0.0212, 0.0172, 0.0309],\n",
            "        [0.0348, 0.0198, 0.0238,  ..., 0.0328, 0.0357, 0.0195],\n",
            "        ...,\n",
            "        [0.0180, 0.0296, 0.0284,  ..., 0.0391, 0.0292, 0.0346],\n",
            "        [0.0238, 0.0238, 0.0248,  ..., 0.0313, 0.0284, 0.0192],\n",
            "        [0.0237, 0.0316, 0.0407,  ..., 0.0276, 0.0301, 0.0254]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 0\n",
            "0.7052241563796997\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0668, 0.0392, 0.0271,  ..., 0.0208, 0.0379, 0.0228],\n",
            "        [0.0286, 0.0323, 0.0326,  ..., 0.0286, 0.0209, 0.0275],\n",
            "        [0.0284, 0.0320, 0.0208,  ..., 0.0165, 0.0378, 0.0286],\n",
            "        ...,\n",
            "        [0.0294, 0.0280, 0.0253,  ..., 0.0417, 0.0412, 0.0501],\n",
            "        [0.0262, 0.0387, 0.0254,  ..., 0.0323, 0.0448, 0.0361],\n",
            "        [0.0474, 0.0271, 0.0415,  ..., 0.0350, 0.0355, 0.0366]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 0\n",
            "0.6892269849777222\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0369, 0.0440, 0.0258,  ..., 0.0252, 0.0252, 0.0213],\n",
            "        [0.0369, 0.0264, 0.0423,  ..., 0.0281, 0.0281, 0.0192],\n",
            "        [0.0305, 0.0308, 0.0295,  ..., 0.0177, 0.0177, 0.0297],\n",
            "        ...,\n",
            "        [0.0368, 0.0354, 0.0250,  ..., 0.0479, 0.0479, 0.0284],\n",
            "        [0.0368, 0.0354, 0.0250,  ..., 0.0479, 0.0479, 0.0284],\n",
            "        [0.0211, 0.0241, 0.0577,  ..., 0.0284, 0.0284, 0.0197]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 0\n",
            "0.6921306252479553\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0593, 0.0306, 0.0246,  ..., 0.0401, 0.0212, 0.0425],\n",
            "        [0.0342, 0.0230, 0.0231,  ..., 0.0296, 0.0290, 0.0230],\n",
            "        [0.0337, 0.0283, 0.0410,  ..., 0.0308, 0.0360, 0.0245],\n",
            "        ...,\n",
            "        [0.0331, 0.0442, 0.0251,  ..., 0.0400, 0.0223, 0.0737],\n",
            "        [0.0205, 0.0297, 0.0156,  ..., 0.0316, 0.0350, 0.0144],\n",
            "        [0.0288, 0.0457, 0.0441,  ..., 0.0284, 0.0377, 0.0184]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 0\n",
            "0.6928268074989319\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0452, 0.0377, 0.0247,  ..., 0.0528, 0.0273, 0.0452],\n",
            "        [0.0223, 0.0543, 0.0291,  ..., 0.0289, 0.0189, 0.0223],\n",
            "        [0.0377, 0.0238, 0.0278,  ..., 0.0406, 0.0301, 0.0377],\n",
            "        ...,\n",
            "        [0.0490, 0.0280, 0.0288,  ..., 0.0205, 0.0250, 0.0490],\n",
            "        [0.0480, 0.0500, 0.0298,  ..., 0.0178, 0.0365, 0.0480],\n",
            "        [0.0452, 0.0377, 0.0247,  ..., 0.0528, 0.0273, 0.0452]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 0\n",
            "0.6902662515640259\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0344, 0.0308, 0.0328,  ..., 0.0328, 0.0288, 0.0220],\n",
            "        [0.0283, 0.0368, 0.0528,  ..., 0.0528, 0.0304, 0.0260],\n",
            "        [0.0278, 0.0145, 0.0595,  ..., 0.0595, 0.0303, 0.0258],\n",
            "        ...,\n",
            "        [0.0278, 0.0145, 0.0595,  ..., 0.0595, 0.0303, 0.0258],\n",
            "        [0.0230, 0.0204, 0.0438,  ..., 0.0438, 0.0218, 0.0294],\n",
            "        [0.0163, 0.0253, 0.0457,  ..., 0.0457, 0.0444, 0.0185]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 0\n",
            "0.6944749355316162\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0857, 0.0424, 0.0253,  ..., 0.0324, 0.0254, 0.0256],\n",
            "        [0.0287, 0.0289, 0.0419,  ..., 0.0400, 0.0227, 0.0308],\n",
            "        [0.0235, 0.0790, 0.0334,  ..., 0.0173, 0.0430, 0.0310],\n",
            "        ...,\n",
            "        [0.0365, 0.0474, 0.0253,  ..., 0.0746, 0.0374, 0.0411],\n",
            "        [0.0271, 0.0216, 0.0220,  ..., 0.0269, 0.0295, 0.0330],\n",
            "        [0.0235, 0.0306, 0.0212,  ..., 0.0316, 0.0285, 0.0518]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 0\n",
            "0.6893984079360962\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0301, 0.0451, 0.0333,  ..., 0.0301, 0.0326, 0.0324],\n",
            "        [0.0223, 0.0443, 0.0251,  ..., 0.0409, 0.0201, 0.0222],\n",
            "        [0.0560, 0.0227, 0.0904,  ..., 0.0336, 0.0395, 0.0344],\n",
            "        ...,\n",
            "        [0.0204, 0.0307, 0.0323,  ..., 0.0574, 0.0189, 0.0201],\n",
            "        [0.0302, 0.0314, 0.0276,  ..., 0.0319, 0.0293, 0.0416],\n",
            "        [0.0192, 0.0317, 0.0211,  ..., 0.0318, 0.0339, 0.0217]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 0\n",
            "0.6953341960906982\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0762, 0.0269, 0.0381,  ..., 0.0276, 0.0276, 0.0352],\n",
            "        [0.0300, 0.0413, 0.0267,  ..., 0.0385, 0.0385, 0.0115],\n",
            "        [0.0290, 0.0866, 0.0245,  ..., 0.0272, 0.0272, 0.0276],\n",
            "        ...,\n",
            "        [0.0540, 0.0535, 0.0447,  ..., 0.0317, 0.0317, 0.0220],\n",
            "        [0.0540, 0.0535, 0.0447,  ..., 0.0317, 0.0317, 0.0220],\n",
            "        [0.0322, 0.0241, 0.0338,  ..., 0.0187, 0.0187, 0.0628]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 0\n",
            "0.6919185519218445\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0272, 0.0190, 0.0329,  ..., 0.0514, 0.0237, 0.0276],\n",
            "        [0.0275, 0.0580, 0.0236,  ..., 0.0258, 0.0370, 0.0317],\n",
            "        [0.0305, 0.0223, 0.0324,  ..., 0.0170, 0.0231, 0.0324],\n",
            "        ...,\n",
            "        [0.0276, 0.0279, 0.0196,  ..., 0.0398, 0.0245, 0.0285],\n",
            "        [0.0263, 0.0333, 0.0233,  ..., 0.0208, 0.0294, 0.0356],\n",
            "        [0.0213, 0.0280, 0.0279,  ..., 0.0385, 0.0376, 0.0252]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 0\n",
            "0.6990209221839905\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0256, 0.0206, 0.0201,  ..., 0.0262, 0.0319, 0.0470],\n",
            "        [0.0275, 0.0509, 0.0213,  ..., 0.0396, 0.0326, 0.0339],\n",
            "        [0.0325, 0.0339, 0.0220,  ..., 0.0215, 0.0370, 0.0371],\n",
            "        ...,\n",
            "        [0.0495, 0.0151, 0.0616,  ..., 0.0445, 0.0281, 0.0283],\n",
            "        [0.0280, 0.0238, 0.0304,  ..., 0.0264, 0.0413, 0.0367],\n",
            "        [0.0188, 0.0218, 0.0304,  ..., 0.0262, 0.0274, 0.0220]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 0\n",
            "0.6920744776725769\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0336, 0.0243, 0.0246,  ..., 0.0413, 0.0245, 0.0289],\n",
            "        [0.0296, 0.0356, 0.0440,  ..., 0.0325, 0.0222, 0.0246],\n",
            "        [0.0392, 0.0289, 0.0220,  ..., 0.0291, 0.0263, 0.0255],\n",
            "        ...,\n",
            "        [0.0289, 0.0242, 0.0381,  ..., 0.0325, 0.0275, 0.0261],\n",
            "        [0.0262, 0.0167, 0.0345,  ..., 0.0278, 0.0188, 0.0318],\n",
            "        [0.0261, 0.0300, 0.0219,  ..., 0.0404, 0.0322, 0.0193]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 0\n",
            "0.6944752931594849\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0236, 0.0352, 0.0287,  ..., 0.0542, 0.0394, 0.0236],\n",
            "        [0.0220, 0.0413, 0.0716,  ..., 0.0257, 0.0401, 0.0217],\n",
            "        [0.0402, 0.0158, 0.0870,  ..., 0.0161, 0.0149, 0.0215],\n",
            "        ...,\n",
            "        [0.0259, 0.0235, 0.0575,  ..., 0.0608, 0.0180, 0.0248],\n",
            "        [0.0318, 0.0267, 0.0297,  ..., 0.0329, 0.0268, 0.0303],\n",
            "        [0.0284, 0.0639, 0.0320,  ..., 0.0478, 0.0384, 0.0168]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 0\n",
            "0.6918237209320068\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0466, 0.0434, 0.0353,  ..., 0.0188, 0.0292, 0.0235],\n",
            "        [0.0136, 0.0172, 0.0200,  ..., 0.0202, 0.0735, 0.0146],\n",
            "        [0.0255, 0.0304, 0.0229,  ..., 0.0343, 0.0338, 0.0300],\n",
            "        ...,\n",
            "        [0.0175, 0.0336, 0.0266,  ..., 0.0330, 0.0293, 0.0204],\n",
            "        [0.0368, 0.0452, 0.0284,  ..., 0.0279, 0.0321, 0.0219],\n",
            "        [0.0325, 0.0299, 0.0385,  ..., 0.0342, 0.0285, 0.0164]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 0\n",
            "0.693306565284729\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0212, 0.0286, 0.0426,  ..., 0.0353, 0.0426, 0.0358],\n",
            "        [0.0290, 0.0375, 0.0342,  ..., 0.0428, 0.0342, 0.0345],\n",
            "        [0.0226, 0.0375, 0.0174,  ..., 0.0240, 0.0174, 0.0253],\n",
            "        ...,\n",
            "        [0.0236, 0.0334, 0.0294,  ..., 0.0397, 0.0294, 0.0370],\n",
            "        [0.0226, 0.0375, 0.0174,  ..., 0.0240, 0.0174, 0.0253],\n",
            "        [0.0341, 0.0348, 0.0287,  ..., 0.0161, 0.0287, 0.0464]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 0\n",
            "0.6914098262786865\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0512, 0.0348, 0.0343,  ..., 0.0287, 0.0254, 0.0286],\n",
            "        [0.0418, 0.0799, 0.0373,  ..., 0.0246, 0.0253, 0.0242],\n",
            "        [0.0406, 0.0240, 0.0503,  ..., 0.0427, 0.0223, 0.0211],\n",
            "        ...,\n",
            "        [0.0307, 0.0264, 0.0369,  ..., 0.0578, 0.0280, 0.0313],\n",
            "        [0.0315, 0.0302, 0.0327,  ..., 0.0312, 0.0462, 0.0253],\n",
            "        [0.0275, 0.0468, 0.0158,  ..., 0.0279, 0.0540, 0.0166]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 0\n",
            "0.6794413924217224\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0882, 0.1325, 0.1254, 0.0785, 0.1692, 0.0826, 0.1692, 0.1544],\n",
            "        [0.1273, 0.1202, 0.1955, 0.1315, 0.0924, 0.1207, 0.0924, 0.1201],\n",
            "        [0.1752, 0.1235, 0.1209, 0.0990, 0.0983, 0.1526, 0.0983, 0.1325],\n",
            "        [0.1310, 0.1694, 0.1389, 0.0883, 0.0972, 0.0834, 0.0972, 0.1946],\n",
            "        [0.1439, 0.1612, 0.1201, 0.0763, 0.1242, 0.1171, 0.1242, 0.1329],\n",
            "        [0.1335, 0.1506, 0.1130, 0.1210, 0.1316, 0.1228, 0.1316, 0.0958],\n",
            "        [0.1439, 0.1612, 0.1201, 0.0763, 0.1242, 0.1171, 0.1242, 0.1329],\n",
            "        [0.0883, 0.1591, 0.1417, 0.1087, 0.1632, 0.0884, 0.1632, 0.0873]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 1\n",
            "0.6950004696846008\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0176, 0.0286, 0.0386,  ..., 0.0222, 0.0227, 0.0191],\n",
            "        [0.0207, 0.0190, 0.0225,  ..., 0.0249, 0.0267, 0.0753],\n",
            "        [0.0243, 0.0301, 0.0203,  ..., 0.0553, 0.0206, 0.0348],\n",
            "        ...,\n",
            "        [0.0212, 0.0322, 0.0267,  ..., 0.0290, 0.0625, 0.0219],\n",
            "        [0.0139, 0.0338, 0.0201,  ..., 0.0329, 0.0407, 0.0405],\n",
            "        [0.0213, 0.0383, 0.0429,  ..., 0.0307, 0.0275, 0.0298]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 1\n",
            "0.6811354756355286\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0218, 0.0291, 0.0407,  ..., 0.0175, 0.0245, 0.0218],\n",
            "        [0.0409, 0.0465, 0.0427,  ..., 0.0238, 0.0164, 0.0409],\n",
            "        [0.0268, 0.0282, 0.0693,  ..., 0.0191, 0.0277, 0.0268],\n",
            "        ...,\n",
            "        [0.0491, 0.0246, 0.0739,  ..., 0.0240, 0.0350, 0.0491],\n",
            "        [0.0327, 0.0102, 0.0338,  ..., 0.0463, 0.0360, 0.0327],\n",
            "        [0.0218, 0.0291, 0.0407,  ..., 0.0175, 0.0245, 0.0218]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 1\n",
            "0.7436099052429199\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0451, 0.0479, 0.0299,  ..., 0.0333, 0.0191, 0.0197],\n",
            "        [0.0374, 0.0294, 0.0353,  ..., 0.0292, 0.0890, 0.0511],\n",
            "        [0.0221, 0.0358, 0.0312,  ..., 0.0396, 0.0214, 0.0365],\n",
            "        ...,\n",
            "        [0.0318, 0.0295, 0.0269,  ..., 0.0438, 0.0277, 0.0204],\n",
            "        [0.0254, 0.0296, 0.0308,  ..., 0.0186, 0.0672, 0.0346],\n",
            "        [0.0570, 0.0256, 0.0390,  ..., 0.0281, 0.0257, 0.0229]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 1\n",
            "0.6953156590461731\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0348, 0.0439, 0.0453,  ..., 0.0239, 0.0403, 0.0238],\n",
            "        [0.0393, 0.0299, 0.0326,  ..., 0.0207, 0.0300, 0.0351],\n",
            "        [0.0140, 0.0223, 0.0196,  ..., 0.0259, 0.0361, 0.0218],\n",
            "        ...,\n",
            "        [0.0204, 0.0320, 0.0252,  ..., 0.0237, 0.0316, 0.0294],\n",
            "        [0.0264, 0.0169, 0.0150,  ..., 0.0311, 0.1114, 0.0378],\n",
            "        [0.0231, 0.0218, 0.0322,  ..., 0.0180, 0.0281, 0.0361]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 1\n",
            "0.6982247829437256\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0300, 0.0253, 0.0205,  ..., 0.0315, 0.0231, 0.0231],\n",
            "        [0.0206, 0.0210, 0.0205,  ..., 0.0241, 0.0288, 0.0288],\n",
            "        [0.0304, 0.0356, 0.0379,  ..., 0.0462, 0.0294, 0.0294],\n",
            "        ...,\n",
            "        [0.0370, 0.0417, 0.0389,  ..., 0.0288, 0.0363, 0.0363],\n",
            "        [0.0679, 0.0465, 0.0220,  ..., 0.0361, 0.0220, 0.0220],\n",
            "        [0.0679, 0.0465, 0.0220,  ..., 0.0361, 0.0220, 0.0220]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 1\n",
            "0.6946684122085571\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0229, 0.0300, 0.0343,  ..., 0.0484, 0.0386, 0.0343],\n",
            "        [0.0395, 0.0310, 0.0336,  ..., 0.0246, 0.0369, 0.0336],\n",
            "        [0.0319, 0.0224, 0.0316,  ..., 0.0206, 0.0390, 0.0316],\n",
            "        ...,\n",
            "        [0.0367, 0.0316, 0.0191,  ..., 0.0199, 0.0332, 0.0191],\n",
            "        [0.0408, 0.0277, 0.0396,  ..., 0.0207, 0.0451, 0.0396],\n",
            "        [0.0319, 0.0224, 0.0316,  ..., 0.0206, 0.0390, 0.0316]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 1\n",
            "0.6993964910507202\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0207, 0.0288, 0.0746,  ..., 0.0195, 0.0283, 0.0197],\n",
            "        [0.0194, 0.0174, 0.0219,  ..., 0.0324, 0.0250, 0.0254],\n",
            "        [0.0250, 0.0157, 0.0256,  ..., 0.0253, 0.0228, 0.0307],\n",
            "        ...,\n",
            "        [0.0185, 0.0190, 0.0277,  ..., 0.0380, 0.0361, 0.0407],\n",
            "        [0.0346, 0.0321, 0.0248,  ..., 0.0185, 0.0385, 0.0299],\n",
            "        [0.0209, 0.0216, 0.0777,  ..., 0.0305, 0.0255, 0.0748]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 1\n",
            "0.6883692145347595\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0218, 0.0270, 0.0235,  ..., 0.0282, 0.0290, 0.0402],\n",
            "        [0.0337, 0.0341, 0.0287,  ..., 0.0189, 0.0376, 0.0417],\n",
            "        [0.0241, 0.0363, 0.0235,  ..., 0.0254, 0.0178, 0.0355],\n",
            "        ...,\n",
            "        [0.0426, 0.0354, 0.0293,  ..., 0.0290, 0.0208, 0.0346],\n",
            "        [0.0347, 0.0252, 0.0348,  ..., 0.0339, 0.0305, 0.0303],\n",
            "        [0.0544, 0.0356, 0.0270,  ..., 0.0354, 0.0371, 0.0222]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 1\n",
            "0.71332186460495\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0230, 0.0230, 0.0247,  ..., 0.0244, 0.0317, 0.0177],\n",
            "        [0.0230, 0.0230, 0.0247,  ..., 0.0244, 0.0317, 0.0177],\n",
            "        [0.0346, 0.0346, 0.0268,  ..., 0.0286, 0.0221, 0.0392],\n",
            "        ...,\n",
            "        [0.0343, 0.0343, 0.0205,  ..., 0.0431, 0.0418, 0.0471],\n",
            "        [0.0442, 0.0442, 0.0237,  ..., 0.0181, 0.0492, 0.0270],\n",
            "        [0.0215, 0.0215, 0.0235,  ..., 0.0471, 0.0201, 0.1108]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 1\n",
            "0.690269410610199\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0139, 0.0210, 0.0259,  ..., 0.0259, 0.0236, 0.0312],\n",
            "        [0.0383, 0.0622, 0.0217,  ..., 0.0217, 0.0230, 0.0492],\n",
            "        [0.0230, 0.0136, 0.0567,  ..., 0.0567, 0.0418, 0.0277],\n",
            "        ...,\n",
            "        [0.0230, 0.0136, 0.0567,  ..., 0.0567, 0.0418, 0.0277],\n",
            "        [0.0178, 0.0308, 0.0314,  ..., 0.0314, 0.0109, 0.0264],\n",
            "        [0.0286, 0.0111, 0.0177,  ..., 0.0177, 0.0222, 0.0449]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 1\n",
            "0.6895580291748047\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0198, 0.0156, 0.0423,  ..., 0.0299, 0.0286, 0.0249],\n",
            "        [0.0205, 0.0199, 0.0291,  ..., 0.0316, 0.0370, 0.0192],\n",
            "        [0.0401, 0.0183, 0.0345,  ..., 0.0252, 0.0338, 0.0317],\n",
            "        ...,\n",
            "        [0.0178, 0.0384, 0.0164,  ..., 0.0279, 0.0307, 0.0200],\n",
            "        [0.0131, 0.0255, 0.0247,  ..., 0.0264, 0.0525, 0.0294],\n",
            "        [0.0379, 0.0241, 0.0468,  ..., 0.0278, 0.0393, 0.0206]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 1\n",
            "0.6935814619064331\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0236, 0.0383, 0.0255,  ..., 0.0360, 0.0518, 0.0395],\n",
            "        [0.0195, 0.1491, 0.0156,  ..., 0.0348, 0.0244, 0.0236],\n",
            "        [0.0395, 0.0268, 0.0223,  ..., 0.0162, 0.0350, 0.0418],\n",
            "        ...,\n",
            "        [0.0243, 0.0313, 0.0158,  ..., 0.0786, 0.0249, 0.0447],\n",
            "        [0.0281, 0.0349, 0.0200,  ..., 0.0387, 0.0394, 0.0280],\n",
            "        [0.0419, 0.0238, 0.0285,  ..., 0.0204, 0.0358, 0.0618]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 1\n",
            "0.688470721244812\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0193, 0.0262, 0.0276,  ..., 0.0323, 0.0196, 0.0349],\n",
            "        [0.0240, 0.0308, 0.0396,  ..., 0.0255, 0.0255, 0.0375],\n",
            "        [0.0288, 0.0414, 0.0294,  ..., 0.0302, 0.0382, 0.0430],\n",
            "        ...,\n",
            "        [0.0402, 0.0233, 0.0286,  ..., 0.0261, 0.0306, 0.0278],\n",
            "        [0.0285, 0.0196, 0.0326,  ..., 0.0302, 0.0309, 0.0356],\n",
            "        [0.0239, 0.0338, 0.0352,  ..., 0.0236, 0.0784, 0.0450]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 1\n",
            "0.703908383846283\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0392, 0.0338, 0.0406,  ..., 0.0421, 0.0492, 0.0501],\n",
            "        [0.0279, 0.0740, 0.0223,  ..., 0.0269, 0.0348, 0.0255],\n",
            "        [0.0336, 0.0419, 0.0260,  ..., 0.0360, 0.0296, 0.0245],\n",
            "        ...,\n",
            "        [0.0303, 0.0433, 0.0328,  ..., 0.0244, 0.0395, 0.0302],\n",
            "        [0.0267, 0.0201, 0.0284,  ..., 0.0279, 0.0162, 0.0224],\n",
            "        [0.0723, 0.0283, 0.0387,  ..., 0.0226, 0.0249, 0.0094]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 1\n",
            "0.6865347027778625\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0289, 0.0269, 0.0268,  ..., 0.0286, 0.0409, 0.0457],\n",
            "        [0.0232, 0.0659, 0.0417,  ..., 0.0226, 0.0297, 0.0296],\n",
            "        [0.0369, 0.0379, 0.1118,  ..., 0.0231, 0.0240, 0.0334],\n",
            "        ...,\n",
            "        [0.0218, 0.0461, 0.0195,  ..., 0.0384, 0.0274, 0.0328],\n",
            "        [0.0304, 0.0553, 0.0331,  ..., 0.0325, 0.0559, 0.0370],\n",
            "        [0.0219, 0.0249, 0.0367,  ..., 0.0181, 0.0475, 0.0300]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 1\n",
            "0.6984561681747437\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0182, 0.1630, 0.0608,  ..., 0.0180, 0.0354, 0.0229],\n",
            "        [0.0195, 0.0108, 0.0293,  ..., 0.0235, 0.0591, 0.0273],\n",
            "        [0.0294, 0.0227, 0.0364,  ..., 0.0295, 0.0237, 0.0167],\n",
            "        ...,\n",
            "        [0.0218, 0.0374, 0.0253,  ..., 0.0348, 0.0263, 0.0266],\n",
            "        [0.0154, 0.0479, 0.0342,  ..., 0.0314, 0.0214, 0.0229],\n",
            "        [0.0425, 0.0265, 0.0341,  ..., 0.0226, 0.0148, 0.0188]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 1\n",
            "0.7069417238235474\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0269, 0.0251, 0.0344,  ..., 0.0134, 0.0177, 0.0623],\n",
            "        [0.0419, 0.0205, 0.0138,  ..., 0.0634, 0.0312, 0.0281],\n",
            "        [0.0346, 0.0609, 0.0274,  ..., 0.0278, 0.0214, 0.0247],\n",
            "        ...,\n",
            "        [0.0282, 0.0371, 0.0419,  ..., 0.0176, 0.0392, 0.0391],\n",
            "        [0.0216, 0.0407, 0.0315,  ..., 0.0276, 0.0109, 0.0147],\n",
            "        [0.0324, 0.0522, 0.0203,  ..., 0.0284, 0.0193, 0.0179]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 1\n",
            "0.7033466696739197\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0276, 0.0287, 0.0291,  ..., 0.0251, 0.0262, 0.0387],\n",
            "        [0.0427, 0.0176, 0.0657,  ..., 0.0259, 0.0262, 0.0231],\n",
            "        [0.0376, 0.0221, 0.0237,  ..., 0.0158, 0.0306, 0.0332],\n",
            "        ...,\n",
            "        [0.0243, 0.0329, 0.0258,  ..., 0.0247, 0.0270, 0.0377],\n",
            "        [0.0194, 0.0210, 0.0303,  ..., 0.0235, 0.0448, 0.0400],\n",
            "        [0.0191, 0.0408, 0.0214,  ..., 0.0294, 0.0172, 0.0190]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 1\n",
            "0.6995275616645813\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0223, 0.0285, 0.0283,  ..., 0.0498, 0.0312, 0.0280],\n",
            "        [0.0290, 0.0321, 0.0325,  ..., 0.0353, 0.0443, 0.0314],\n",
            "        [0.0299, 0.0184, 0.0689,  ..., 0.0201, 0.0470, 0.0343],\n",
            "        ...,\n",
            "        [0.0347, 0.0195, 0.0437,  ..., 0.0510, 0.0342, 0.0291],\n",
            "        [0.0354, 0.0300, 0.0358,  ..., 0.0239, 0.0650, 0.0450],\n",
            "        [0.0263, 0.0274, 0.0411,  ..., 0.0176, 0.0410, 0.2222]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 1\n",
            "0.7052231431007385\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0198, 0.0186, 0.0270,  ..., 0.0166, 0.0258, 0.0356],\n",
            "        [0.0081, 0.1344, 0.0319,  ..., 0.1231, 0.0550, 0.0537],\n",
            "        [0.0203, 0.0148, 0.0343,  ..., 0.0141, 0.0500, 0.0164],\n",
            "        ...,\n",
            "        [0.0296, 0.0158, 0.0244,  ..., 0.0135, 0.0307, 0.0295],\n",
            "        [0.0310, 0.0196, 0.0389,  ..., 0.0300, 0.0611, 0.0175],\n",
            "        [0.0292, 0.0160, 0.0331,  ..., 0.0399, 0.0197, 0.0283]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 1\n",
            "0.6916800737380981\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0216, 0.0334, 0.0277,  ..., 0.0322, 0.0372, 0.0430],\n",
            "        [0.0480, 0.0159, 0.0253,  ..., 0.0280, 0.0356, 0.0400],\n",
            "        [0.0539, 0.0284, 0.0265,  ..., 0.0329, 0.0311, 0.0473],\n",
            "        ...,\n",
            "        [0.0517, 0.0191, 0.0359,  ..., 0.0257, 0.0319, 0.0270],\n",
            "        [0.0435, 0.0344, 0.0370,  ..., 0.0409, 0.0326, 0.0321],\n",
            "        [0.0196, 0.0414, 0.0271,  ..., 0.0226, 0.0210, 0.0204]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 1\n",
            "0.6993255615234375\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0619, 0.0335, 0.0309,  ..., 0.0213, 0.0237, 0.1322],\n",
            "        [0.0285, 0.0254, 0.0338,  ..., 0.0227, 0.0291, 0.0233],\n",
            "        [0.0415, 0.0229, 0.0296,  ..., 0.0228, 0.1058, 0.0767],\n",
            "        ...,\n",
            "        [0.0466, 0.0120, 0.0295,  ..., 0.0157, 0.0402, 0.0166],\n",
            "        [0.0751, 0.0166, 0.0317,  ..., 0.0225, 0.0432, 0.0132],\n",
            "        [0.0247, 0.0248, 0.0284,  ..., 0.0245, 0.0123, 0.0177]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 1\n",
            "0.693130612373352\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0602, 0.0190, 0.0602,  ..., 0.0166, 0.0150, 0.0160],\n",
            "        [0.0480, 0.0263, 0.0480,  ..., 0.0247, 0.0282, 0.0242],\n",
            "        [0.0602, 0.0190, 0.0602,  ..., 0.0166, 0.0150, 0.0160],\n",
            "        ...,\n",
            "        [0.0194, 0.0284, 0.0194,  ..., 0.0209, 0.0204, 0.0326],\n",
            "        [0.0204, 0.0189, 0.0204,  ..., 0.0128, 0.0125, 0.0117],\n",
            "        [0.0267, 0.0195, 0.0267,  ..., 0.0109, 0.0467, 0.1266]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 1\n",
            "0.6949242353439331\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0256, 0.0219, 0.0267,  ..., 0.0235, 0.0413, 0.0236],\n",
            "        [0.0232, 0.0255, 0.0235,  ..., 0.0224, 0.1020, 0.0345],\n",
            "        [0.0265, 0.0425, 0.0214,  ..., 0.0278, 0.0291, 0.0427],\n",
            "        ...,\n",
            "        [0.0268, 0.0322, 0.0210,  ..., 0.1730, 0.0221, 0.0481],\n",
            "        [0.0301, 0.0187, 0.0395,  ..., 0.0236, 0.0174, 0.0376],\n",
            "        [0.0259, 0.0256, 0.0472,  ..., 0.0160, 0.0299, 0.0315]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 1\n",
            "0.689446210861206\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0382, 0.0201, 0.0427,  ..., 0.0173, 0.0291, 0.0499],\n",
            "        [0.0217, 0.0390, 0.0263,  ..., 0.0321, 0.0281, 0.0382],\n",
            "        [0.0263, 0.0770, 0.0244,  ..., 0.0574, 0.0182, 0.0253],\n",
            "        ...,\n",
            "        [0.0294, 0.0320, 0.0184,  ..., 0.0548, 0.0292, 0.0396],\n",
            "        [0.0158, 0.0387, 0.0164,  ..., 0.0409, 0.0231, 0.0111],\n",
            "        [0.0287, 0.0233, 0.0550,  ..., 0.0236, 0.0264, 0.0233]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 1\n",
            "0.6971664428710938\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0300, 0.0445, 0.0224,  ..., 0.0251, 0.0213, 0.0415],\n",
            "        [0.0382, 0.0170, 0.0174,  ..., 0.0371, 0.0263, 0.0375],\n",
            "        [0.0428, 0.0314, 0.0229,  ..., 0.0271, 0.0384, 0.0372],\n",
            "        ...,\n",
            "        [0.0371, 0.0223, 0.0301,  ..., 0.0183, 0.0308, 0.0187],\n",
            "        [0.0399, 0.0323, 0.0572,  ..., 0.0263, 0.0181, 0.0228],\n",
            "        [0.0306, 0.0292, 0.0261,  ..., 0.0245, 0.0256, 0.0277]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 1\n",
            "0.6883826851844788\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0167, 0.0289, 0.0213,  ..., 0.0588, 0.0218, 0.0373],\n",
            "        [0.0159, 0.0304, 0.0363,  ..., 0.0273, 0.0279, 0.0528],\n",
            "        [0.0131, 0.0347, 0.0128,  ..., 0.0174, 0.0153, 0.1238],\n",
            "        ...,\n",
            "        [0.0207, 0.0294, 0.0471,  ..., 0.0309, 0.0187, 0.0439],\n",
            "        [0.0363, 0.0361, 0.0450,  ..., 0.0268, 0.0176, 0.0380],\n",
            "        [0.0200, 0.0423, 0.0118,  ..., 0.0254, 0.0228, 0.0627]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 1\n",
            "0.7001703977584839\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0317, 0.0192, 0.0554,  ..., 0.0300, 0.0186, 0.0302],\n",
            "        [0.0243, 0.0363, 0.0230,  ..., 0.0243, 0.0310, 0.0261],\n",
            "        [0.0194, 0.0182, 0.0280,  ..., 0.0257, 0.0162, 0.0256],\n",
            "        ...,\n",
            "        [0.0135, 0.0217, 0.0353,  ..., 0.0262, 0.0341, 0.0434],\n",
            "        [0.0230, 0.0207, 0.0279,  ..., 0.0289, 0.0274, 0.0257],\n",
            "        [0.0265, 0.0316, 0.0258,  ..., 0.0254, 0.0312, 0.0275]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 1\n",
            "0.6867184042930603\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0255, 0.0330, 0.0452,  ..., 0.0414, 0.0341, 0.0268],\n",
            "        [0.0371, 0.0468, 0.0293,  ..., 0.0447, 0.0168, 0.0224],\n",
            "        [0.0330, 0.0205, 0.0901,  ..., 0.0104, 0.0379, 0.0153],\n",
            "        ...,\n",
            "        [0.0351, 0.0181, 0.0138,  ..., 0.0207, 0.0386, 0.0295],\n",
            "        [0.0405, 0.0678, 0.0365,  ..., 0.0163, 0.0157, 0.0244],\n",
            "        [0.0312, 0.0190, 0.0190,  ..., 0.0348, 0.0153, 0.1521]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 1\n",
            "0.6821721792221069\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0202, 0.0258, 0.0257,  ..., 0.0368, 0.0351, 0.0604],\n",
            "        [0.0731, 0.0181, 0.0170,  ..., 0.0298, 0.0217, 0.0193],\n",
            "        [0.0364, 0.0313, 0.0407,  ..., 0.0360, 0.0247, 0.0292],\n",
            "        ...,\n",
            "        [0.0571, 0.0341, 0.0232,  ..., 0.0283, 0.0157, 0.0182],\n",
            "        [0.0431, 0.0225, 0.0238,  ..., 0.0472, 0.0265, 0.0411],\n",
            "        [0.0217, 0.0262, 0.0258,  ..., 0.0191, 0.0291, 0.0874]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 1\n",
            "0.6907110214233398\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0389, 0.0177, 0.0268,  ..., 0.0386, 0.0263, 0.0231],\n",
            "        [0.0306, 0.0202, 0.0212,  ..., 0.0215, 0.0210, 0.0181],\n",
            "        [0.0524, 0.0177, 0.0205,  ..., 0.0394, 0.0405, 0.0246],\n",
            "        ...,\n",
            "        [0.0477, 0.0094, 0.0386,  ..., 0.0192, 0.0202, 0.0364],\n",
            "        [0.0273, 0.0142, 0.0192,  ..., 0.0148, 0.0261, 0.0248],\n",
            "        [0.0276, 0.0215, 0.0213,  ..., 0.0184, 0.0301, 0.0237]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 1\n",
            "0.6766701936721802\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0479, 0.0922, 0.0758, 0.3292, 0.1286, 0.0760, 0.1156, 0.1348],\n",
            "        [0.1632, 0.1577, 0.1032, 0.1444, 0.1014, 0.0715, 0.0963, 0.1622],\n",
            "        [0.0989, 0.1059, 0.1202, 0.1981, 0.1237, 0.1079, 0.1003, 0.1449],\n",
            "        [0.1117, 0.3034, 0.1301, 0.0857, 0.1259, 0.0684, 0.1005, 0.0744],\n",
            "        [0.1029, 0.0763, 0.0644, 0.1213, 0.3727, 0.0804, 0.0755, 0.1066],\n",
            "        [0.0582, 0.1078, 0.1191, 0.1626, 0.0956, 0.2029, 0.1227, 0.1311],\n",
            "        [0.1136, 0.1299, 0.1557, 0.0803, 0.1285, 0.1079, 0.1284, 0.1556],\n",
            "        [0.1221, 0.1061, 0.1348, 0.0907, 0.1107, 0.1458, 0.1334, 0.1564]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 2\n",
            "0.6909953355789185\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0310, 0.0325, 0.0377,  ..., 0.0316, 0.0246, 0.0403],\n",
            "        [0.0194, 0.0221, 0.0533,  ..., 0.0317, 0.0696, 0.0379],\n",
            "        [0.0365, 0.0246, 0.0208,  ..., 0.0250, 0.0343, 0.0332],\n",
            "        ...,\n",
            "        [0.0223, 0.0280, 0.0212,  ..., 0.0320, 0.0196, 0.0207],\n",
            "        [0.0253, 0.0414, 0.0246,  ..., 0.0258, 0.0286, 0.0176],\n",
            "        [0.0246, 0.0279, 0.0259,  ..., 0.0275, 0.0353, 0.0383]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 2\n",
            "0.675919234752655\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0249, 0.0252, 0.0281,  ..., 0.0429, 0.0376, 0.0384],\n",
            "        [0.0160, 0.0366, 0.0446,  ..., 0.0416, 0.0467, 0.0301],\n",
            "        [0.0274, 0.0220, 0.0277,  ..., 0.0307, 0.0398, 0.0356],\n",
            "        ...,\n",
            "        [0.0207, 0.0228, 0.0300,  ..., 0.0295, 0.0436, 0.0171],\n",
            "        [0.0185, 0.0151, 0.0180,  ..., 0.0490, 0.2587, 0.0151],\n",
            "        [0.0181, 0.0251, 0.0195,  ..., 0.0389, 0.0191, 0.0737]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 2\n",
            "0.7042372226715088\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0216, 0.0803, 0.0242,  ..., 0.0160, 0.0414, 0.0225],\n",
            "        [0.0298, 0.0268, 0.0588,  ..., 0.0388, 0.0414, 0.0213],\n",
            "        [0.0342, 0.0340, 0.0210,  ..., 0.0144, 0.0343, 0.0321],\n",
            "        ...,\n",
            "        [0.0163, 0.0379, 0.0206,  ..., 0.0157, 0.0199, 0.0401],\n",
            "        [0.0655, 0.0325, 0.0314,  ..., 0.0223, 0.0808, 0.0187],\n",
            "        [0.0361, 0.0276, 0.0566,  ..., 0.0377, 0.0525, 0.0187]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 2\n",
            "0.6674973368644714\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0075, 0.0278, 0.0237,  ..., 0.0303, 0.0530, 0.0397],\n",
            "        [0.0269, 0.3048, 0.0173,  ..., 0.0178, 0.0232, 0.0076],\n",
            "        [0.0291, 0.0232, 0.0281,  ..., 0.0267, 0.0259, 0.0299],\n",
            "        ...,\n",
            "        [0.0482, 0.0264, 0.0177,  ..., 0.0139, 0.0126, 0.0134],\n",
            "        [0.0271, 0.0345, 0.0264,  ..., 0.0188, 0.0275, 0.0185],\n",
            "        [0.0502, 0.0225, 0.0193,  ..., 0.0226, 0.0178, 0.0271]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 2\n",
            "0.7056671380996704\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0275, 0.0147, 0.0410,  ..., 0.0266, 0.0191, 0.0397],\n",
            "        [0.0274, 0.0311, 0.0239,  ..., 0.0666, 0.0137, 0.0196],\n",
            "        [0.0240, 0.0355, 0.0172,  ..., 0.0263, 0.2409, 0.0177],\n",
            "        ...,\n",
            "        [0.0223, 0.0356, 0.0279,  ..., 0.0209, 0.0673, 0.0236],\n",
            "        [0.0313, 0.0247, 0.0133,  ..., 0.0608, 0.0269, 0.0318],\n",
            "        [0.0287, 0.0193, 0.0461,  ..., 0.0149, 0.0333, 0.0141]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 2\n",
            "0.6696579456329346\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0272, 0.0317, 0.0306,  ..., 0.0357, 0.0324, 0.0246],\n",
            "        [0.0396, 0.0354, 0.0414,  ..., 0.0257, 0.0221, 0.0314],\n",
            "        [0.0225, 0.0231, 0.1439,  ..., 0.0139, 0.0255, 0.0117],\n",
            "        ...,\n",
            "        [0.0212, 0.0111, 0.0782,  ..., 0.0620, 0.0206, 0.0459],\n",
            "        [0.0426, 0.0171, 0.0733,  ..., 0.0375, 0.0234, 0.0324],\n",
            "        [0.0355, 0.0385, 0.0146,  ..., 0.0329, 0.0283, 0.0191]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 2\n",
            "0.708477258682251\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0886, 0.0161, 0.0382,  ..., 0.0234, 0.0346, 0.0218],\n",
            "        [0.0246, 0.0206, 0.0370,  ..., 0.0808, 0.0349, 0.0233],\n",
            "        [0.0199, 0.0208, 0.2267,  ..., 0.0341, 0.0294, 0.0881],\n",
            "        ...,\n",
            "        [0.0284, 0.0582, 0.0307,  ..., 0.0975, 0.0277, 0.0283],\n",
            "        [0.0466, 0.0203, 0.0438,  ..., 0.0223, 0.0212, 0.0378],\n",
            "        [0.0223, 0.0238, 0.0415,  ..., 0.0523, 0.0372, 0.0879]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 2\n",
            "0.6714667081832886\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0688, 0.0124, 0.0477,  ..., 0.0150, 0.0368, 0.1164],\n",
            "        [0.0082, 0.0133, 0.1892,  ..., 0.0094, 0.0139, 0.0210],\n",
            "        [0.0356, 0.0106, 0.1125,  ..., 0.0248, 0.0342, 0.0272],\n",
            "        ...,\n",
            "        [0.0212, 0.0647, 0.0438,  ..., 0.0195, 0.0395, 0.0290],\n",
            "        [0.0541, 0.1451, 0.0143,  ..., 0.0301, 0.1405, 0.0159],\n",
            "        [0.0247, 0.0234, 0.0237,  ..., 0.0241, 0.0236, 0.0408]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 2\n",
            "0.6951860785484314\n",
            "one attention pattern developping during training\n",
            "tensor([[0.2119, 0.0209, 0.0130,  ..., 0.0088, 0.0224, 0.0169],\n",
            "        [0.0417, 0.0287, 0.0218,  ..., 0.0145, 0.0268, 0.0375],\n",
            "        [0.0254, 0.0429, 0.0244,  ..., 0.0298, 0.0366, 0.0339],\n",
            "        ...,\n",
            "        [0.0091, 0.0046, 0.0103,  ..., 0.0809, 0.0185, 0.0088],\n",
            "        [0.0480, 0.0235, 0.0187,  ..., 0.0483, 0.0278, 0.0236],\n",
            "        [0.0314, 0.0200, 0.0624,  ..., 0.0290, 0.0310, 0.0312]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 2\n",
            "0.7005038857460022\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0282, 0.0214, 0.0204,  ..., 0.0196, 0.0441, 0.0326],\n",
            "        [0.0506, 0.0131, 0.0250,  ..., 0.0171, 0.0212, 0.0230],\n",
            "        [0.0349, 0.0369, 0.0365,  ..., 0.0547, 0.0186, 0.0157],\n",
            "        ...,\n",
            "        [0.0629, 0.0278, 0.0205,  ..., 0.0331, 0.0320, 0.0337],\n",
            "        [0.0268, 0.0423, 0.0299,  ..., 0.0365, 0.0582, 0.0278],\n",
            "        [0.0222, 0.0119, 0.0215,  ..., 0.0279, 0.0322, 0.0906]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 2\n",
            "0.6970381140708923\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0585, 0.0585, 0.0120,  ..., 0.0196, 0.0165, 0.0186],\n",
            "        [0.0585, 0.0585, 0.0120,  ..., 0.0196, 0.0165, 0.0186],\n",
            "        [0.0734, 0.0734, 0.0183,  ..., 0.0166, 0.0302, 0.0362],\n",
            "        ...,\n",
            "        [0.0275, 0.0275, 0.0297,  ..., 0.0276, 0.0299, 0.0358],\n",
            "        [0.0187, 0.0187, 0.0272,  ..., 0.0210, 0.0951, 0.0334],\n",
            "        [0.0370, 0.0370, 0.0230,  ..., 0.0305, 0.0247, 0.0257]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 2\n",
            "0.6914004683494568\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0123, 0.0205, 0.0273,  ..., 0.0475, 0.0191, 0.0240],\n",
            "        [0.0285, 0.0167, 0.0173,  ..., 0.0337, 0.0233, 0.0362],\n",
            "        [0.0391, 0.0175, 0.0300,  ..., 0.0527, 0.0225, 0.1088],\n",
            "        ...,\n",
            "        [0.0306, 0.0234, 0.0297,  ..., 0.0274, 0.0284, 0.0374],\n",
            "        [0.0172, 0.0315, 0.0189,  ..., 0.0201, 0.0341, 0.0230],\n",
            "        [0.0195, 0.0333, 0.0520,  ..., 0.0265, 0.0543, 0.0261]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 2\n",
            "0.6740275025367737\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0313, 0.0184, 0.1529,  ..., 0.0247, 0.0243, 0.0338],\n",
            "        [0.0148, 0.3484, 0.0088,  ..., 0.0219, 0.0249, 0.0321],\n",
            "        [0.0318, 0.0187, 0.0164,  ..., 0.0165, 0.0310, 0.0230],\n",
            "        ...,\n",
            "        [0.0135, 0.0180, 0.1435,  ..., 0.0987, 0.0094, 0.0146],\n",
            "        [0.0346, 0.0469, 0.0294,  ..., 0.0453, 0.0249, 0.0433],\n",
            "        [0.0301, 0.0441, 0.0148,  ..., 0.0286, 0.0214, 0.0991]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 2\n",
            "0.6829884052276611\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0525, 0.0149, 0.0442,  ..., 0.0497, 0.0236, 0.0149],\n",
            "        [0.0328, 0.0277, 0.0449,  ..., 0.0170, 0.0659, 0.0277],\n",
            "        [0.0399, 0.0292, 0.0156,  ..., 0.0256, 0.0321, 0.0292],\n",
            "        ...,\n",
            "        [0.0280, 0.0335, 0.0334,  ..., 0.0178, 0.0405, 0.0335],\n",
            "        [0.0376, 0.0242, 0.0276,  ..., 0.0412, 0.0379, 0.0242],\n",
            "        [0.0328, 0.0277, 0.0449,  ..., 0.0170, 0.0659, 0.0277]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 2\n",
            "0.6801163554191589\n",
            "one attention pattern developping during training\n",
            "tensor([[0.2714, 0.0196, 0.0286,  ..., 0.0289, 0.0183, 0.0215],\n",
            "        [0.0375, 0.0067, 0.0193,  ..., 0.0873, 0.0137, 0.0166],\n",
            "        [0.0286, 0.0350, 0.0296,  ..., 0.0263, 0.0320, 0.0276],\n",
            "        ...,\n",
            "        [0.0393, 0.1059, 0.0299,  ..., 0.0187, 0.0206, 0.0626],\n",
            "        [0.0290, 0.1048, 0.0249,  ..., 0.0172, 0.0328, 0.0184],\n",
            "        [0.0383, 0.0290, 0.0248,  ..., 0.0298, 0.0381, 0.0341]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 2\n",
            "0.69046550989151\n",
            "one attention pattern developping during training\n",
            "tensor([[0.1422, 0.2010, 0.0395,  ..., 0.0137, 0.0072, 0.0301],\n",
            "        [0.0247, 0.2676, 0.0187,  ..., 0.0213, 0.0047, 0.0143],\n",
            "        [0.0276, 0.0176, 0.2654,  ..., 0.0268, 0.0345, 0.0322],\n",
            "        ...,\n",
            "        [0.0301, 0.0913, 0.0321,  ..., 0.0304, 0.0182, 0.0373],\n",
            "        [0.0343, 0.0356, 0.0536,  ..., 0.0369, 0.0277, 0.0297],\n",
            "        [0.0238, 0.0117, 0.0189,  ..., 0.0223, 0.0220, 0.1275]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 2\n",
            "0.6942676901817322\n",
            "one attention pattern developping during training\n",
            "tensor([[0.1548, 0.0173, 0.0145,  ..., 0.0137, 0.0269, 0.0401],\n",
            "        [0.0609, 0.0204, 0.0417,  ..., 0.0313, 0.0227, 0.0380],\n",
            "        [0.0100, 0.0299, 0.1283,  ..., 0.0263, 0.0105, 0.0093],\n",
            "        ...,\n",
            "        [0.0180, 0.0230, 0.0385,  ..., 0.0205, 0.0230, 0.0467],\n",
            "        [0.0407, 0.0468, 0.0390,  ..., 0.0371, 0.0204, 0.0291],\n",
            "        [0.0231, 0.0173, 0.0241,  ..., 0.0530, 0.0353, 0.0239]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 2\n",
            "0.6775412559509277\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0403, 0.0251, 0.0391,  ..., 0.0181, 0.0240, 0.0521],\n",
            "        [0.0163, 0.0250, 0.0281,  ..., 0.0307, 0.0262, 0.0241],\n",
            "        [0.0158, 0.0385, 0.0292,  ..., 0.0205, 0.0192, 0.0288],\n",
            "        ...,\n",
            "        [0.0426, 0.0143, 0.0276,  ..., 0.0456, 0.0369, 0.0228],\n",
            "        [0.0269, 0.0260, 0.0365,  ..., 0.0295, 0.0211, 0.0273],\n",
            "        [0.0335, 0.0359, 0.0282,  ..., 0.0277, 0.0246, 0.0268]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 2\n",
            "0.6927524209022522\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0097, 0.0223, 0.0181,  ..., 0.0455, 0.0501, 0.0101],\n",
            "        [0.0806, 0.0315, 0.0352,  ..., 0.0280, 0.0264, 0.0486],\n",
            "        [0.3143, 0.0223, 0.0177,  ..., 0.0132, 0.0123, 0.0339],\n",
            "        ...,\n",
            "        [0.0091, 0.0517, 0.0244,  ..., 0.0329, 0.0190, 0.0306],\n",
            "        [0.4505, 0.0083, 0.0081,  ..., 0.0064, 0.0030, 0.0598],\n",
            "        [0.1056, 0.0328, 0.0212,  ..., 0.0356, 0.0140, 0.0309]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 2\n",
            "0.6835182309150696\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0238, 0.0240, 0.0250,  ..., 0.0185, 0.0268, 0.0241],\n",
            "        [0.0343, 0.0068, 0.0059,  ..., 0.0155, 0.0342, 0.0171],\n",
            "        [0.0173, 0.0236, 0.0172,  ..., 0.0246, 0.0332, 0.0194],\n",
            "        ...,\n",
            "        [0.0313, 0.0255, 0.0246,  ..., 0.0274, 0.0321, 0.0439],\n",
            "        [0.0199, 0.0220, 0.0393,  ..., 0.0320, 0.0162, 0.0229],\n",
            "        [0.0258, 0.0134, 0.0249,  ..., 0.0260, 0.0231, 0.0184]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 2\n",
            "0.7557176351547241\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0334, 0.0255, 0.0396,  ..., 0.0201, 0.0411, 0.0316],\n",
            "        [0.0273, 0.0399, 0.0309,  ..., 0.0225, 0.0236, 0.0398],\n",
            "        [0.0291, 0.0229, 0.0208,  ..., 0.0248, 0.0369, 0.0366],\n",
            "        ...,\n",
            "        [0.0437, 0.2157, 0.0578,  ..., 0.0051, 0.0234, 0.0353],\n",
            "        [0.0246, 0.0621, 0.0409,  ..., 0.0255, 0.0856, 0.0309],\n",
            "        [0.0490, 0.0302, 0.0283,  ..., 0.0242, 0.0106, 0.0363]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 2\n",
            "0.6941573619842529\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0218, 0.0273, 0.0194,  ..., 0.0261, 0.1272, 0.0355],\n",
            "        [0.0148, 0.0232, 0.0272,  ..., 0.0148, 0.0186, 0.0546],\n",
            "        [0.0259, 0.0335, 0.0186,  ..., 0.0271, 0.0466, 0.0178],\n",
            "        ...,\n",
            "        [0.0214, 0.0309, 0.0108,  ..., 0.0237, 0.0215, 0.0445],\n",
            "        [0.0193, 0.0183, 0.0250,  ..., 0.0196, 0.1570, 0.0214],\n",
            "        [0.0242, 0.0355, 0.0287,  ..., 0.0325, 0.0333, 0.0416]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 2\n",
            "0.7031688094139099\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0328, 0.0201, 0.0411,  ..., 0.0429, 0.0319, 0.0319],\n",
            "        [0.0201, 0.0128, 0.0919,  ..., 0.2797, 0.0250, 0.0250],\n",
            "        [0.0215, 0.0513, 0.0219,  ..., 0.0060, 0.0142, 0.0142],\n",
            "        ...,\n",
            "        [0.0156, 0.0308, 0.0162,  ..., 0.0097, 0.0215, 0.0215],\n",
            "        [0.0859, 0.0271, 0.0416,  ..., 0.0160, 0.0298, 0.0298],\n",
            "        [0.0859, 0.0271, 0.0416,  ..., 0.0160, 0.0298, 0.0298]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 2\n",
            "0.6583861708641052\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0139, 0.0230, 0.0453,  ..., 0.0212, 0.0513, 0.0245],\n",
            "        [0.0211, 0.0282, 0.0104,  ..., 0.0194, 0.0315, 0.0233],\n",
            "        [0.0192, 0.0120, 0.0262,  ..., 0.0233, 0.0218, 0.0172],\n",
            "        ...,\n",
            "        [0.0211, 0.0165, 0.0297,  ..., 0.0161, 0.0148, 0.0229],\n",
            "        [0.0581, 0.0168, 0.0312,  ..., 0.0181, 0.1176, 0.0234],\n",
            "        [0.0291, 0.0754, 0.0232,  ..., 0.0101, 0.0057, 0.0855]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 2\n",
            "0.6803821921348572\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0237, 0.0239, 0.0100,  ..., 0.0296, 0.0285, 0.0100],\n",
            "        [0.0387, 0.0174, 0.0362,  ..., 0.0250, 0.0253, 0.0362],\n",
            "        [0.0343, 0.0357, 0.0271,  ..., 0.0184, 0.0394, 0.0271],\n",
            "        ...,\n",
            "        [0.0085, 0.1211, 0.0170,  ..., 0.0134, 0.0192, 0.0170],\n",
            "        [0.0337, 0.0197, 0.0282,  ..., 0.0253, 0.0316, 0.0282],\n",
            "        [0.0343, 0.0357, 0.0271,  ..., 0.0184, 0.0394, 0.0271]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 2\n",
            "0.6952010989189148\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0205, 0.0278, 0.0379,  ..., 0.0329, 0.0387, 0.0410],\n",
            "        [0.0219, 0.0227, 0.0383,  ..., 0.0254, 0.0188, 0.0267],\n",
            "        [0.0413, 0.0321, 0.0179,  ..., 0.0214, 0.0334, 0.0754],\n",
            "        ...,\n",
            "        [0.0186, 0.0163, 0.0360,  ..., 0.2221, 0.0425, 0.0314],\n",
            "        [0.0181, 0.0223, 0.0250,  ..., 0.0205, 0.0473, 0.0279],\n",
            "        [0.0167, 0.0282, 0.0286,  ..., 0.0185, 0.0253, 0.0261]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 2\n",
            "0.6863111257553101\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0367, 0.0240, 0.0348,  ..., 0.0348, 0.0189, 0.0250],\n",
            "        [0.0109, 0.0093, 0.0068,  ..., 0.0068, 0.0454, 0.0079],\n",
            "        [0.0235, 0.0220, 0.0163,  ..., 0.0163, 0.0349, 0.0430],\n",
            "        ...,\n",
            "        [0.0235, 0.0220, 0.0163,  ..., 0.0163, 0.0349, 0.0430],\n",
            "        [0.0073, 0.0060, 0.0044,  ..., 0.0044, 0.1050, 0.0141],\n",
            "        [0.0408, 0.0262, 0.0355,  ..., 0.0355, 0.0410, 0.0473]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 2\n",
            "0.6813212633132935\n",
            "one attention pattern developping during training\n",
            "tensor([[0.2510, 0.0050, 0.0021,  ..., 0.0066, 0.0071, 0.0129],\n",
            "        [0.0189, 0.1899, 0.0099,  ..., 0.0223, 0.0111, 0.0100],\n",
            "        [0.0399, 0.0216, 0.0093,  ..., 0.0135, 0.0080, 0.0214],\n",
            "        ...,\n",
            "        [0.0294, 0.0449, 0.0213,  ..., 0.0101, 0.1002, 0.0102],\n",
            "        [0.1503, 0.0248, 0.0236,  ..., 0.0429, 0.0192, 0.0318],\n",
            "        [0.0163, 0.0426, 0.0091,  ..., 0.0185, 0.0251, 0.0064]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 2\n",
            "0.6711553335189819\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0331, 0.0422, 0.0223,  ..., 0.0210, 0.0138, 0.0235],\n",
            "        [0.0246, 0.0139, 0.0484,  ..., 0.0371, 0.0528, 0.0238],\n",
            "        [0.0242, 0.0166, 0.0166,  ..., 0.0165, 0.0159, 0.0127],\n",
            "        ...,\n",
            "        [0.0419, 0.0285, 0.0240,  ..., 0.0247, 0.0247, 0.0339],\n",
            "        [0.0080, 0.0260, 0.0094,  ..., 0.0132, 0.0102, 0.0253],\n",
            "        [0.0284, 0.0272, 0.0150,  ..., 0.0186, 0.0135, 0.0142]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 2\n",
            "0.7131510972976685\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0156, 0.0294, 0.0384,  ..., 0.0294, 0.0351, 0.0351],\n",
            "        [0.0107, 0.1311, 0.0100,  ..., 0.1311, 0.0184, 0.0184],\n",
            "        [0.0186, 0.0245, 0.0156,  ..., 0.0245, 0.0467, 0.0467],\n",
            "        ...,\n",
            "        [0.0107, 0.1311, 0.0100,  ..., 0.1311, 0.0184, 0.0184],\n",
            "        [0.0114, 0.0189, 0.0221,  ..., 0.0189, 0.1572, 0.1572],\n",
            "        [0.0114, 0.0189, 0.0221,  ..., 0.0189, 0.1572, 0.1572]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 2\n",
            "0.6717064380645752\n",
            "one attention pattern developping during training\n",
            "tensor([[0.1414, 0.0302, 0.0435,  ..., 0.0286, 0.0244, 0.0180],\n",
            "        [0.0099, 0.0107, 0.0070,  ..., 0.0164, 0.0336, 0.1072],\n",
            "        [0.0459, 0.0205, 0.0155,  ..., 0.0344, 0.0247, 0.0289],\n",
            "        ...,\n",
            "        [0.0261, 0.0266, 0.0421,  ..., 0.0319, 0.0486, 0.0199],\n",
            "        [0.0791, 0.0180, 0.0144,  ..., 0.0097, 0.0334, 0.0359],\n",
            "        [0.0238, 0.0253, 0.0453,  ..., 0.0800, 0.0225, 0.0229]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 2\n",
            "0.7430413961410522\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0544, 0.1955, 0.0931, 0.1226, 0.3157, 0.0665, 0.0814, 0.0707],\n",
            "        [0.2158, 0.2596, 0.0539, 0.0759, 0.0727, 0.0516, 0.0938, 0.1768],\n",
            "        [0.0366, 0.1496, 0.0855, 0.1072, 0.1340, 0.2679, 0.1263, 0.0929],\n",
            "        [0.0579, 0.1104, 0.0998, 0.0825, 0.0737, 0.3557, 0.0798, 0.1402],\n",
            "        [0.0848, 0.1103, 0.0920, 0.1249, 0.1318, 0.1363, 0.1146, 0.2055],\n",
            "        [0.1201, 0.1117, 0.0843, 0.1172, 0.1015, 0.0732, 0.1418, 0.2502],\n",
            "        [0.3712, 0.0704, 0.0478, 0.0762, 0.0822, 0.0346, 0.2770, 0.0406],\n",
            "        [0.0831, 0.1552, 0.1462, 0.2688, 0.0969, 0.0753, 0.1087, 0.0659]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 3\n",
            "0.6814709901809692\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0227, 0.0225, 0.0231,  ..., 0.0210, 0.0375, 0.0327],\n",
            "        [0.0260, 0.0228, 0.1695,  ..., 0.0181, 0.0801, 0.0230],\n",
            "        [0.0174, 0.0330, 0.0585,  ..., 0.0175, 0.0099, 0.0138],\n",
            "        ...,\n",
            "        [0.0193, 0.0285, 0.0542,  ..., 0.0311, 0.0196, 0.0223],\n",
            "        [0.0159, 0.0197, 0.0459,  ..., 0.0151, 0.0964, 0.0155],\n",
            "        [0.0200, 0.0248, 0.0333,  ..., 0.0359, 0.0146, 0.0403]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 3\n",
            "0.6621727347373962\n",
            "one attention pattern developping during training\n",
            "tensor([[0.1224, 0.0240, 0.1370,  ..., 0.0176, 0.0383, 0.0187],\n",
            "        [0.0208, 0.0308, 0.0188,  ..., 0.0272, 0.0261, 0.0215],\n",
            "        [0.2120, 0.0242, 0.0073,  ..., 0.0300, 0.0280, 0.0796],\n",
            "        ...,\n",
            "        [0.0282, 0.0210, 0.0520,  ..., 0.0433, 0.0510, 0.0393],\n",
            "        [0.2929, 0.0187, 0.0309,  ..., 0.0263, 0.0154, 0.0288],\n",
            "        [0.0037, 0.0070, 0.4978,  ..., 0.0136, 0.0027, 0.0039]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 3\n",
            "0.705764651298523\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0147, 0.0232, 0.0208,  ..., 0.0613, 0.0284, 0.1851],\n",
            "        [0.0183, 0.1724, 0.0062,  ..., 0.0547, 0.0210, 0.0431],\n",
            "        [0.0375, 0.0140, 0.0298,  ..., 0.0216, 0.0368, 0.0363],\n",
            "        ...,\n",
            "        [0.0215, 0.0198, 0.0447,  ..., 0.0148, 0.0409, 0.0162],\n",
            "        [0.0291, 0.0187, 0.0303,  ..., 0.0199, 0.0071, 0.0149],\n",
            "        [0.0401, 0.0238, 0.0495,  ..., 0.0167, 0.0194, 0.0157]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 3\n",
            "0.6678167581558228\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0165, 0.0168, 0.0146,  ..., 0.0593, 0.0291, 0.0339],\n",
            "        [0.0212, 0.0265, 0.0250,  ..., 0.0203, 0.0375, 0.0257],\n",
            "        [0.0284, 0.0522, 0.0392,  ..., 0.0271, 0.0207, 0.0203],\n",
            "        ...,\n",
            "        [0.0238, 0.0164, 0.0322,  ..., 0.0169, 0.0247, 0.0759],\n",
            "        [0.0197, 0.0212, 0.0240,  ..., 0.0189, 0.1278, 0.0802],\n",
            "        [0.0248, 0.0135, 0.0232,  ..., 0.0070, 0.0236, 0.0121]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 3\n",
            "0.6363129615783691\n",
            "one attention pattern developping during training\n",
            "tensor([[0.1324, 0.0427, 0.0557,  ..., 0.0152, 0.0171, 0.0394],\n",
            "        [0.0235, 0.0616, 0.0231,  ..., 0.0210, 0.0236, 0.0936],\n",
            "        [0.0213, 0.0225, 0.0214,  ..., 0.0416, 0.0244, 0.0584],\n",
            "        ...,\n",
            "        [0.0226, 0.0182, 0.0175,  ..., 0.0345, 0.0376, 0.0245],\n",
            "        [0.0441, 0.1048, 0.0179,  ..., 0.0135, 0.0073, 0.0198],\n",
            "        [0.0171, 0.1560, 0.0372,  ..., 0.0223, 0.0054, 0.0074]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 3\n",
            "0.6630796194076538\n",
            "one attention pattern developping during training\n",
            "tensor([[0.1565, 0.0044, 0.0017,  ..., 0.0107, 0.0409, 0.0044],\n",
            "        [0.0134, 0.0186, 0.0180,  ..., 0.0165, 0.0189, 0.0186],\n",
            "        [0.0086, 0.0181, 0.0087,  ..., 0.0115, 0.0144, 0.0181],\n",
            "        ...,\n",
            "        [0.0328, 0.0120, 0.0107,  ..., 0.0255, 0.0374, 0.0120],\n",
            "        [0.0299, 0.0157, 0.0020,  ..., 0.0138, 0.1386, 0.0157],\n",
            "        [0.0134, 0.0186, 0.0180,  ..., 0.0165, 0.0189, 0.0186]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 3\n",
            "0.6145985722541809\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0289, 0.0186, 0.0339,  ..., 0.0171, 0.0313, 0.0158],\n",
            "        [0.0284, 0.0240, 0.0356,  ..., 0.0122, 0.0199, 0.0188],\n",
            "        [0.0520, 0.0277, 0.0362,  ..., 0.0157, 0.0203, 0.0147],\n",
            "        ...,\n",
            "        [0.0367, 0.0164, 0.0371,  ..., 0.0104, 0.0190, 0.0328],\n",
            "        [0.0331, 0.0152, 0.0219,  ..., 0.0102, 0.0952, 0.0399],\n",
            "        [0.0065, 0.1368, 0.0167,  ..., 0.0613, 0.0368, 0.0197]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 3\n",
            "0.6294199228286743\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0281, 0.0210, 0.0128,  ..., 0.0333, 0.0502, 0.0392],\n",
            "        [0.0474, 0.0138, 0.0178,  ..., 0.0193, 0.0251, 0.0623],\n",
            "        [0.1150, 0.0222, 0.0081,  ..., 0.0101, 0.0553, 0.0431],\n",
            "        ...,\n",
            "        [0.0300, 0.0222, 0.0386,  ..., 0.0222, 0.0362, 0.0195],\n",
            "        [0.0131, 0.0161, 0.0103,  ..., 0.0207, 0.3353, 0.2616],\n",
            "        [0.0139, 0.0429, 0.0238,  ..., 0.0360, 0.0543, 0.0285]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 3\n",
            "0.7335414290428162\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0217, 0.0278, 0.0252,  ..., 0.0583, 0.0217, 0.0453],\n",
            "        [0.0160, 0.0390, 0.0558,  ..., 0.0302, 0.1278, 0.0223],\n",
            "        [0.1297, 0.0113, 0.1149,  ..., 0.0262, 0.0088, 0.0194],\n",
            "        ...,\n",
            "        [0.0346, 0.0083, 0.0359,  ..., 0.1200, 0.0205, 0.0257],\n",
            "        [0.0146, 0.0232, 0.0225,  ..., 0.0205, 0.0254, 0.0406],\n",
            "        [0.0149, 0.0282, 0.0296,  ..., 0.0154, 0.0142, 0.0291]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 3\n",
            "0.6182096600532532\n",
            "one attention pattern developping during training\n",
            "tensor([[0.2013, 0.0107, 0.0175,  ..., 0.0297, 0.0146, 0.0367],\n",
            "        [0.0344, 0.1191, 0.0269,  ..., 0.0229, 0.0178, 0.0219],\n",
            "        [0.0168, 0.0124, 0.0274,  ..., 0.0082, 0.0131, 0.0831],\n",
            "        ...,\n",
            "        [0.0533, 0.0323, 0.0224,  ..., 0.0121, 0.0179, 0.0220],\n",
            "        [0.0162, 0.0242, 0.0187,  ..., 0.0406, 0.0265, 0.0218],\n",
            "        [0.0229, 0.0107, 0.0074,  ..., 0.0076, 0.0112, 0.1268]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 3\n",
            "0.666722297668457\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0317, 0.0227, 0.0330,  ..., 0.0195, 0.0233, 0.0564],\n",
            "        [0.0178, 0.0298, 0.0458,  ..., 0.0210, 0.0392, 0.0248],\n",
            "        [0.0114, 0.0235, 0.0366,  ..., 0.0241, 0.0190, 0.0129],\n",
            "        ...,\n",
            "        [0.0056, 0.0224, 0.0155,  ..., 0.0074, 0.0119, 0.0110],\n",
            "        [0.0306, 0.0319, 0.0204,  ..., 0.0249, 0.0314, 0.0259],\n",
            "        [0.0798, 0.0483, 0.0310,  ..., 0.0225, 0.0130, 0.0252]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 3\n",
            "0.6640239357948303\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0270, 0.0282, 0.0322,  ..., 0.0222, 0.0581, 0.0438],\n",
            "        [0.0027, 0.2349, 0.0079,  ..., 0.0063, 0.0021, 0.0091],\n",
            "        [0.0254, 0.0337, 0.0307,  ..., 0.0329, 0.0276, 0.0236],\n",
            "        ...,\n",
            "        [0.0114, 0.0096, 0.0137,  ..., 0.0117, 0.0076, 0.0138],\n",
            "        [0.0259, 0.0893, 0.0214,  ..., 0.0200, 0.0366, 0.0158],\n",
            "        [0.0128, 0.0689, 0.0089,  ..., 0.0771, 0.0114, 0.0143]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 3\n",
            "0.6972924470901489\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0081, 0.0192, 0.0136,  ..., 0.0163, 0.0156, 0.0159],\n",
            "        [0.0250, 0.0218, 0.0612,  ..., 0.0235, 0.0333, 0.0134],\n",
            "        [0.0651, 0.0210, 0.0300,  ..., 0.0280, 0.0304, 0.0240],\n",
            "        ...,\n",
            "        [0.0231, 0.0258, 0.0315,  ..., 0.0140, 0.0187, 0.0257],\n",
            "        [0.0110, 0.0305, 0.0252,  ..., 0.0194, 0.0190, 0.0201],\n",
            "        [0.0244, 0.0491, 0.0194,  ..., 0.0274, 0.0211, 0.0109]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 3\n",
            "0.6826350092887878\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0420, 0.0299, 0.0213,  ..., 0.0192, 0.0154, 0.0189],\n",
            "        [0.0255, 0.0233, 0.0099,  ..., 0.0504, 0.0106, 0.0201],\n",
            "        [0.0340, 0.0828, 0.0255,  ..., 0.0243, 0.0294, 0.0384],\n",
            "        ...,\n",
            "        [0.0122, 0.2621, 0.0122,  ..., 0.0361, 0.0125, 0.0242],\n",
            "        [0.0211, 0.0338, 0.0185,  ..., 0.0281, 0.0254, 0.0241],\n",
            "        [0.0257, 0.0156, 0.0253,  ..., 0.0209, 0.0145, 0.0110]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 3\n",
            "0.6929634809494019\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0326, 0.0212, 0.0197,  ..., 0.1066, 0.0174, 0.0286],\n",
            "        [0.0049, 0.0024, 0.0748,  ..., 0.0033, 0.0250, 0.0249],\n",
            "        [0.0146, 0.0173, 0.0162,  ..., 0.0270, 0.0252, 0.0734],\n",
            "        ...,\n",
            "        [0.0071, 0.0104, 0.0407,  ..., 0.0102, 0.0156, 0.0296],\n",
            "        [0.0133, 0.0101, 0.0369,  ..., 0.0173, 0.0178, 0.0362],\n",
            "        [0.0725, 0.0332, 0.0199,  ..., 0.0268, 0.0256, 0.0801]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 3\n",
            "0.6629692912101746\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0243, 0.0259, 0.0406,  ..., 0.0229, 0.0813, 0.0243],\n",
            "        [0.0073, 0.0311, 0.0261,  ..., 0.0179, 0.0106, 0.0073],\n",
            "        [0.0213, 0.0158, 0.0259,  ..., 0.0231, 0.0215, 0.0213],\n",
            "        ...,\n",
            "        [0.0058, 0.0097, 0.0095,  ..., 0.0275, 0.0142, 0.0058],\n",
            "        [0.0098, 0.0485, 0.0273,  ..., 0.0239, 0.0906, 0.0098],\n",
            "        [0.0243, 0.0259, 0.0406,  ..., 0.0229, 0.0813, 0.0243]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 3\n",
            "0.6344658732414246\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0341, 0.0232, 0.0226,  ..., 0.0085, 0.0102, 0.0076],\n",
            "        [0.0312, 0.0232, 0.0235,  ..., 0.0314, 0.0188, 0.0819],\n",
            "        [0.0194, 0.0127, 0.0083,  ..., 0.0288, 0.0089, 0.0662],\n",
            "        ...,\n",
            "        [0.0200, 0.0297, 0.0213,  ..., 0.1679, 0.0349, 0.0957],\n",
            "        [0.0060, 0.0800, 0.0172,  ..., 0.0304, 0.0194, 0.0121],\n",
            "        [0.0253, 0.0334, 0.0243,  ..., 0.0210, 0.0232, 0.0227]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 3\n",
            "0.740684986114502\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0170, 0.0019, 0.0118,  ..., 0.0061, 0.0017, 0.0048],\n",
            "        [0.0115, 0.0069, 0.0139,  ..., 0.0096, 0.0076, 0.0090],\n",
            "        [0.0337, 0.2411, 0.0066,  ..., 0.0149, 0.0262, 0.0162],\n",
            "        ...,\n",
            "        [0.0128, 0.0127, 0.0054,  ..., 0.0080, 0.0034, 0.0042],\n",
            "        [0.0052, 0.0008, 0.0041,  ..., 0.0005, 0.0010, 0.0053],\n",
            "        [0.0015, 0.0043, 0.0080,  ..., 0.0024, 0.0087, 0.0155]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 3\n",
            "0.6780710220336914\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0016, 0.0102, 0.0006,  ..., 0.0121, 0.0030, 0.0121],\n",
            "        [0.0070, 0.0114, 0.0298,  ..., 0.0259, 0.0226, 0.0259],\n",
            "        [0.0122, 0.0193, 0.0064,  ..., 0.0122, 0.0741, 0.0122],\n",
            "        ...,\n",
            "        [0.0281, 0.0227, 0.0458,  ..., 0.0256, 0.0384, 0.0256],\n",
            "        [0.0465, 0.0200, 0.0426,  ..., 0.0504, 0.1757, 0.0504],\n",
            "        [0.0281, 0.0227, 0.0458,  ..., 0.0256, 0.0384, 0.0256]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 3\n",
            "0.671746551990509\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0901, 0.0365, 0.0268,  ..., 0.0533, 0.0533, 0.0226],\n",
            "        [0.0417, 0.0353, 0.0422,  ..., 0.0281, 0.0281, 0.0393],\n",
            "        [0.0095, 0.0104, 0.3175,  ..., 0.0171, 0.0171, 0.0767],\n",
            "        ...,\n",
            "        [0.0484, 0.0915, 0.0269,  ..., 0.0196, 0.0196, 0.0128],\n",
            "        [0.0484, 0.0915, 0.0269,  ..., 0.0196, 0.0196, 0.0128],\n",
            "        [0.0188, 0.0708, 0.0552,  ..., 0.0290, 0.0290, 0.0290]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 3\n",
            "0.7220718264579773\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0041, 0.1218, 0.0263,  ..., 0.0147, 0.0127, 0.0147],\n",
            "        [0.0551, 0.0208, 0.0394,  ..., 0.0257, 0.0206, 0.0257],\n",
            "        [0.0104, 0.0521, 0.0243,  ..., 0.0208, 0.0275, 0.0208],\n",
            "        ...,\n",
            "        [0.0250, 0.0171, 0.0750,  ..., 0.0181, 0.0208, 0.0181],\n",
            "        [0.0047, 0.0394, 0.0146,  ..., 0.0050, 0.0287, 0.0050],\n",
            "        [0.0250, 0.0171, 0.0750,  ..., 0.0181, 0.0208, 0.0181]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 3\n",
            "0.6237944960594177\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0325, 0.0067, 0.0070,  ..., 0.0058, 0.0088, 0.0059],\n",
            "        [0.0600, 0.2375, 0.0035,  ..., 0.0068, 0.0024, 0.0027],\n",
            "        [0.0116, 0.0177, 0.2425,  ..., 0.0223, 0.0228, 0.0255],\n",
            "        ...,\n",
            "        [0.0147, 0.0106, 0.0284,  ..., 0.0052, 0.0190, 0.0545],\n",
            "        [0.0267, 0.0273, 0.0252,  ..., 0.0176, 0.0237, 0.0337],\n",
            "        [0.0176, 0.0078, 0.1622,  ..., 0.0098, 0.0134, 0.1412]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 3\n",
            "0.6848192811012268\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0202, 0.0389, 0.1385,  ..., 0.0210, 0.0208, 0.0225],\n",
            "        [0.0642, 0.0282, 0.0065,  ..., 0.0206, 0.0768, 0.0239],\n",
            "        [0.0668, 0.0335, 0.0065,  ..., 0.0035, 0.1282, 0.0038],\n",
            "        ...,\n",
            "        [0.0292, 0.0321, 0.0233,  ..., 0.0107, 0.0781, 0.0560],\n",
            "        [0.0255, 0.0201, 0.0038,  ..., 0.0110, 0.1203, 0.0149],\n",
            "        [0.0315, 0.0323, 0.0237,  ..., 0.0139, 0.0663, 0.0158]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 3\n",
            "0.6794108748435974\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0195, 0.0455, 0.0169,  ..., 0.0388, 0.0388, 0.0168],\n",
            "        [0.0311, 0.0228, 0.0288,  ..., 0.0193, 0.0193, 0.0351],\n",
            "        [0.0388, 0.0131, 0.0087,  ..., 0.0138, 0.0138, 0.0399],\n",
            "        ...,\n",
            "        [0.0175, 0.0462, 0.0177,  ..., 0.0889, 0.0889, 0.0216],\n",
            "        [0.0175, 0.0462, 0.0177,  ..., 0.0889, 0.0889, 0.0216],\n",
            "        [0.0143, 0.0193, 0.0304,  ..., 0.0141, 0.0141, 0.0206]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 3\n",
            "0.8034764528274536\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0214, 0.0412, 0.0191,  ..., 0.0222, 0.0309, 0.0234],\n",
            "        [0.0400, 0.0324, 0.0120,  ..., 0.2747, 0.0105, 0.0180],\n",
            "        [0.0091, 0.0229, 0.0093,  ..., 0.0254, 0.0197, 0.0185],\n",
            "        ...,\n",
            "        [0.0361, 0.0158, 0.0318,  ..., 0.0131, 0.0114, 0.0138],\n",
            "        [0.0162, 0.0273, 0.0160,  ..., 0.0047, 0.0038, 0.0182],\n",
            "        [0.0220, 0.0212, 0.0217,  ..., 0.0147, 0.0156, 0.1353]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 3\n",
            "0.7476557493209839\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0189, 0.0084, 0.0058,  ..., 0.0042, 0.0072, 0.0023],\n",
            "        [0.0525, 0.0524, 0.0202,  ..., 0.0125, 0.0276, 0.0161],\n",
            "        [0.0199, 0.0307, 0.0120,  ..., 0.0252, 0.0170, 0.0288],\n",
            "        ...,\n",
            "        [0.0055, 0.0076, 0.0068,  ..., 0.0085, 0.0077, 0.0042],\n",
            "        [0.0309, 0.0519, 0.0205,  ..., 0.0261, 0.0499, 0.0600],\n",
            "        [0.0075, 0.0181, 0.0164,  ..., 0.0182, 0.0155, 0.2662]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 3\n",
            "0.6822918057441711\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0046, 0.0086, 0.1399,  ..., 0.0410, 0.0630, 0.0086],\n",
            "        [0.0053, 0.0187, 0.0476,  ..., 0.0061, 0.0038, 0.0187],\n",
            "        [0.0216, 0.0373, 0.0076,  ..., 0.0249, 0.0166, 0.0373],\n",
            "        ...,\n",
            "        [0.0189, 0.0137, 0.2680,  ..., 0.0222, 0.0156, 0.0137],\n",
            "        [0.0504, 0.0283, 0.0153,  ..., 0.0134, 0.1116, 0.0283],\n",
            "        [0.0053, 0.0187, 0.0476,  ..., 0.0061, 0.0038, 0.0187]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 3\n",
            "0.6938298940658569\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0155, 0.0411, 0.0106,  ..., 0.0195, 0.0229, 0.0375],\n",
            "        [0.0168, 0.0272, 0.0236,  ..., 0.0294, 0.0631, 0.0636],\n",
            "        [0.0352, 0.0295, 0.0380,  ..., 0.0155, 0.0335, 0.0128],\n",
            "        ...,\n",
            "        [0.0838, 0.0133, 0.0193,  ..., 0.1201, 0.0077, 0.0288],\n",
            "        [0.0166, 0.0592, 0.0525,  ..., 0.0609, 0.0370, 0.0471],\n",
            "        [0.0028, 0.0012, 0.0028,  ..., 0.0507, 0.0017, 0.2477]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 3\n",
            "0.6514162421226501\n",
            "one attention pattern developping during training\n",
            "tensor([[0.3401, 0.0144, 0.0114,  ..., 0.0102, 0.0184, 0.0114],\n",
            "        [0.0083, 0.0107, 0.0214,  ..., 0.0170, 0.0209, 0.0214],\n",
            "        [0.0135, 0.0635, 0.0148,  ..., 0.0253, 0.0144, 0.0148],\n",
            "        ...,\n",
            "        [0.0234, 0.0166, 0.0250,  ..., 0.0378, 0.0213, 0.0250],\n",
            "        [0.0065, 0.0166, 0.0437,  ..., 0.0119, 0.0424, 0.0437],\n",
            "        [0.0135, 0.0635, 0.0148,  ..., 0.0253, 0.0144, 0.0148]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 3\n",
            "0.6567381620407104\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0205, 0.0252, 0.0388,  ..., 0.0625, 0.0423, 0.0695],\n",
            "        [0.0161, 0.0162, 0.0273,  ..., 0.0211, 0.0197, 0.0198],\n",
            "        [0.0297, 0.0264, 0.0672,  ..., 0.0234, 0.0304, 0.0833],\n",
            "        ...,\n",
            "        [0.0100, 0.0017, 0.0282,  ..., 0.0071, 0.0068, 0.0041],\n",
            "        [0.0017, 0.0012, 0.0009,  ..., 0.0009, 0.0003, 0.0022],\n",
            "        [0.0146, 0.0211, 0.0177,  ..., 0.0119, 0.0055, 0.1125]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 3\n",
            "0.6498784422874451\n",
            "one attention pattern developping during training\n",
            "tensor([[0.2995, 0.0069, 0.0042,  ..., 0.0051, 0.0187, 0.0100],\n",
            "        [0.0347, 0.0057, 0.0094,  ..., 0.0045, 0.0090, 0.0536],\n",
            "        [0.0402, 0.0089, 0.0061,  ..., 0.0178, 0.0164, 0.0118],\n",
            "        ...,\n",
            "        [0.0308, 0.0237, 0.0209,  ..., 0.0141, 0.0192, 0.0196],\n",
            "        [0.0200, 0.0213, 0.0660,  ..., 0.0243, 0.0323, 0.0290],\n",
            "        [0.0419, 0.0174, 0.0117,  ..., 0.0396, 0.0315, 0.0124]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 3\n",
            "0.6699057817459106\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0801, 0.0609, 0.0699, 0.2201, 0.2012, 0.0558, 0.1698, 0.1422],\n",
            "        [0.0438, 0.2909, 0.0795, 0.1109, 0.0316, 0.0836, 0.1718, 0.1879],\n",
            "        [0.1959, 0.1237, 0.1252, 0.1245, 0.1514, 0.1760, 0.0768, 0.0265],\n",
            "        [0.1027, 0.0312, 0.0275, 0.4631, 0.1350, 0.0547, 0.0350, 0.1508],\n",
            "        [0.3396, 0.0346, 0.0503, 0.1258, 0.1451, 0.0713, 0.1888, 0.0445],\n",
            "        [0.1200, 0.0835, 0.2377, 0.1979, 0.0758, 0.0888, 0.1538, 0.0424],\n",
            "        [0.1162, 0.1651, 0.1017, 0.1602, 0.1871, 0.0991, 0.1319, 0.0389],\n",
            "        [0.2044, 0.0628, 0.0782, 0.3010, 0.0891, 0.1189, 0.0580, 0.0876]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 4\n",
            "0.6629999876022339\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0116, 0.0059, 0.0047,  ..., 0.0265, 0.0088, 0.0089],\n",
            "        [0.0065, 0.0785, 0.0321,  ..., 0.0140, 0.0160, 0.0181],\n",
            "        [0.0264, 0.0022, 0.0079,  ..., 0.0192, 0.0070, 0.0273],\n",
            "        ...,\n",
            "        [0.0164, 0.0153, 0.0159,  ..., 0.0219, 0.0340, 0.0174],\n",
            "        [0.0370, 0.0270, 0.0235,  ..., 0.0264, 0.0448, 0.0310],\n",
            "        [0.0262, 0.0391, 0.0195,  ..., 0.0374, 0.0268, 0.0408]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 4\n",
            "0.6809971332550049\n",
            "one attention pattern developping during training\n",
            "tensor([[0.1448, 0.0387, 0.0256,  ..., 0.0146, 0.0146, 0.0254],\n",
            "        [0.0282, 0.0123, 0.0171,  ..., 0.0413, 0.0281, 0.0115],\n",
            "        [0.0214, 0.0203, 0.0236,  ..., 0.0474, 0.0284, 0.0298],\n",
            "        ...,\n",
            "        [0.0183, 0.0203, 0.0209,  ..., 0.0300, 0.0119, 0.0074],\n",
            "        [0.0163, 0.0101, 0.0150,  ..., 0.0168, 0.0200, 0.0151],\n",
            "        [0.0116, 0.0174, 0.0096,  ..., 0.0169, 0.0121, 0.0141]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 4\n",
            "0.6413131952285767\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0192, 0.0053, 0.0086,  ..., 0.0168, 0.0219, 0.0071],\n",
            "        [0.0226, 0.0565, 0.0256,  ..., 0.0369, 0.0662, 0.0277],\n",
            "        [0.0131, 0.0239, 0.3061,  ..., 0.0175, 0.0067, 0.0195],\n",
            "        ...,\n",
            "        [0.0498, 0.0316, 0.0514,  ..., 0.0245, 0.0188, 0.0390],\n",
            "        [0.0323, 0.0301, 0.0191,  ..., 0.0275, 0.0135, 0.0357],\n",
            "        [0.0600, 0.0152, 0.0504,  ..., 0.0109, 0.0440, 0.0170]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 4\n",
            "0.6349179744720459\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0313, 0.0256, 0.0174,  ..., 0.0459, 0.0113, 0.0223],\n",
            "        [0.0443, 0.1096, 0.0260,  ..., 0.0294, 0.0242, 0.0212],\n",
            "        [0.0114, 0.1941, 0.0084,  ..., 0.0200, 0.0206, 0.0137],\n",
            "        ...,\n",
            "        [0.1198, 0.0108, 0.0254,  ..., 0.0058, 0.0256, 0.0344],\n",
            "        [0.0400, 0.0352, 0.0165,  ..., 0.0182, 0.0192, 0.0229],\n",
            "        [0.0044, 0.0576, 0.0145,  ..., 0.0225, 0.0114, 0.0093]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 4\n",
            "0.6491243839263916\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0209, 0.0203, 0.0318,  ..., 0.0075, 0.0345, 0.0416],\n",
            "        [0.0233, 0.0102, 0.0240,  ..., 0.0567, 0.1500, 0.0141],\n",
            "        [0.0266, 0.1554, 0.0072,  ..., 0.0990, 0.0299, 0.0885],\n",
            "        ...,\n",
            "        [0.0359, 0.0070, 0.0143,  ..., 0.0990, 0.1606, 0.0313],\n",
            "        [0.0081, 0.0088, 0.0079,  ..., 0.0072, 0.2550, 0.1521],\n",
            "        [0.0281, 0.0336, 0.0171,  ..., 0.0679, 0.0223, 0.0182]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 4\n",
            "0.6936355829238892\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0237, 0.0557, 0.0271,  ..., 0.0238, 0.0306, 0.0246],\n",
            "        [0.0143, 0.0742, 0.0167,  ..., 0.0327, 0.0466, 0.0043],\n",
            "        [0.0228, 0.0374, 0.1695,  ..., 0.0399, 0.0525, 0.0095],\n",
            "        ...,\n",
            "        [0.0124, 0.0062, 0.0126,  ..., 0.0194, 0.0351, 0.0272],\n",
            "        [0.0121, 0.1052, 0.0144,  ..., 0.0190, 0.0062, 0.0616],\n",
            "        [0.0203, 0.0976, 0.0226,  ..., 0.0184, 0.0081, 0.0253]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 4\n",
            "0.5844860076904297\n",
            "one attention pattern developping during training\n",
            "tensor([[0.3532, 0.0071, 0.0198,  ..., 0.0144, 0.0096, 0.0235],\n",
            "        [0.0268, 0.1474, 0.0055,  ..., 0.0117, 0.2670, 0.0039],\n",
            "        [0.0175, 0.0104, 0.0389,  ..., 0.2141, 0.0132, 0.0332],\n",
            "        ...,\n",
            "        [0.0057, 0.0347, 0.0186,  ..., 0.0591, 0.0152, 0.0250],\n",
            "        [0.0280, 0.0322, 0.0191,  ..., 0.0371, 0.0178, 0.0187],\n",
            "        [0.1809, 0.0201, 0.0505,  ..., 0.0148, 0.0134, 0.0409]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 4\n",
            "0.6951574087142944\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0263, 0.0149, 0.0259,  ..., 0.0148, 0.0142, 0.0287],\n",
            "        [0.0356, 0.0281, 0.0220,  ..., 0.0159, 0.0218, 0.0220],\n",
            "        [0.0422, 0.0154, 0.0108,  ..., 0.0332, 0.0107, 0.0385],\n",
            "        ...,\n",
            "        [0.0619, 0.0211, 0.0089,  ..., 0.0108, 0.0103, 0.0288],\n",
            "        [0.0217, 0.0300, 0.0227,  ..., 0.0435, 0.0440, 0.0305],\n",
            "        [0.0143, 0.0206, 0.0140,  ..., 0.0132, 0.0286, 0.0155]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 4\n",
            "0.6940177083015442\n",
            "one attention pattern developping during training\n",
            "tensor([[0.2235, 0.0162, 0.0136,  ..., 0.0189, 0.0148, 0.0165],\n",
            "        [0.0176, 0.1342, 0.0463,  ..., 0.0485, 0.0271, 0.0236],\n",
            "        [0.0326, 0.0168, 0.1593,  ..., 0.0203, 0.0223, 0.0621],\n",
            "        ...,\n",
            "        [0.0191, 0.0149, 0.0092,  ..., 0.0118, 0.0229, 0.0177],\n",
            "        [0.0118, 0.0182, 0.0321,  ..., 0.0140, 0.0163, 0.0165],\n",
            "        [0.0140, 0.0139, 0.0191,  ..., 0.0115, 0.0502, 0.0189]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 4\n",
            "0.6995572447776794\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0020, 0.0061, 0.0790,  ..., 0.0015, 0.0078, 0.2429],\n",
            "        [0.0092, 0.1447, 0.0295,  ..., 0.0146, 0.0146, 0.0445],\n",
            "        [0.0042, 0.0156, 0.1656,  ..., 0.0063, 0.0072, 0.0091],\n",
            "        ...,\n",
            "        [0.0419, 0.0236, 0.0208,  ..., 0.2482, 0.0186, 0.0060],\n",
            "        [0.0602, 0.0244, 0.0128,  ..., 0.0161, 0.0368, 0.0110],\n",
            "        [0.0128, 0.0222, 0.0100,  ..., 0.0050, 0.0176, 0.2953]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 4\n",
            "0.6753833889961243\n",
            "one attention pattern developping during training\n",
            "tensor([[0.3086, 0.0207, 0.0069,  ..., 0.0345, 0.0208, 0.0264],\n",
            "        [0.0665, 0.0230, 0.0318,  ..., 0.0250, 0.0404, 0.1165],\n",
            "        [0.0281, 0.0126, 0.0219,  ..., 0.0114, 0.0335, 0.0407],\n",
            "        ...,\n",
            "        [0.0123, 0.0123, 0.0142,  ..., 0.0070, 0.0319, 0.0579],\n",
            "        [0.0111, 0.0320, 0.0228,  ..., 0.0278, 0.0169, 0.0157],\n",
            "        [0.0083, 0.0249, 0.0106,  ..., 0.0033, 0.0044, 0.0022]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 4\n",
            "0.6822395324707031\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0171, 0.0269, 0.0107,  ..., 0.0134, 0.0110, 0.0122],\n",
            "        [0.0652, 0.2912, 0.0069,  ..., 0.0107, 0.0097, 0.0099],\n",
            "        [0.0260, 0.0202, 0.0132,  ..., 0.0099, 0.0101, 0.0088],\n",
            "        ...,\n",
            "        [0.0368, 0.0418, 0.0148,  ..., 0.0118, 0.0228, 0.0183],\n",
            "        [0.0094, 0.0363, 0.0208,  ..., 0.0058, 0.1107, 0.0031],\n",
            "        [0.0320, 0.0075, 0.0047,  ..., 0.0040, 0.0133, 0.0097]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 4\n",
            "0.642894983291626\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0165, 0.0178, 0.0115,  ..., 0.0306, 0.0281, 0.0145],\n",
            "        [0.0254, 0.0227, 0.0117,  ..., 0.0642, 0.0212, 0.0232],\n",
            "        [0.0391, 0.0255, 0.0042,  ..., 0.0490, 0.0347, 0.0072],\n",
            "        ...,\n",
            "        [0.0232, 0.0142, 0.0060,  ..., 0.0074, 0.0155, 0.0151],\n",
            "        [0.0186, 0.0464, 0.0107,  ..., 0.0237, 0.0105, 0.0184],\n",
            "        [0.1029, 0.0277, 0.0141,  ..., 0.0060, 0.0262, 0.0033]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 4\n",
            "0.6159786581993103\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0145, 0.0142, 0.0103,  ..., 0.0207, 0.0380, 0.0136],\n",
            "        [0.0163, 0.0185, 0.0157,  ..., 0.0171, 0.0113, 0.0044],\n",
            "        [0.0263, 0.0162, 0.0155,  ..., 0.0225, 0.0171, 0.0505],\n",
            "        ...,\n",
            "        [0.0179, 0.0354, 0.0271,  ..., 0.0146, 0.0325, 0.0422],\n",
            "        [0.0091, 0.0361, 0.0280,  ..., 0.0498, 0.0071, 0.1624],\n",
            "        [0.0149, 0.0185, 0.0259,  ..., 0.0186, 0.0815, 0.0138]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 4\n",
            "0.6609255075454712\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0183, 0.0157, 0.0111,  ..., 0.0127, 0.0162, 0.0460],\n",
            "        [0.0262, 0.0161, 0.0154,  ..., 0.0175, 0.0161, 0.0461],\n",
            "        [0.0206, 0.0286, 0.2442,  ..., 0.0370, 0.0184, 0.0273],\n",
            "        ...,\n",
            "        [0.0155, 0.0169, 0.0295,  ..., 0.1122, 0.2288, 0.0377],\n",
            "        [0.0162, 0.0170, 0.0097,  ..., 0.0195, 0.1196, 0.0231],\n",
            "        [0.0291, 0.0144, 0.0087,  ..., 0.0081, 0.0081, 0.2242]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 4\n",
            "0.6265790462493896\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0175, 0.0190, 0.0088,  ..., 0.0275, 0.0098, 0.0172],\n",
            "        [0.0030, 0.0452, 0.2423,  ..., 0.0005, 0.0533, 0.0009],\n",
            "        [0.0188, 0.0123, 0.1144,  ..., 0.0614, 0.0114, 0.0299],\n",
            "        ...,\n",
            "        [0.0239, 0.0668, 0.0275,  ..., 0.0352, 0.0309, 0.0408],\n",
            "        [0.0226, 0.0310, 0.2516,  ..., 0.0295, 0.0063, 0.0222],\n",
            "        [0.0165, 0.0234, 0.0256,  ..., 0.0447, 0.0250, 0.0306]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 4\n",
            "0.6938856244087219\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0052, 0.0048, 0.0190,  ..., 0.0075, 0.0020, 0.0140],\n",
            "        [0.0127, 0.1235, 0.0170,  ..., 0.0279, 0.0111, 0.0338],\n",
            "        [0.0309, 0.0341, 0.0110,  ..., 0.0228, 0.0375, 0.0234],\n",
            "        ...,\n",
            "        [0.0119, 0.0083, 0.0075,  ..., 0.0303, 0.0019, 0.0014],\n",
            "        [0.0084, 0.0091, 0.0084,  ..., 0.0167, 0.0111, 0.0635],\n",
            "        [0.0100, 0.0166, 0.0155,  ..., 0.0273, 0.0337, 0.0864]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 4\n",
            "0.7587844729423523\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0528, 0.0283, 0.0246,  ..., 0.0248, 0.0736, 0.0175],\n",
            "        [0.0261, 0.1041, 0.0233,  ..., 0.0424, 0.0265, 0.0387],\n",
            "        [0.0614, 0.0228, 0.0232,  ..., 0.0158, 0.0295, 0.0574],\n",
            "        ...,\n",
            "        [0.0065, 0.2301, 0.0421,  ..., 0.0081, 0.0471, 0.0101],\n",
            "        [0.0310, 0.0157, 0.0397,  ..., 0.2644, 0.0267, 0.0132],\n",
            "        [0.0299, 0.0380, 0.0197,  ..., 0.0143, 0.0193, 0.0227]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 4\n",
            "0.5926966667175293\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0072, 0.0195, 0.0042,  ..., 0.0079, 0.0724, 0.0033],\n",
            "        [0.0248, 0.2527, 0.0590,  ..., 0.0141, 0.0082, 0.0154],\n",
            "        [0.0489, 0.0305, 0.0329,  ..., 0.0293, 0.0316, 0.0184],\n",
            "        ...,\n",
            "        [0.0226, 0.0148, 0.0143,  ..., 0.0190, 0.0731, 0.0126],\n",
            "        [0.0232, 0.0077, 0.0131,  ..., 0.0062, 0.3021, 0.0129],\n",
            "        [0.0213, 0.0161, 0.0170,  ..., 0.0293, 0.0213, 0.0220]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 4\n",
            "0.6843446493148804\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0199, 0.0214, 0.0384,  ..., 0.0339, 0.0301, 0.0233],\n",
            "        [0.0240, 0.0323, 0.2629,  ..., 0.0261, 0.0284, 0.0240],\n",
            "        [0.0153, 0.0093, 0.3228,  ..., 0.0241, 0.0130, 0.0230],\n",
            "        ...,\n",
            "        [0.0249, 0.0150, 0.0322,  ..., 0.0283, 0.1987, 0.0391],\n",
            "        [0.0367, 0.0148, 0.0288,  ..., 0.0094, 0.0531, 0.0307],\n",
            "        [0.0355, 0.0139, 0.0205,  ..., 0.0214, 0.0199, 0.0435]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 4\n",
            "0.5955970287322998\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0245, 0.0673, 0.0946,  ..., 0.0097, 0.0209, 0.0124],\n",
            "        [0.0089, 0.1840, 0.0040,  ..., 0.0210, 0.0155, 0.0215],\n",
            "        [0.0103, 0.0151, 0.0144,  ..., 0.0559, 0.0192, 0.0164],\n",
            "        ...,\n",
            "        [0.0093, 0.0035, 0.0056,  ..., 0.2082, 0.0072, 0.0050],\n",
            "        [0.0039, 0.0097, 0.0036,  ..., 0.0075, 0.0035, 0.0177],\n",
            "        [0.0380, 0.0214, 0.0167,  ..., 0.0171, 0.0413, 0.0278]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 4\n",
            "0.6740014553070068\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0123, 0.0283, 0.0130,  ..., 0.0282, 0.0496, 0.0059],\n",
            "        [0.0061, 0.0172, 0.0376,  ..., 0.0393, 0.0199, 0.0253],\n",
            "        [0.0162, 0.0189, 0.0457,  ..., 0.0152, 0.0151, 0.0274],\n",
            "        ...,\n",
            "        [0.1556, 0.0219, 0.0282,  ..., 0.0218, 0.0317, 0.0180],\n",
            "        [0.0404, 0.0252, 0.0296,  ..., 0.0219, 0.0099, 0.0220],\n",
            "        [0.0118, 0.0312, 0.0415,  ..., 0.0261, 0.0117, 0.0167]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 4\n",
            "0.6408542394638062\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0297, 0.0190, 0.0320,  ..., 0.0216, 0.0302, 0.0254],\n",
            "        [0.0281, 0.1327, 0.0534,  ..., 0.0359, 0.0313, 0.0162],\n",
            "        [0.0024, 0.0107, 0.3075,  ..., 0.0177, 0.0277, 0.0162],\n",
            "        ...,\n",
            "        [0.0174, 0.0083, 0.0212,  ..., 0.0485, 0.0465, 0.0182],\n",
            "        [0.2710, 0.2531, 0.0053,  ..., 0.0008, 0.0009, 0.0017],\n",
            "        [0.0072, 0.0111, 0.0350,  ..., 0.0322, 0.0511, 0.0180]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 4\n",
            "0.664172887802124\n",
            "one attention pattern developping during training\n",
            "tensor([[0.3415, 0.0062, 0.0055,  ..., 0.0102, 0.0161, 0.0049],\n",
            "        [0.3375, 0.0067, 0.0322,  ..., 0.0228, 0.0041, 0.0070],\n",
            "        [0.0105, 0.0323, 0.0300,  ..., 0.0230, 0.0258, 0.0522],\n",
            "        ...,\n",
            "        [0.0139, 0.0501, 0.0216,  ..., 0.0173, 0.0564, 0.0245],\n",
            "        [0.0256, 0.0116, 0.0251,  ..., 0.0278, 0.0254, 0.0700],\n",
            "        [0.0092, 0.0318, 0.0509,  ..., 0.0373, 0.0370, 0.1102]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 4\n",
            "0.6849658489227295\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0248, 0.0055, 0.0167,  ..., 0.0057, 0.0516, 0.0144],\n",
            "        [0.0147, 0.0101, 0.0088,  ..., 0.1457, 0.0529, 0.2099],\n",
            "        [0.0283, 0.0159, 0.0166,  ..., 0.0647, 0.0417, 0.0976],\n",
            "        ...,\n",
            "        [0.1456, 0.0091, 0.0080,  ..., 0.3622, 0.0150, 0.0175],\n",
            "        [0.0412, 0.0248, 0.0110,  ..., 0.0081, 0.1196, 0.0356],\n",
            "        [0.0387, 0.0069, 0.0121,  ..., 0.0279, 0.0157, 0.0077]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 4\n",
            "0.6364532113075256\n",
            "one attention pattern developping during training\n",
            "tensor([[0.1642, 0.0130, 0.0130,  ..., 0.0144, 0.0179, 0.0108],\n",
            "        [0.0707, 0.0143, 0.0095,  ..., 0.0306, 0.0192, 0.0175],\n",
            "        [0.0110, 0.0314, 0.0249,  ..., 0.1136, 0.0106, 0.0073],\n",
            "        ...,\n",
            "        [0.0155, 0.0379, 0.0074,  ..., 0.2732, 0.0194, 0.0063],\n",
            "        [0.0184, 0.0216, 0.0231,  ..., 0.0670, 0.0165, 0.0131],\n",
            "        [0.0111, 0.0154, 0.0341,  ..., 0.0272, 0.0120, 0.0132]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 4\n",
            "0.7687970399856567\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0163, 0.0228, 0.0119,  ..., 0.0126, 0.0115, 0.0119],\n",
            "        [0.0096, 0.0197, 0.0180,  ..., 0.0277, 0.0054, 0.0180],\n",
            "        [0.0237, 0.0246, 0.0262,  ..., 0.0328, 0.0107, 0.0262],\n",
            "        ...,\n",
            "        [0.0075, 0.0098, 0.0666,  ..., 0.0036, 0.0240, 0.0666],\n",
            "        [0.1345, 0.0142, 0.0381,  ..., 0.0147, 0.0154, 0.0381],\n",
            "        [0.0237, 0.0246, 0.0262,  ..., 0.0328, 0.0107, 0.0262]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 4\n",
            "0.6223022937774658\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0102, 0.0092, 0.0057,  ..., 0.0077, 0.0267, 0.0129],\n",
            "        [0.0245, 0.0186, 0.0450,  ..., 0.0320, 0.0185, 0.0187],\n",
            "        [0.0725, 0.0267, 0.2635,  ..., 0.0071, 0.0916, 0.0044],\n",
            "        ...,\n",
            "        [0.0091, 0.0064, 0.0020,  ..., 0.0040, 0.0127, 0.0082],\n",
            "        [0.0162, 0.0387, 0.0351,  ..., 0.0203, 0.1658, 0.0148],\n",
            "        [0.0170, 0.0444, 0.0207,  ..., 0.0264, 0.0296, 0.0345]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 4\n",
            "0.6004207730293274\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0116, 0.0214, 0.0197,  ..., 0.0371, 0.0074, 0.0201],\n",
            "        [0.0121, 0.0214, 0.0285,  ..., 0.0377, 0.0219, 0.0109],\n",
            "        [0.0249, 0.0174, 0.1663,  ..., 0.0561, 0.0032, 0.0068],\n",
            "        ...,\n",
            "        [0.0105, 0.0679, 0.0154,  ..., 0.3119, 0.0152, 0.0041],\n",
            "        [0.0027, 0.0031, 0.0027,  ..., 0.0010, 0.1013, 0.0246],\n",
            "        [0.0153, 0.0246, 0.0345,  ..., 0.0111, 0.0281, 0.0140]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 4\n",
            "0.6895977854728699\n",
            "one attention pattern developping during training\n",
            "tensor([[0.3672, 0.0076, 0.0034,  ..., 0.0348, 0.0043, 0.0173],\n",
            "        [0.0324, 0.0209, 0.0427,  ..., 0.1198, 0.0596, 0.0154],\n",
            "        [0.4720, 0.0129, 0.0014,  ..., 0.0847, 0.0052, 0.0066],\n",
            "        ...,\n",
            "        [0.0025, 0.0016, 0.2354,  ..., 0.0009, 0.0023, 0.0111],\n",
            "        [0.0107, 0.0155, 0.1361,  ..., 0.0346, 0.0210, 0.0054],\n",
            "        [0.0128, 0.0184, 0.0099,  ..., 0.0251, 0.0128, 0.0355]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 4\n",
            "0.594602644443512\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0041, 0.1283, 0.0100,  ..., 0.0150, 0.0100, 0.0033],\n",
            "        [0.0475, 0.0444, 0.0360,  ..., 0.0109, 0.0360, 0.0172],\n",
            "        [0.0113, 0.0154, 0.0232,  ..., 0.0120, 0.0232, 0.0172],\n",
            "        ...,\n",
            "        [0.0046, 0.0901, 0.0049,  ..., 0.0108, 0.0049, 0.0093],\n",
            "        [0.0113, 0.0154, 0.0232,  ..., 0.0120, 0.0232, 0.0172],\n",
            "        [0.0254, 0.0275, 0.0249,  ..., 0.0169, 0.0249, 0.0180]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 4\n",
            "0.6957151889801025\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0464, 0.1022, 0.1009, 0.0936, 0.3133, 0.1217, 0.1029, 0.1191],\n",
            "        [0.0873, 0.0338, 0.0885, 0.1936, 0.2427, 0.1249, 0.0487, 0.1805],\n",
            "        [0.0323, 0.0793, 0.3879, 0.1784, 0.0394, 0.1089, 0.1168, 0.0569],\n",
            "        [0.1178, 0.1434, 0.2014, 0.0179, 0.3171, 0.0311, 0.0526, 0.1187],\n",
            "        [0.1289, 0.0927, 0.2313, 0.1164, 0.0597, 0.2031, 0.0801, 0.0878],\n",
            "        [0.2389, 0.1035, 0.0964, 0.0070, 0.3973, 0.0197, 0.0599, 0.0772],\n",
            "        [0.1111, 0.0894, 0.1018, 0.1857, 0.0710, 0.0963, 0.2591, 0.0856],\n",
            "        [0.0693, 0.1473, 0.0825, 0.1437, 0.0972, 0.1324, 0.2277, 0.0999]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 5\n",
            "0.6565212607383728\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0218, 0.0385, 0.0240,  ..., 0.0545, 0.0145, 0.0229],\n",
            "        [0.0200, 0.0320, 0.0541,  ..., 0.0305, 0.0200, 0.0093],\n",
            "        [0.2489, 0.0089, 0.0205,  ..., 0.0067, 0.0076, 0.0077],\n",
            "        ...,\n",
            "        [0.0568, 0.0182, 0.0429,  ..., 0.0082, 0.0208, 0.0147],\n",
            "        [0.0031, 0.0041, 0.0036,  ..., 0.0049, 0.1374, 0.0044],\n",
            "        [0.0312, 0.0218, 0.0221,  ..., 0.0252, 0.0138, 0.0051]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 5\n",
            "0.6270406246185303\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0204, 0.0157, 0.0653,  ..., 0.0334, 0.0026, 0.0118],\n",
            "        [0.0372, 0.2969, 0.0064,  ..., 0.0145, 0.0125, 0.0125],\n",
            "        [0.0009, 0.0007, 0.0324,  ..., 0.0028, 0.2726, 0.0067],\n",
            "        ...,\n",
            "        [0.0029, 0.0097, 0.0072,  ..., 0.0066, 0.4625, 0.0077],\n",
            "        [0.0020, 0.2449, 0.0019,  ..., 0.0078, 0.0043, 0.0068],\n",
            "        [0.0333, 0.0093, 0.0129,  ..., 0.0101, 0.0138, 0.0170]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 5\n",
            "0.7052153944969177\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0328, 0.0161, 0.0265,  ..., 0.0413, 0.0409, 0.0386],\n",
            "        [0.0068, 0.2317, 0.0325,  ..., 0.0155, 0.0171, 0.0082],\n",
            "        [0.0115, 0.2335, 0.0073,  ..., 0.0203, 0.0147, 0.0134],\n",
            "        ...,\n",
            "        [0.0235, 0.0194, 0.0359,  ..., 0.0222, 0.0250, 0.0129],\n",
            "        [0.0207, 0.0023, 0.0025,  ..., 0.0306, 0.3189, 0.0094],\n",
            "        [0.0021, 0.0114, 0.0100,  ..., 0.0154, 0.0016, 0.0051]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 5\n",
            "0.6553244590759277\n",
            "one attention pattern developping during training\n",
            "tensor([[0.1486, 0.0204, 0.0117,  ..., 0.0021, 0.0095, 0.0195],\n",
            "        [0.0127, 0.0423, 0.0293,  ..., 0.0392, 0.0230, 0.0178],\n",
            "        [0.0373, 0.0167, 0.0413,  ..., 0.0291, 0.0423, 0.0384],\n",
            "        ...,\n",
            "        [0.1384, 0.0100, 0.0224,  ..., 0.0057, 0.0213, 0.0247],\n",
            "        [0.0032, 0.1762, 0.0033,  ..., 0.0095, 0.0081, 0.0736],\n",
            "        [0.0212, 0.1525, 0.0390,  ..., 0.0260, 0.0124, 0.0684]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 5\n",
            "0.6728327870368958\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0347, 0.0159, 0.0268,  ..., 0.0703, 0.0209, 0.0308],\n",
            "        [0.0155, 0.0087, 0.0116,  ..., 0.0145, 0.0222, 0.0066],\n",
            "        [0.0643, 0.0091, 0.0213,  ..., 0.0267, 0.0186, 0.0184],\n",
            "        ...,\n",
            "        [0.0125, 0.2528, 0.0080,  ..., 0.0033, 0.0050, 0.0161],\n",
            "        [0.0268, 0.2203, 0.0238,  ..., 0.0149, 0.0179, 0.0316],\n",
            "        [0.0064, 0.2733, 0.0085,  ..., 0.0074, 0.0074, 0.0138]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 5\n",
            "0.6260095238685608\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0049, 0.0037, 0.0177,  ..., 0.0030, 0.0076, 0.0047],\n",
            "        [0.0123, 0.3495, 0.0021,  ..., 0.0025, 0.0027, 0.0022],\n",
            "        [0.0229, 0.0274, 0.0163,  ..., 0.0206, 0.1385, 0.0113],\n",
            "        ...,\n",
            "        [0.0098, 0.0216, 0.0120,  ..., 0.0054, 0.0041, 0.0054],\n",
            "        [0.0300, 0.0207, 0.0375,  ..., 0.0111, 0.0178, 0.0175],\n",
            "        [0.0266, 0.0276, 0.0205,  ..., 0.0181, 0.0138, 0.0143]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 5\n",
            "0.6088984608650208\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0591, 0.2065, 0.0139,  ..., 0.0521, 0.0070, 0.0337],\n",
            "        [0.0153, 0.0225, 0.0280,  ..., 0.0996, 0.0088, 0.0193],\n",
            "        [0.0062, 0.2700, 0.0170,  ..., 0.0166, 0.0663, 0.0221],\n",
            "        ...,\n",
            "        [0.0102, 0.0174, 0.0260,  ..., 0.1041, 0.0290, 0.0109],\n",
            "        [0.0109, 0.0188, 0.0275,  ..., 0.0263, 0.0750, 0.0251],\n",
            "        [0.0140, 0.1148, 0.0248,  ..., 0.0151, 0.0388, 0.0146]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 5\n",
            "0.6233770251274109\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0037, 0.0079, 0.0644,  ..., 0.0164, 0.0552, 0.0741],\n",
            "        [0.0292, 0.0526, 0.0097,  ..., 0.0119, 0.0487, 0.0876],\n",
            "        [0.0358, 0.0180, 0.0447,  ..., 0.0122, 0.0146, 0.0635],\n",
            "        ...,\n",
            "        [0.0115, 0.0104, 0.0542,  ..., 0.0120, 0.0150, 0.0607],\n",
            "        [0.0144, 0.0097, 0.0264,  ..., 0.0254, 0.1531, 0.1435],\n",
            "        [0.0009, 0.0004, 0.0115,  ..., 0.0082, 0.2076, 0.1287]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 5\n",
            "0.6380751132965088\n",
            "one attention pattern developping during training\n",
            "tensor([[0.1813, 0.0202, 0.0075,  ..., 0.0122, 0.0384, 0.0125],\n",
            "        [0.0380, 0.3931, 0.0095,  ..., 0.0289, 0.0219, 0.0160],\n",
            "        [0.0214, 0.0175, 0.0151,  ..., 0.0360, 0.0335, 0.0140],\n",
            "        ...,\n",
            "        [0.0006, 0.0048, 0.0039,  ..., 0.0747, 0.0010, 0.0168],\n",
            "        [0.0221, 0.0039, 0.0150,  ..., 0.0266, 0.0374, 0.0918],\n",
            "        [0.0158, 0.0120, 0.0309,  ..., 0.0232, 0.0148, 0.0132]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 5\n",
            "0.6512327790260315\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0527, 0.0169, 0.0238,  ..., 0.0356, 0.0360, 0.0453],\n",
            "        [0.0099, 0.0210, 0.0112,  ..., 0.0388, 0.0253, 0.0060],\n",
            "        [0.0047, 0.1705, 0.0213,  ..., 0.0079, 0.0029, 0.0049],\n",
            "        ...,\n",
            "        [0.0102, 0.0158, 0.0114,  ..., 0.3396, 0.0100, 0.0118],\n",
            "        [0.0385, 0.0148, 0.0245,  ..., 0.0143, 0.0150, 0.0328],\n",
            "        [0.0014, 0.0080, 0.1025,  ..., 0.0014, 0.0056, 0.0004]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 5\n",
            "0.6927208304405212\n",
            "one attention pattern developping during training\n",
            "tensor([[0.2170, 0.0229, 0.0186,  ..., 0.0150, 0.0245, 0.0194],\n",
            "        [0.1907, 0.0028, 0.0021,  ..., 0.0898, 0.0024, 0.0394],\n",
            "        [0.0270, 0.0460, 0.0166,  ..., 0.0147, 0.0203, 0.0154],\n",
            "        ...,\n",
            "        [0.0112, 0.0336, 0.0062,  ..., 0.0153, 0.0113, 0.0073],\n",
            "        [0.0507, 0.0322, 0.0202,  ..., 0.0409, 0.0118, 0.0215],\n",
            "        [0.0124, 0.0135, 0.0198,  ..., 0.0142, 0.2344, 0.0132]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 5\n",
            "0.7323122620582581\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0003, 0.0061, 0.0016,  ..., 0.0028, 0.0023, 0.0008],\n",
            "        [0.0502, 0.0261, 0.0343,  ..., 0.0132, 0.0286, 0.0131],\n",
            "        [0.0186, 0.0278, 0.0134,  ..., 0.0261, 0.0235, 0.0366],\n",
            "        ...,\n",
            "        [0.0286, 0.0100, 0.0092,  ..., 0.0165, 0.0155, 0.0266],\n",
            "        [0.0299, 0.0481, 0.0177,  ..., 0.0353, 0.0300, 0.0180],\n",
            "        [0.0234, 0.0657, 0.0187,  ..., 0.0165, 0.0239, 0.0132]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 5\n",
            "0.6199914216995239\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0396, 0.0536, 0.0117,  ..., 0.0117, 0.0396, 0.0276],\n",
            "        [0.0234, 0.0098, 0.0973,  ..., 0.0973, 0.0234, 0.0231],\n",
            "        [0.0451, 0.0207, 0.0323,  ..., 0.0323, 0.0451, 0.0384],\n",
            "        ...,\n",
            "        [0.0451, 0.0207, 0.0323,  ..., 0.0323, 0.0451, 0.0384],\n",
            "        [0.0396, 0.0536, 0.0117,  ..., 0.0117, 0.0396, 0.0276],\n",
            "        [0.0203, 0.0015, 0.1547,  ..., 0.1547, 0.0203, 0.0011]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 5\n",
            "0.6627938151359558\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0473, 0.0473, 0.0348,  ..., 0.0205, 0.0111, 0.0099],\n",
            "        [0.0473, 0.0473, 0.0348,  ..., 0.0205, 0.0111, 0.0099],\n",
            "        [0.0047, 0.0047, 0.0021,  ..., 0.0320, 0.0094, 0.0252],\n",
            "        ...,\n",
            "        [0.0474, 0.0474, 0.0140,  ..., 0.0036, 0.0306, 0.0131],\n",
            "        [0.0912, 0.0912, 0.0177,  ..., 0.1451, 0.0136, 0.0322],\n",
            "        [0.0227, 0.0227, 0.0417,  ..., 0.0282, 0.0341, 0.0514]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 5\n",
            "0.6560949087142944\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0080, 0.0108, 0.0105,  ..., 0.0099, 0.0643, 0.0048],\n",
            "        [0.0171, 0.0187, 0.0199,  ..., 0.0118, 0.0102, 0.0220],\n",
            "        [0.0034, 0.2233, 0.0045,  ..., 0.0031, 0.0119, 0.0262],\n",
            "        ...,\n",
            "        [0.0307, 0.0248, 0.0262,  ..., 0.0195, 0.0132, 0.0140],\n",
            "        [0.0021, 0.0541, 0.0309,  ..., 0.0033, 0.2389, 0.0148],\n",
            "        [0.0202, 0.0115, 0.0103,  ..., 0.0124, 0.0092, 0.0108]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 5\n",
            "0.6468738913536072\n",
            "one attention pattern developping during training\n",
            "tensor([[2.4572e-01, 4.7983e-04, 2.7444e-02,  ..., 8.6512e-04, 3.2498e-04,\n",
            "         1.8557e-02],\n",
            "        [2.7821e-01, 1.5809e-02, 5.8686e-03,  ..., 2.7292e-02, 7.8151e-03,\n",
            "         3.4916e-02],\n",
            "        [4.8008e-02, 2.1346e-02, 5.0704e-03,  ..., 1.1964e-01, 1.6954e-02,\n",
            "         2.2318e-02],\n",
            "        ...,\n",
            "        [5.0778e-03, 2.1304e-02, 3.2378e-02,  ..., 3.1106e-03, 7.2566e-01,\n",
            "         9.9569e-04],\n",
            "        [1.6203e-03, 1.2836e-03, 2.4304e-01,  ..., 8.9183e-04, 6.3786e-03,\n",
            "         4.6750e-01],\n",
            "        [6.2050e-03, 1.4783e-02, 1.6232e-02,  ..., 1.0588e-02, 2.1938e-03,\n",
            "         3.2467e-01]], grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 5\n",
            "0.6430538892745972\n",
            "one attention pattern developping during training\n",
            "tensor([[0.2480, 0.0029, 0.0018,  ..., 0.0021, 0.0027, 0.0122],\n",
            "        [0.0380, 0.2925, 0.0074,  ..., 0.0064, 0.0033, 0.0122],\n",
            "        [0.1862, 0.0050, 0.0036,  ..., 0.0274, 0.0398, 0.0031],\n",
            "        ...,\n",
            "        [0.0691, 0.0099, 0.0042,  ..., 0.0063, 0.0354, 0.0418],\n",
            "        [0.0065, 0.0208, 0.0173,  ..., 0.0556, 0.0068, 0.2963],\n",
            "        [0.0058, 0.0761, 0.0072,  ..., 0.0048, 0.0032, 0.5467]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 5\n",
            "0.6269989013671875\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0042, 0.0461, 0.0125,  ..., 0.0204, 0.0097, 0.0302],\n",
            "        [0.0089, 0.0160, 0.0323,  ..., 0.0069, 0.0060, 0.0435],\n",
            "        [0.0210, 0.0304, 0.1500,  ..., 0.0099, 0.0280, 0.0163],\n",
            "        ...,\n",
            "        [0.0493, 0.0080, 0.0325,  ..., 0.0163, 0.0180, 0.1878],\n",
            "        [0.0027, 0.0012, 0.0053,  ..., 0.1531, 0.0543, 0.0027],\n",
            "        [0.0166, 0.0342, 0.0488,  ..., 0.0425, 0.0216, 0.0047]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 5\n",
            "0.6649022102355957\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0146, 0.0338, 0.0499,  ..., 0.0344, 0.0362, 0.0191],\n",
            "        [0.0118, 0.2700, 0.2351,  ..., 0.0228, 0.0093, 0.0050],\n",
            "        [0.0106, 0.0234, 0.1734,  ..., 0.0565, 0.0751, 0.0142],\n",
            "        ...,\n",
            "        [0.0161, 0.0128, 0.0471,  ..., 0.0738, 0.0068, 0.0024],\n",
            "        [0.0129, 0.0414, 0.0320,  ..., 0.0317, 0.0151, 0.0122],\n",
            "        [0.1655, 0.0078, 0.0243,  ..., 0.0232, 0.0277, 0.0098]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 5\n",
            "0.663323163986206\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0478, 0.0304, 0.0578,  ..., 0.0174, 0.0239, 0.0145],\n",
            "        [0.0186, 0.0301, 0.0156,  ..., 0.0228, 0.0627, 0.0330],\n",
            "        [0.0011, 0.0010, 0.2742,  ..., 0.0010, 0.0038, 0.0004],\n",
            "        ...,\n",
            "        [0.0301, 0.0239, 0.0763,  ..., 0.0195, 0.0102, 0.0170],\n",
            "        [0.0605, 0.0034, 0.0088,  ..., 0.0104, 0.1102, 0.0043],\n",
            "        [0.0062, 0.0103, 0.3204,  ..., 0.0072, 0.0123, 0.0200]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 5\n",
            "0.6011743545532227\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0109, 0.0031, 0.0065,  ..., 0.0085, 0.0092, 0.0058],\n",
            "        [0.0254, 0.0163, 0.0408,  ..., 0.0327, 0.0376, 0.0215],\n",
            "        [0.0014, 0.0020, 0.0987,  ..., 0.0057, 0.0036, 0.0090],\n",
            "        ...,\n",
            "        [0.0206, 0.0149, 0.0142,  ..., 0.2567, 0.0089, 0.0156],\n",
            "        [0.0048, 0.0236, 0.0187,  ..., 0.0232, 0.0039, 0.2558],\n",
            "        [0.0247, 0.0269, 0.0184,  ..., 0.0386, 0.0176, 0.0155]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 5\n",
            "0.6614255905151367\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0090, 0.0037, 0.0199,  ..., 0.0028, 0.0093, 0.0097],\n",
            "        [0.0134, 0.0239, 0.0277,  ..., 0.0182, 0.0307, 0.1114],\n",
            "        [0.0758, 0.0102, 0.0202,  ..., 0.0165, 0.0203, 0.0222],\n",
            "        ...,\n",
            "        [0.0506, 0.0189, 0.0249,  ..., 0.0130, 0.0345, 0.0790],\n",
            "        [0.0213, 0.0106, 0.0111,  ..., 0.0139, 0.0455, 0.0150],\n",
            "        [0.0207, 0.0197, 0.0192,  ..., 0.0390, 0.0566, 0.0230]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 5\n",
            "0.6134378910064697\n",
            "one attention pattern developping during training\n",
            "tensor([[3.5251e-02, 3.8491e-04, 4.4290e-04,  ..., 6.1166e-04, 1.1656e-04,\n",
            "         1.6947e-04],\n",
            "        [7.6805e-03, 3.9999e-02, 1.6992e-02,  ..., 1.4221e-02, 4.0347e-02,\n",
            "         4.9079e-02],\n",
            "        [5.1189e-03, 5.8564e-02, 3.1242e-03,  ..., 1.2245e-02, 3.7344e-03,\n",
            "         2.1492e-01],\n",
            "        ...,\n",
            "        [2.2358e-02, 8.7956e-02, 2.5178e-02,  ..., 2.3975e-02, 1.5816e-02,\n",
            "         4.6136e-02],\n",
            "        [3.0195e-03, 8.1395e-03, 1.8338e-03,  ..., 4.9123e-03, 8.4741e-03,\n",
            "         2.6682e-03],\n",
            "        [1.6777e-02, 7.3759e-03, 4.3722e-03,  ..., 3.9879e-03, 1.2911e-02,\n",
            "         4.8490e-03]], grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 5\n",
            "0.5100435614585876\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0123, 0.0267, 0.0349,  ..., 0.0255, 0.0363, 0.0357],\n",
            "        [0.0111, 0.0132, 0.1089,  ..., 0.0121, 0.2818, 0.0208],\n",
            "        [0.1161, 0.0235, 0.1231,  ..., 0.0389, 0.0059, 0.0092],\n",
            "        ...,\n",
            "        [0.0054, 0.0185, 0.0182,  ..., 0.0100, 0.0033, 0.0204],\n",
            "        [0.0004, 0.0035, 0.0010,  ..., 0.0127, 0.2484, 0.0003],\n",
            "        [0.0133, 0.0163, 0.0123,  ..., 0.0210, 0.0070, 0.0113]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 5\n",
            "0.6848993301391602\n",
            "one attention pattern developping during training\n",
            "tensor([[0.3026, 0.0094, 0.0059,  ..., 0.0130, 0.0019, 0.0015],\n",
            "        [0.0222, 0.0095, 0.0406,  ..., 0.0209, 0.1052, 0.0172],\n",
            "        [0.0995, 0.0120, 0.0129,  ..., 0.0325, 0.0065, 0.0610],\n",
            "        ...,\n",
            "        [0.1866, 0.0349, 0.0103,  ..., 0.0156, 0.0160, 0.0315],\n",
            "        [0.0022, 0.0016, 0.0024,  ..., 0.0035, 0.0064, 0.0049],\n",
            "        [0.0263, 0.0149, 0.0184,  ..., 0.0262, 0.2762, 0.0123]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 5\n",
            "0.6549791693687439\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0396, 0.0265, 0.0266,  ..., 0.0197, 0.1177, 0.0265],\n",
            "        [0.0347, 0.0153, 0.0292,  ..., 0.0352, 0.0623, 0.0153],\n",
            "        [0.0192, 0.0269, 0.0193,  ..., 0.0379, 0.0265, 0.0269],\n",
            "        ...,\n",
            "        [0.0381, 0.0130, 0.0142,  ..., 0.0518, 0.0166, 0.0130],\n",
            "        [0.0413, 0.0166, 0.0133,  ..., 0.0204, 0.2717, 0.0166],\n",
            "        [0.0347, 0.0153, 0.0292,  ..., 0.0352, 0.0623, 0.0153]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 5\n",
            "0.7763888835906982\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0105, 0.0126, 0.0430,  ..., 0.0220, 0.0353, 0.0216],\n",
            "        [0.0082, 0.0216, 0.0069,  ..., 0.0132, 0.0234, 0.0057],\n",
            "        [0.0090, 0.0055, 0.0162,  ..., 0.0208, 0.0052, 0.0042],\n",
            "        ...,\n",
            "        [0.0244, 0.0105, 0.2676,  ..., 0.0085, 0.0271, 0.0215],\n",
            "        [0.0270, 0.0159, 0.0534,  ..., 0.0267, 0.0091, 0.0139],\n",
            "        [0.0165, 0.0101, 0.0070,  ..., 0.0076, 0.0036, 0.2695]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 5\n",
            "0.5862271785736084\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0033, 0.0107, 0.0314,  ..., 0.0314, 0.0341, 0.0188],\n",
            "        [0.0333, 0.0656, 0.0620,  ..., 0.0456, 0.0160, 0.0379],\n",
            "        [0.0106, 0.0095, 0.0056,  ..., 0.0730, 0.0100, 0.0031],\n",
            "        ...,\n",
            "        [0.0709, 0.0829, 0.0261,  ..., 0.0051, 0.0225, 0.0105],\n",
            "        [0.0190, 0.0646, 0.0339,  ..., 0.0353, 0.0454, 0.0379],\n",
            "        [0.0410, 0.0351, 0.0275,  ..., 0.0406, 0.0330, 0.0200]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 5\n",
            "0.8177464604377747\n",
            "one attention pattern developping during training\n",
            "tensor([[3.0743e-04, 1.2849e-01, 3.8491e-04,  ..., 1.8211e-04, 6.5441e-05,\n",
            "         7.4676e-04],\n",
            "        [2.2968e-02, 6.1429e-03, 4.4210e-02,  ..., 1.7641e-02, 1.7747e-01,\n",
            "         1.6487e-02],\n",
            "        [1.9486e-02, 6.0903e-03, 4.8814e-02,  ..., 2.6158e-02, 1.7781e-01,\n",
            "         9.7258e-03],\n",
            "        ...,\n",
            "        [1.7263e-02, 4.2290e-02, 7.2958e-03,  ..., 1.9586e-02, 4.4086e-02,\n",
            "         4.3711e-02],\n",
            "        [7.0656e-03, 6.8003e-04, 1.2312e-01,  ..., 3.4855e-03, 3.1435e-01,\n",
            "         2.9274e-03],\n",
            "        [1.2242e-02, 1.7174e-02, 1.7049e-02,  ..., 1.5278e-02, 7.0621e-03,\n",
            "         1.9977e-02]], grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 5\n",
            "0.6351389288902283\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0433, 0.0268, 0.0225,  ..., 0.0657, 0.0311, 0.0182],\n",
            "        [0.0132, 0.0509, 0.0252,  ..., 0.0094, 0.0315, 0.0108],\n",
            "        [0.0164, 0.0221, 0.0145,  ..., 0.0058, 0.0284, 0.0198],\n",
            "        ...,\n",
            "        [0.0031, 0.0033, 0.0025,  ..., 0.5562, 0.0058, 0.0013],\n",
            "        [0.0107, 0.0169, 0.0072,  ..., 0.1082, 0.0275, 0.0185],\n",
            "        [0.0083, 0.0143, 0.0063,  ..., 0.0140, 0.0133, 0.0127]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 5\n",
            "0.7202625870704651\n",
            "one attention pattern developping during training\n",
            "tensor([[1.5784e-02, 1.4567e-02, 1.2739e-02,  ..., 5.0792e-02, 3.7964e-02,\n",
            "         4.6151e-02],\n",
            "        [2.7774e-02, 6.4144e-03, 1.8130e-02,  ..., 3.6548e-02, 1.4293e-02,\n",
            "         7.5631e-02],\n",
            "        [1.2637e-02, 1.0879e-02, 1.6260e-02,  ..., 1.8690e-02, 1.9174e-02,\n",
            "         6.6273e-02],\n",
            "        ...,\n",
            "        [3.2339e-03, 2.7073e-04, 4.7625e-03,  ..., 7.5850e-04, 1.4384e-01,\n",
            "         2.7264e-01],\n",
            "        [7.2544e-02, 8.4888e-03, 1.7805e-02,  ..., 3.4155e-02, 2.0888e-02,\n",
            "         1.8653e-02],\n",
            "        [1.5370e-02, 1.5371e-02, 3.5735e-02,  ..., 2.1547e-02, 9.7389e-03,\n",
            "         9.8000e-02]], grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 5\n",
            "0.6261953711509705\n",
            "one attention pattern developping during training\n",
            "tensor([[0.3724, 0.0245, 0.0443, 0.2527, 0.0551, 0.0963, 0.1025, 0.0523],\n",
            "        [0.0519, 0.0589, 0.3207, 0.0774, 0.0725, 0.1098, 0.0908, 0.2180],\n",
            "        [0.4203, 0.0417, 0.0204, 0.2931, 0.0626, 0.0684, 0.0413, 0.0522],\n",
            "        [0.0926, 0.0809, 0.0565, 0.1495, 0.0784, 0.3553, 0.0912, 0.0956],\n",
            "        [0.0271, 0.3208, 0.0622, 0.0563, 0.0168, 0.4064, 0.0731, 0.0374],\n",
            "        [0.0505, 0.1128, 0.0326, 0.2334, 0.2619, 0.1935, 0.0336, 0.0818],\n",
            "        [0.1177, 0.0283, 0.1403, 0.0410, 0.1083, 0.0576, 0.4286, 0.0781],\n",
            "        [0.0449, 0.3223, 0.1691, 0.0284, 0.0042, 0.2542, 0.1731, 0.0038]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 6\n",
            "0.6278840899467468\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0231, 0.0297, 0.0195,  ..., 0.0300, 0.0236, 0.0223],\n",
            "        [0.0433, 0.0114, 0.1182,  ..., 0.0345, 0.0314, 0.0067],\n",
            "        [0.0033, 0.0036, 0.1060,  ..., 0.0016, 0.0041, 0.0045],\n",
            "        ...,\n",
            "        [0.0095, 0.0291, 0.0043,  ..., 0.0091, 0.0335, 0.0086],\n",
            "        [0.0186, 0.0311, 0.0071,  ..., 0.0144, 0.1824, 0.0285],\n",
            "        [0.0253, 0.0273, 0.0295,  ..., 0.0348, 0.0319, 0.0205]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 6\n",
            "0.6452015042304993\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0301, 0.0014, 0.0025,  ..., 0.0026, 0.0106, 0.0369],\n",
            "        [0.0607, 0.1596, 0.0118,  ..., 0.0050, 0.0057, 0.0109],\n",
            "        [0.0538, 0.0185, 0.0072,  ..., 0.0263, 0.0486, 0.0029],\n",
            "        ...,\n",
            "        [0.0390, 0.0338, 0.0142,  ..., 0.0319, 0.0229, 0.0708],\n",
            "        [0.0531, 0.0094, 0.1135,  ..., 0.0168, 0.0127, 0.0382],\n",
            "        [0.1151, 0.0030, 0.0204,  ..., 0.0117, 0.0246, 0.1261]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 6\n",
            "0.6771893501281738\n",
            "one attention pattern developping during training\n",
            "tensor([[0.2746, 0.0045, 0.0123,  ..., 0.0216, 0.0047, 0.0120],\n",
            "        [0.0321, 0.1018, 0.0157,  ..., 0.0380, 0.0065, 0.0197],\n",
            "        [0.0129, 0.0109, 0.0237,  ..., 0.2521, 0.0209, 0.0249],\n",
            "        ...,\n",
            "        [0.0137, 0.0155, 0.0152,  ..., 0.0513, 0.0248, 0.0352],\n",
            "        [0.0370, 0.0149, 0.0304,  ..., 0.0251, 0.0128, 0.0368],\n",
            "        [0.0014, 0.2192, 0.0167,  ..., 0.0074, 0.0080, 0.0029]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 6\n",
            "0.7067339420318604\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0108, 0.0029, 0.0154,  ..., 0.0465, 0.0052, 0.0040],\n",
            "        [0.0057, 0.0010, 0.0229,  ..., 0.0189, 0.1992, 0.0156],\n",
            "        [0.0061, 0.0100, 0.0141,  ..., 0.0135, 0.0083, 0.0124],\n",
            "        ...,\n",
            "        [0.0388, 0.0347, 0.0220,  ..., 0.0186, 0.0213, 0.0136],\n",
            "        [0.0158, 0.0078, 0.0265,  ..., 0.0097, 0.0084, 0.0037],\n",
            "        [0.0484, 0.0190, 0.0422,  ..., 0.0112, 0.0160, 0.0128]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 6\n",
            "0.6505671739578247\n",
            "one attention pattern developping during training\n",
            "tensor([[0.1481, 0.0110, 0.1481,  ..., 0.0124, 0.0464, 0.0211],\n",
            "        [0.0096, 0.0089, 0.0096,  ..., 0.0339, 0.0401, 0.0233],\n",
            "        [0.1481, 0.0110, 0.1481,  ..., 0.0124, 0.0464, 0.0211],\n",
            "        ...,\n",
            "        [0.0473, 0.0184, 0.0473,  ..., 0.0053, 0.0120, 0.0328],\n",
            "        [0.0060, 0.0288, 0.0060,  ..., 0.0363, 0.2543, 0.0285],\n",
            "        [0.0440, 0.0178, 0.0440,  ..., 0.0093, 0.0095, 0.0599]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 6\n",
            "0.5607665181159973\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0143, 0.0139, 0.0143,  ..., 0.0039, 0.1470, 0.1525],\n",
            "        [0.0190, 0.2765, 0.0370,  ..., 0.0190, 0.0105, 0.0360],\n",
            "        [0.0205, 0.1113, 0.0319,  ..., 0.0070, 0.0152, 0.0528],\n",
            "        ...,\n",
            "        [0.0090, 0.0301, 0.0117,  ..., 0.0175, 0.0146, 0.0275],\n",
            "        [0.0513, 0.0561, 0.0264,  ..., 0.1346, 0.0038, 0.0137],\n",
            "        [0.0087, 0.0078, 0.0120,  ..., 0.0048, 0.3163, 0.1477]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 6\n",
            "0.7115699648857117\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0129, 0.0274, 0.0513,  ..., 0.0360, 0.0431, 0.0126],\n",
            "        [0.0292, 0.0534, 0.0606,  ..., 0.0141, 0.1216, 0.0182],\n",
            "        [0.0058, 0.1268, 0.0028,  ..., 0.0170, 0.0055, 0.0119],\n",
            "        ...,\n",
            "        [0.0291, 0.0297, 0.0836,  ..., 0.0303, 0.0253, 0.0488],\n",
            "        [0.0175, 0.1004, 0.0230,  ..., 0.0275, 0.0177, 0.0350],\n",
            "        [0.0327, 0.0130, 0.0205,  ..., 0.0187, 0.0145, 0.0127]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 6\n",
            "0.6168051362037659\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0405, 0.0204, 0.0069,  ..., 0.0110, 0.0256, 0.0133],\n",
            "        [0.0156, 0.0062, 0.0021,  ..., 0.0095, 0.0039, 0.0067],\n",
            "        [0.0099, 0.0301, 0.0080,  ..., 0.0638, 0.0722, 0.0065],\n",
            "        ...,\n",
            "        [0.0108, 0.0180, 0.0058,  ..., 0.3283, 0.0280, 0.0481],\n",
            "        [0.1233, 0.0257, 0.0261,  ..., 0.0288, 0.0253, 0.0302],\n",
            "        [0.0016, 0.0062, 0.0012,  ..., 0.0013, 0.0115, 0.0023]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 6\n",
            "0.6174226999282837\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0087, 0.0137, 0.0259,  ..., 0.0555, 0.0210, 0.0251],\n",
            "        [0.0157, 0.0051, 0.0094,  ..., 0.0423, 0.0449, 0.0139],\n",
            "        [0.0241, 0.0229, 0.1150,  ..., 0.0115, 0.1036, 0.0243],\n",
            "        ...,\n",
            "        [0.0396, 0.1097, 0.0234,  ..., 0.0255, 0.0013, 0.0165],\n",
            "        [0.0003, 0.0017, 0.0063,  ..., 0.0171, 0.0059, 0.0048],\n",
            "        [0.0254, 0.0164, 0.0145,  ..., 0.0454, 0.0043, 0.0239]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 6\n",
            "0.6805216073989868\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0100, 0.0123, 0.0599,  ..., 0.0188, 0.0049, 0.1422],\n",
            "        [0.0121, 0.0092, 0.2368,  ..., 0.1069, 0.0044, 0.0116],\n",
            "        [0.0292, 0.0333, 0.0155,  ..., 0.0267, 0.0214, 0.0139],\n",
            "        ...,\n",
            "        [0.0111, 0.0196, 0.0257,  ..., 0.0089, 0.0269, 0.0188],\n",
            "        [0.0051, 0.0115, 0.0003,  ..., 0.1914, 0.2465, 0.0388],\n",
            "        [0.0162, 0.0031, 0.0562,  ..., 0.0043, 0.0095, 0.0094]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 6\n",
            "0.6482694745063782\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0789, 0.0063, 0.0086,  ..., 0.0115, 0.0086, 0.0538],\n",
            "        [0.0080, 0.2030, 0.0013,  ..., 0.0084, 0.0013, 0.0017],\n",
            "        [0.0024, 0.0012, 0.1182,  ..., 0.0007, 0.1182, 0.0030],\n",
            "        ...,\n",
            "        [0.0065, 0.0101, 0.0159,  ..., 0.0076, 0.0159, 0.0151],\n",
            "        [0.0024, 0.0012, 0.1182,  ..., 0.0007, 0.1182, 0.0030],\n",
            "        [0.0168, 0.0208, 0.0124,  ..., 0.0083, 0.0124, 0.0080]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 6\n",
            "0.6124532222747803\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0831, 0.0376, 0.0103,  ..., 0.0175, 0.0206, 0.0151],\n",
            "        [0.0260, 0.0041, 0.0050,  ..., 0.0107, 0.0091, 0.0094],\n",
            "        [0.0121, 0.0111, 0.0515,  ..., 0.0281, 0.0087, 0.0189],\n",
            "        ...,\n",
            "        [0.0355, 0.0206, 0.0084,  ..., 0.0466, 0.0027, 0.0227],\n",
            "        [0.0162, 0.0087, 0.0121,  ..., 0.0151, 0.0470, 0.0147],\n",
            "        [0.0226, 0.0067, 0.0039,  ..., 0.0107, 0.0207, 0.0161]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 6\n",
            "0.6292463541030884\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0239, 0.0139, 0.0246,  ..., 0.0468, 0.0306, 0.0160],\n",
            "        [0.0071, 0.0138, 0.0048,  ..., 0.0166, 0.0318, 0.0102],\n",
            "        [0.0226, 0.0335, 0.0123,  ..., 0.0292, 0.0452, 0.0249],\n",
            "        ...,\n",
            "        [0.0028, 0.0263, 0.2489,  ..., 0.2505, 0.0032, 0.0029],\n",
            "        [0.0158, 0.0317, 0.0226,  ..., 0.0106, 0.0752, 0.1267],\n",
            "        [0.0267, 0.0135, 0.0549,  ..., 0.0183, 0.0090, 0.0393]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 6\n",
            "0.7405888438224792\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0151, 0.0142, 0.0204,  ..., 0.0182, 0.0040, 0.0007],\n",
            "        [0.0179, 0.0933, 0.0182,  ..., 0.0161, 0.1096, 0.0164],\n",
            "        [0.0046, 0.0126, 0.0580,  ..., 0.1771, 0.0590, 0.0968],\n",
            "        ...,\n",
            "        [0.0040, 0.0088, 0.0155,  ..., 0.2426, 0.0250, 0.0980],\n",
            "        [0.0079, 0.0084, 0.0267,  ..., 0.0563, 0.2237, 0.0338],\n",
            "        [0.0172, 0.0097, 0.0449,  ..., 0.0567, 0.0122, 0.0074]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 6\n",
            "0.6533293724060059\n",
            "one attention pattern developping during training\n",
            "tensor([[0.3074, 0.1052, 0.0014,  ..., 0.0425, 0.0024, 0.0123],\n",
            "        [0.2076, 0.0013, 0.0071,  ..., 0.0025, 0.0053, 0.0015],\n",
            "        [0.0244, 0.0324, 0.0035,  ..., 0.0209, 0.0068, 0.0089],\n",
            "        ...,\n",
            "        [0.1627, 0.0108, 0.0082,  ..., 0.0228, 0.0300, 0.0098],\n",
            "        [0.0093, 0.0357, 0.0194,  ..., 0.0101, 0.0143, 0.0100],\n",
            "        [0.0107, 0.0116, 0.0222,  ..., 0.0305, 0.0214, 0.0134]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 6\n",
            "0.6792852282524109\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0025, 0.0047, 0.0085,  ..., 0.0044, 0.0060, 0.0049],\n",
            "        [0.0297, 0.0759, 0.0076,  ..., 0.0046, 0.0011, 0.0139],\n",
            "        [0.0183, 0.0418, 0.0127,  ..., 0.0224, 0.0107, 0.0135],\n",
            "        ...,\n",
            "        [0.0106, 0.0117, 0.0087,  ..., 0.0084, 0.0273, 0.0211],\n",
            "        [0.0255, 0.0174, 0.0089,  ..., 0.0353, 0.0055, 0.0146],\n",
            "        [0.0061, 0.0066, 0.0292,  ..., 0.0090, 0.0567, 0.0246]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 6\n",
            "0.7607987523078918\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0138, 0.0120, 0.0107,  ..., 0.0066, 0.0352, 0.0123],\n",
            "        [0.0054, 0.0217, 0.0225,  ..., 0.0099, 0.0259, 0.0442],\n",
            "        [0.0191, 0.0034, 0.0044,  ..., 0.0374, 0.0056, 0.0061],\n",
            "        ...,\n",
            "        [0.0266, 0.0490, 0.0274,  ..., 0.0198, 0.0178, 0.0137],\n",
            "        [0.0077, 0.0079, 0.0033,  ..., 0.0456, 0.0082, 0.0446],\n",
            "        [0.0068, 0.0055, 0.0059,  ..., 0.1452, 0.0052, 0.2317]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 6\n",
            "0.6765707731246948\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0127, 0.0083, 0.0201,  ..., 0.0114, 0.2278, 0.0265],\n",
            "        [0.0461, 0.0134, 0.0221,  ..., 0.0129, 0.0318, 0.0218],\n",
            "        [0.0096, 0.0103, 0.0046,  ..., 0.0333, 0.0084, 0.0185],\n",
            "        ...,\n",
            "        [0.0220, 0.0372, 0.0633,  ..., 0.0052, 0.0094, 0.0163],\n",
            "        [0.0207, 0.0050, 0.0174,  ..., 0.0020, 0.0060, 0.0097],\n",
            "        [0.0128, 0.0119, 0.0519,  ..., 0.0198, 0.0146, 0.0255]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 6\n",
            "0.6646834015846252\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0011, 0.2500, 0.2500,  ..., 0.0023, 0.0010, 0.0034],\n",
            "        [0.0506, 0.0013, 0.0013,  ..., 0.0175, 0.0049, 0.0249],\n",
            "        [0.0506, 0.0013, 0.0013,  ..., 0.0175, 0.0049, 0.0249],\n",
            "        ...,\n",
            "        [0.0217, 0.0054, 0.0054,  ..., 0.0100, 0.0171, 0.0292],\n",
            "        [0.0200, 0.0243, 0.0243,  ..., 0.0119, 0.0461, 0.0329],\n",
            "        [0.0116, 0.1301, 0.1301,  ..., 0.0086, 0.0121, 0.1389]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 6\n",
            "0.6395705342292786\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0206, 0.0238, 0.0122,  ..., 0.0105, 0.0135, 0.3903],\n",
            "        [0.0004, 0.2956, 0.0033,  ..., 0.0013, 0.0052, 0.0011],\n",
            "        [0.0150, 0.0493, 0.0041,  ..., 0.0103, 0.0339, 0.0109],\n",
            "        ...,\n",
            "        [0.0122, 0.0209, 0.0218,  ..., 0.0064, 0.0098, 0.2928],\n",
            "        [0.0040, 0.0275, 0.0098,  ..., 0.0027, 0.0947, 0.0014],\n",
            "        [0.0098, 0.0132, 0.0118,  ..., 0.0325, 0.0201, 0.0154]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 6\n",
            "0.6488545536994934\n",
            "one attention pattern developping during training\n",
            "tensor([[0.2345, 0.0120, 0.0103,  ..., 0.0056, 0.0109, 0.0097],\n",
            "        [0.0299, 0.0537, 0.0148,  ..., 0.0220, 0.0064, 0.0093],\n",
            "        [0.0179, 0.0518, 0.0249,  ..., 0.0401, 0.0090, 0.0065],\n",
            "        ...,\n",
            "        [0.0172, 0.0067, 0.0095,  ..., 0.1468, 0.2691, 0.0055],\n",
            "        [0.1080, 0.0110, 0.0050,  ..., 0.0115, 0.0116, 0.0132],\n",
            "        [0.0113, 0.0170, 0.0087,  ..., 0.0203, 0.0080, 0.0073]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 6\n",
            "0.6741997003555298\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0134, 0.0052, 0.0067,  ..., 0.0051, 0.0111, 0.0008],\n",
            "        [0.0097, 0.0155, 0.0220,  ..., 0.0067, 0.0205, 0.0047],\n",
            "        [0.0055, 0.0061, 0.0516,  ..., 0.0109, 0.0016, 0.0043],\n",
            "        ...,\n",
            "        [0.0146, 0.0220, 0.0298,  ..., 0.1036, 0.0118, 0.0085],\n",
            "        [0.0099, 0.0131, 0.0198,  ..., 0.0017, 0.0396, 0.0027],\n",
            "        [0.0166, 0.0097, 0.0082,  ..., 0.0178, 0.0195, 0.1790]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 6\n",
            "0.6128461360931396\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0100, 0.0124, 0.0200,  ..., 0.0057, 0.0041, 0.0047],\n",
            "        [0.0468, 0.0046, 0.0216,  ..., 0.0081, 0.0059, 0.0103],\n",
            "        [0.0615, 0.0065, 0.0114,  ..., 0.0122, 0.0124, 0.0203],\n",
            "        ...,\n",
            "        [0.0306, 0.0233, 0.0249,  ..., 0.0163, 0.0196, 0.0207],\n",
            "        [0.0130, 0.0066, 0.0083,  ..., 0.0082, 0.0126, 0.0070],\n",
            "        [0.0150, 0.0117, 0.0130,  ..., 0.0664, 0.0195, 0.0654]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 6\n",
            "0.6645470857620239\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0138, 0.0219, 0.0060,  ..., 0.0084, 0.0149, 0.0043],\n",
            "        [0.0146, 0.0728, 0.0133,  ..., 0.0067, 0.0081, 0.0272],\n",
            "        [0.0245, 0.0195, 0.0163,  ..., 0.0069, 0.0212, 0.0178],\n",
            "        ...,\n",
            "        [0.0217, 0.0189, 0.0159,  ..., 0.0118, 0.0134, 0.0259],\n",
            "        [0.0156, 0.1631, 0.0007,  ..., 0.0015, 0.0012, 0.0044],\n",
            "        [0.0318, 0.0292, 0.0191,  ..., 0.0426, 0.0272, 0.0482]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 6\n",
            "0.635009229183197\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0116, 0.0016, 0.1823,  ..., 0.0011, 0.0047, 0.0061],\n",
            "        [0.0061, 0.0072, 0.0342,  ..., 0.0120, 0.0204, 0.0250],\n",
            "        [0.0040, 0.0411, 0.0111,  ..., 0.3346, 0.0639, 0.0088],\n",
            "        ...,\n",
            "        [0.0191, 0.0147, 0.0081,  ..., 0.0054, 0.0113, 0.0176],\n",
            "        [0.0333, 0.0430, 0.0275,  ..., 0.0395, 0.0866, 0.0418],\n",
            "        [0.0027, 0.0186, 0.0126,  ..., 0.0076, 0.0047, 0.0021]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 6\n",
            "0.7280733585357666\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0160, 0.0145, 0.0172,  ..., 0.0222, 0.0261, 0.0148],\n",
            "        [0.0096, 0.0057, 0.0048,  ..., 0.0105, 0.0158, 0.0294],\n",
            "        [0.0097, 0.0390, 0.0373,  ..., 0.0195, 0.0262, 0.0358],\n",
            "        ...,\n",
            "        [0.0140, 0.0161, 0.0441,  ..., 0.0297, 0.0258, 0.0255],\n",
            "        [0.0240, 0.0227, 0.0058,  ..., 0.0083, 0.0851, 0.0141],\n",
            "        [0.0239, 0.0155, 0.0347,  ..., 0.0109, 0.0179, 0.0121]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 6\n",
            "0.5896264314651489\n",
            "one attention pattern developping during training\n",
            "tensor([[1.5176e-03, 1.2232e-01, 1.4424e-02,  ..., 9.0584e-02, 1.7147e-02,\n",
            "         2.6746e-02],\n",
            "        [5.3399e-02, 3.0725e-03, 9.0324e-02,  ..., 1.1876e-02, 1.0000e-02,\n",
            "         1.3948e-02],\n",
            "        [1.0570e-03, 8.0424e-04, 2.3470e-01,  ..., 7.4011e-04, 3.6504e-03,\n",
            "         2.4897e-03],\n",
            "        ...,\n",
            "        [3.8489e-02, 1.3416e-02, 2.5476e-02,  ..., 1.8411e-02, 4.3112e-02,\n",
            "         1.1286e-02],\n",
            "        [1.6461e-04, 2.0472e-05, 2.4200e-01,  ..., 8.1521e-04, 3.1385e-05,\n",
            "         3.8314e-03],\n",
            "        [1.1300e-02, 1.3125e-01, 1.8529e-02,  ..., 1.0934e-01, 1.6101e-02,\n",
            "         1.1556e-02]], grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 6\n",
            "0.6819592714309692\n",
            "one attention pattern developping during training\n",
            "tensor([[0.2046, 0.0172, 0.0221,  ..., 0.0274, 0.0144, 0.0302],\n",
            "        [0.0218, 0.0216, 0.0198,  ..., 0.0188, 0.0051, 0.0466],\n",
            "        [0.0243, 0.0380, 0.0045,  ..., 0.0182, 0.0063, 0.0221],\n",
            "        ...,\n",
            "        [0.0195, 0.0124, 0.0788,  ..., 0.0533, 0.0185, 0.0365],\n",
            "        [0.0036, 0.0026, 0.0023,  ..., 0.0481, 0.0026, 0.0262],\n",
            "        [0.0093, 0.0102, 0.0031,  ..., 0.0235, 0.0033, 0.0529]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 6\n",
            "0.6900692582130432\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0065, 0.0084, 0.0056,  ..., 0.1584, 0.0043, 0.0066],\n",
            "        [0.0095, 0.0989, 0.0122,  ..., 0.2473, 0.0099, 0.0128],\n",
            "        [0.0117, 0.0074, 0.0252,  ..., 0.0146, 0.0181, 0.0197],\n",
            "        ...,\n",
            "        [0.0881, 0.0205, 0.0806,  ..., 0.0045, 0.0231, 0.0331],\n",
            "        [0.0050, 0.0318, 0.0137,  ..., 0.4071, 0.0466, 0.0046],\n",
            "        [0.0030, 0.0035, 0.0047,  ..., 0.0073, 0.2270, 0.0037]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 6\n",
            "0.6330843567848206\n",
            "one attention pattern developping during training\n",
            "tensor([[2.6006e-02, 4.1053e-02, 5.2931e-03,  ..., 1.2541e-02, 4.1053e-02,\n",
            "         4.5941e-02],\n",
            "        [3.1667e-02, 8.7394e-03, 1.7023e-02,  ..., 1.3782e-02, 8.7394e-03,\n",
            "         2.2839e-02],\n",
            "        [1.8964e-02, 8.9196e-03, 1.5000e-02,  ..., 7.5598e-03, 8.9196e-03,\n",
            "         8.3198e-03],\n",
            "        ...,\n",
            "        [2.7642e-04, 1.2460e-01, 2.8096e-04,  ..., 5.7657e-05, 1.2460e-01,\n",
            "         1.9345e-05],\n",
            "        [3.1667e-02, 8.7394e-03, 1.7023e-02,  ..., 1.3782e-02, 8.7394e-03,\n",
            "         2.2839e-02],\n",
            "        [1.3963e-02, 2.6901e-02, 4.8636e-02,  ..., 2.0433e-02, 2.6901e-02,\n",
            "         9.2520e-03]], grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 6\n",
            "0.7322561144828796\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0184, 0.0126, 0.0426,  ..., 0.0501, 0.0281, 0.0480],\n",
            "        [0.0255, 0.0104, 0.0411,  ..., 0.0271, 0.1433, 0.0130],\n",
            "        [0.0018, 0.0056, 0.0014,  ..., 0.0016, 0.0019, 0.2074],\n",
            "        ...,\n",
            "        [0.0149, 0.0513, 0.0158,  ..., 0.1032, 0.0168, 0.0279],\n",
            "        [0.0160, 0.0134, 0.0171,  ..., 0.0237, 0.0124, 0.0258],\n",
            "        [0.0027, 0.0017, 0.0126,  ..., 0.0202, 0.0028, 0.2455]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 6\n",
            "0.7653878927230835\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0334, 0.0435, 0.2523, 0.0966, 0.1847, 0.0704, 0.0934, 0.2257],\n",
            "        [0.1582, 0.0337, 0.0712, 0.0868, 0.1390, 0.1766, 0.1020, 0.2326],\n",
            "        [0.0750, 0.0459, 0.0822, 0.0660, 0.0442, 0.0737, 0.4151, 0.1980],\n",
            "        [0.1625, 0.0725, 0.0958, 0.0917, 0.1182, 0.1985, 0.1597, 0.1012],\n",
            "        [0.1077, 0.2221, 0.1831, 0.1303, 0.0179, 0.0602, 0.2093, 0.0693],\n",
            "        [0.1604, 0.2586, 0.1600, 0.0098, 0.0617, 0.0704, 0.0653, 0.2139],\n",
            "        [0.0968, 0.2693, 0.2332, 0.0447, 0.1493, 0.0526, 0.0615, 0.0926],\n",
            "        [0.1654, 0.2873, 0.0592, 0.1535, 0.1590, 0.0643, 0.0411, 0.0702]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 7\n",
            "0.6045187711715698\n",
            "one attention pattern developping during training\n",
            "tensor([[0.2442, 0.0193, 0.0005,  ..., 0.0154, 0.0086, 0.1111],\n",
            "        [0.0875, 0.0245, 0.0312,  ..., 0.0373, 0.0073, 0.0926],\n",
            "        [0.0251, 0.0284, 0.0225,  ..., 0.0164, 0.0136, 0.0369],\n",
            "        ...,\n",
            "        [0.0081, 0.0057, 0.0584,  ..., 0.0112, 0.0212, 0.0179],\n",
            "        [0.0319, 0.0198, 0.0164,  ..., 0.0240, 0.0099, 0.1048],\n",
            "        [0.0279, 0.0219, 0.0173,  ..., 0.0114, 0.0448, 0.0116]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 7\n",
            "0.6604785323143005\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0100, 0.0121, 0.0297,  ..., 0.0336, 0.0189, 0.0151],\n",
            "        [0.0141, 0.0018, 0.0074,  ..., 0.0139, 0.0080, 0.0067],\n",
            "        [0.1127, 0.0061, 0.0497,  ..., 0.0035, 0.0082, 0.1298],\n",
            "        ...,\n",
            "        [0.0873, 0.0256, 0.0067,  ..., 0.0056, 0.0058, 0.0025],\n",
            "        [0.0203, 0.0117, 0.0268,  ..., 0.0276, 0.0095, 0.0152],\n",
            "        [0.0072, 0.0395, 0.0047,  ..., 0.0016, 0.0131, 0.0080]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 7\n",
            "0.7463036775588989\n",
            "one attention pattern developping during training\n",
            "tensor([[2.6121e-02, 6.0337e-02, 1.3030e-02,  ..., 1.8523e-02, 1.8374e-02,\n",
            "         1.6071e-02],\n",
            "        [2.2971e-02, 2.3295e-02, 1.9727e-02,  ..., 6.3650e-02, 7.3742e-03,\n",
            "         4.8788e-03],\n",
            "        [9.2999e-03, 2.6593e-02, 1.0214e-02,  ..., 1.3887e-02, 2.8207e-02,\n",
            "         2.1392e-02],\n",
            "        ...,\n",
            "        [1.7773e-04, 8.0759e-04, 3.3497e-04,  ..., 2.3463e-05, 1.3444e-04,\n",
            "         1.3124e-04],\n",
            "        [1.2780e-02, 6.5461e-03, 7.0061e-03,  ..., 2.8076e-02, 1.3416e-02,\n",
            "         1.8748e-02],\n",
            "        [1.2298e-02, 2.8447e-02, 1.4790e-02,  ..., 2.9172e-02, 4.6185e-02,\n",
            "         8.9153e-03]], grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 7\n",
            "0.6577922701835632\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0623, 0.0557, 0.0315,  ..., 0.0200, 0.0087, 0.0271],\n",
            "        [0.0243, 0.0349, 0.1115,  ..., 0.0407, 0.0215, 0.0370],\n",
            "        [0.1479, 0.0099, 0.0128,  ..., 0.0152, 0.0157, 0.0104],\n",
            "        ...,\n",
            "        [0.0069, 0.0353, 0.0207,  ..., 0.0052, 0.0071, 0.0063],\n",
            "        [0.0061, 0.0046, 0.0066,  ..., 0.0070, 0.0015, 0.0113],\n",
            "        [0.0236, 0.0130, 0.0215,  ..., 0.0122, 0.0027, 0.2712]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 7\n",
            "0.671367883682251\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0155, 0.0235, 0.0593,  ..., 0.0119, 0.0057, 0.0225],\n",
            "        [0.0034, 0.0077, 0.0368,  ..., 0.0063, 0.0044, 0.0027],\n",
            "        [0.0087, 0.0089, 0.3272,  ..., 0.0312, 0.0127, 0.0032],\n",
            "        ...,\n",
            "        [0.0004, 0.0197, 0.2854,  ..., 0.0049, 0.0009, 0.0153],\n",
            "        [0.0172, 0.0123, 0.0070,  ..., 0.0059, 0.0031, 0.0085],\n",
            "        [0.0352, 0.0659, 0.0232,  ..., 0.0242, 0.0141, 0.0391]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 7\n",
            "0.6210007071495056\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0189, 0.0323, 0.0127,  ..., 0.0188, 0.0348, 0.0396],\n",
            "        [0.0171, 0.0978, 0.0105,  ..., 0.0257, 0.0208, 0.0330],\n",
            "        [0.0305, 0.0358, 0.0108,  ..., 0.0161, 0.0118, 0.0246],\n",
            "        ...,\n",
            "        [0.0109, 0.0295, 0.0155,  ..., 0.0073, 0.0114, 0.0073],\n",
            "        [0.0128, 0.0138, 0.0081,  ..., 0.0114, 0.0219, 0.0274],\n",
            "        [0.0053, 0.0042, 0.2424,  ..., 0.0327, 0.0043, 0.0039]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 7\n",
            "0.6607495546340942\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0051, 0.0136, 0.0122,  ..., 0.0258, 0.0091, 0.0325],\n",
            "        [0.0008, 0.1070, 0.0017,  ..., 0.0865, 0.0051, 0.0023],\n",
            "        [0.0032, 0.0061, 0.0073,  ..., 0.0745, 0.0082, 0.0078],\n",
            "        ...,\n",
            "        [0.0045, 0.0017, 0.0003,  ..., 0.3067, 0.0023, 0.0025],\n",
            "        [0.0118, 0.0046, 0.0056,  ..., 0.0566, 0.0076, 0.0371],\n",
            "        [0.0742, 0.0214, 0.0236,  ..., 0.0096, 0.0084, 0.0268]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 7\n",
            "0.6180263161659241\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0102, 0.0150, 0.0187,  ..., 0.0102, 0.1029, 0.0357],\n",
            "        [0.0125, 0.0097, 0.0232,  ..., 0.0125, 0.0623, 0.0217],\n",
            "        [0.0226, 0.0648, 0.0078,  ..., 0.0226, 0.0186, 0.0235],\n",
            "        ...,\n",
            "        [0.0102, 0.0150, 0.0187,  ..., 0.0102, 0.1029, 0.0357],\n",
            "        [0.1091, 0.0088, 0.0024,  ..., 0.1091, 0.0095, 0.0042],\n",
            "        [0.0234, 0.0154, 0.0154,  ..., 0.0234, 0.0117, 0.0406]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 7\n",
            "0.5681055188179016\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0571, 0.0271, 0.0025,  ..., 0.0046, 0.0033, 0.0046],\n",
            "        [0.0219, 0.0157, 0.0271,  ..., 0.0169, 0.0176, 0.0169],\n",
            "        [0.0220, 0.0064, 0.0267,  ..., 0.0430, 0.0157, 0.0430],\n",
            "        ...,\n",
            "        [0.0119, 0.0135, 0.0165,  ..., 0.1062, 0.0088, 0.1062],\n",
            "        [0.0245, 0.0220, 0.0148,  ..., 0.0871, 0.0123, 0.0871],\n",
            "        [0.0119, 0.0135, 0.0165,  ..., 0.1062, 0.0088, 0.1062]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 7\n",
            "0.5824439525604248\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0194, 0.0194, 0.0069,  ..., 0.0617, 0.0041, 0.0190],\n",
            "        [0.0194, 0.0194, 0.0069,  ..., 0.0617, 0.0041, 0.0190],\n",
            "        [0.0155, 0.0155, 0.0050,  ..., 0.1618, 0.0225, 0.0074],\n",
            "        ...,\n",
            "        [0.0078, 0.0078, 0.0124,  ..., 0.2793, 0.1489, 0.0304],\n",
            "        [0.0269, 0.0269, 0.0117,  ..., 0.0138, 0.0069, 0.0364],\n",
            "        [0.0528, 0.0528, 0.0084,  ..., 0.0182, 0.0481, 0.0084]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 7\n",
            "0.659753143787384\n",
            "one attention pattern developping during training\n",
            "tensor([[2.3511e-01, 1.8524e-02, 3.6417e-02,  ..., 2.3539e-02, 1.5284e-02,\n",
            "         1.8524e-02],\n",
            "        [1.6114e-02, 5.4278e-03, 1.0252e-02,  ..., 1.6918e-02, 2.8370e-02,\n",
            "         5.4278e-03],\n",
            "        [9.4668e-03, 3.4893e-02, 2.4794e-01,  ..., 4.1026e-02, 7.6042e-03,\n",
            "         3.4893e-02],\n",
            "        ...,\n",
            "        [1.4065e-04, 1.0379e-04, 3.9262e-04,  ..., 3.8228e-05, 3.8002e-04,\n",
            "         1.0379e-04],\n",
            "        [4.7965e-03, 1.7597e-03, 1.1899e-03,  ..., 7.1074e-03, 2.0738e-03,\n",
            "         1.7597e-03],\n",
            "        [1.6114e-02, 5.4278e-03, 1.0252e-02,  ..., 1.6918e-02, 2.8370e-02,\n",
            "         5.4278e-03]], grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 7\n",
            "0.6328949332237244\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0325, 0.0279, 0.0276,  ..., 0.0221, 0.0271, 0.0110],\n",
            "        [0.0044, 0.0138, 0.0111,  ..., 0.0129, 0.0482, 0.0392],\n",
            "        [0.0063, 0.0100, 0.1545,  ..., 0.0127, 0.0090, 0.0113],\n",
            "        ...,\n",
            "        [0.0107, 0.0209, 0.0151,  ..., 0.0178, 0.1461, 0.0548],\n",
            "        [0.0056, 0.0106, 0.0062,  ..., 0.0153, 0.1003, 0.0090],\n",
            "        [0.0055, 0.0048, 0.0479,  ..., 0.0073, 0.0029, 0.1964]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 7\n",
            "0.6285936832427979\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0030, 0.0063, 0.0201,  ..., 0.0087, 0.0738, 0.0044],\n",
            "        [0.0213, 0.0004, 0.0121,  ..., 0.0008, 0.0455, 0.2507],\n",
            "        [0.0170, 0.0428, 0.0566,  ..., 0.0304, 0.0127, 0.0079],\n",
            "        ...,\n",
            "        [0.0069, 0.0095, 0.0180,  ..., 0.0194, 0.0783, 0.0151],\n",
            "        [0.0079, 0.0106, 0.0041,  ..., 0.0218, 0.1299, 0.0078],\n",
            "        [0.0061, 0.0089, 0.0153,  ..., 0.0157, 0.1466, 0.0025]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 7\n",
            "0.6270428895950317\n",
            "one attention pattern developping during training\n",
            "tensor([[0.1136, 0.0439, 0.0930,  ..., 0.0089, 0.0167, 0.0298],\n",
            "        [0.0234, 0.0021, 0.0125,  ..., 0.0060, 0.0101, 0.0161],\n",
            "        [0.0202, 0.0272, 0.0251,  ..., 0.0138, 0.0281, 0.0256],\n",
            "        ...,\n",
            "        [0.0282, 0.0041, 0.0072,  ..., 0.0983, 0.0113, 0.0050],\n",
            "        [0.0179, 0.0130, 0.0308,  ..., 0.0162, 0.0449, 0.1144],\n",
            "        [0.0133, 0.0085, 0.0090,  ..., 0.0228, 0.0165, 0.0717]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 7\n",
            "0.7069354057312012\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0185, 0.0183, 0.0803,  ..., 0.0361, 0.0126, 0.0640],\n",
            "        [0.0053, 0.0007, 0.0064,  ..., 0.0003, 0.0022, 0.0053],\n",
            "        [0.0252, 0.0062, 0.0004,  ..., 0.1925, 0.0010, 0.0009],\n",
            "        ...,\n",
            "        [0.0482, 0.0106, 0.0254,  ..., 0.1673, 0.0169, 0.0036],\n",
            "        [0.0043, 0.0011, 0.0038,  ..., 0.0008, 0.0014, 0.0037],\n",
            "        [0.0140, 0.0145, 0.0132,  ..., 0.0068, 0.0250, 0.0066]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 7\n",
            "0.5748517513275146\n",
            "one attention pattern developping during training\n",
            "tensor([[0.1056, 0.0191, 0.0158,  ..., 0.0035, 0.0680, 0.0069],\n",
            "        [0.0089, 0.0087, 0.0316,  ..., 0.0129, 0.0439, 0.0190],\n",
            "        [0.0176, 0.0127, 0.0023,  ..., 0.0113, 0.0116, 0.0355],\n",
            "        ...,\n",
            "        [0.0049, 0.0014, 0.0303,  ..., 0.0039, 0.0126, 0.0237],\n",
            "        [0.0011, 0.0005, 0.0195,  ..., 0.0013, 0.0003, 0.0116],\n",
            "        [0.0133, 0.0073, 0.1286,  ..., 0.0194, 0.0211, 0.0184]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 7\n",
            "0.6328250169754028\n",
            "one attention pattern developping during training\n",
            "tensor([[0.2379, 0.0026, 0.0215,  ..., 0.0018, 0.0023, 0.0006],\n",
            "        [0.0333, 0.0301, 0.0170,  ..., 0.1978, 0.0011, 0.0090],\n",
            "        [0.0069, 0.0286, 0.0266,  ..., 0.0089, 0.0116, 0.0272],\n",
            "        ...,\n",
            "        [0.0100, 0.0143, 0.0012,  ..., 0.0008, 0.0022, 0.0474],\n",
            "        [0.0476, 0.0150, 0.0319,  ..., 0.0151, 0.1846, 0.0324],\n",
            "        [0.0024, 0.0007, 0.0003,  ..., 0.0050, 0.0007, 0.0036]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 7\n",
            "0.669549286365509\n",
            "one attention pattern developping during training\n",
            "tensor([[4.9310e-01, 2.1286e-03, 4.0714e-04,  ..., 1.4250e-03, 6.5485e-04,\n",
            "         6.3031e-04],\n",
            "        [1.9983e-02, 1.6112e-02, 1.1904e-02,  ..., 1.1729e-02, 9.8963e-03,\n",
            "         3.0421e-02],\n",
            "        [1.5131e-02, 5.7615e-02, 5.0103e-03,  ..., 5.7066e-03, 5.4828e-03,\n",
            "         2.6988e-02],\n",
            "        ...,\n",
            "        [5.8579e-03, 5.9073e-03, 1.4467e-02,  ..., 6.2209e-03, 1.7143e-02,\n",
            "         2.0853e-02],\n",
            "        [1.8988e-02, 9.5344e-04, 1.0958e-03,  ..., 2.3207e-03, 2.7225e-03,\n",
            "         2.4137e-03],\n",
            "        [1.5757e-01, 9.5303e-03, 1.4592e-01,  ..., 1.6485e-02, 1.3456e-02,\n",
            "         1.1494e-02]], grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 7\n",
            "0.7009593844413757\n",
            "one attention pattern developping during training\n",
            "tensor([[0.2506, 0.0286, 0.0050,  ..., 0.0068, 0.0067, 0.0369],\n",
            "        [0.2053, 0.0018, 0.1057,  ..., 0.0008, 0.0113, 0.0069],\n",
            "        [0.1636, 0.0311, 0.0271,  ..., 0.0041, 0.0267, 0.0463],\n",
            "        ...,\n",
            "        [0.0475, 0.0050, 0.0550,  ..., 0.0124, 0.0133, 0.0216],\n",
            "        [0.0562, 0.0291, 0.0268,  ..., 0.0138, 0.0094, 0.0390],\n",
            "        [0.0877, 0.0109, 0.0980,  ..., 0.0175, 0.0245, 0.0072]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 7\n",
            "0.6938068270683289\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0215, 0.0690, 0.0163,  ..., 0.0158, 0.0128, 0.0224],\n",
            "        [0.0197, 0.0042, 0.0192,  ..., 0.0316, 0.0363, 0.0122],\n",
            "        [0.0199, 0.0222, 0.0330,  ..., 0.0194, 0.0153, 0.0194],\n",
            "        ...,\n",
            "        [0.0110, 0.0069, 0.0131,  ..., 0.0260, 0.0307, 0.0120],\n",
            "        [0.0097, 0.0012, 0.0426,  ..., 0.0346, 0.0404, 0.0034],\n",
            "        [0.0243, 0.0323, 0.0270,  ..., 0.0189, 0.0143, 0.0203]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 7\n",
            "0.7378393411636353\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0455, 0.0298, 0.0247,  ..., 0.0164, 0.0211, 0.0159],\n",
            "        [0.0004, 0.2497, 0.0021,  ..., 0.0012, 0.0007, 0.0007],\n",
            "        [0.0130, 0.0811, 0.0012,  ..., 0.0079, 0.0012, 0.0047],\n",
            "        ...,\n",
            "        [0.0047, 0.0059, 0.0041,  ..., 0.3106, 0.0023, 0.0010],\n",
            "        [0.0176, 0.0081, 0.0104,  ..., 0.0206, 0.0157, 0.0155],\n",
            "        [0.0006, 0.2397, 0.0004,  ..., 0.0113, 0.0009, 0.0007]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 7\n",
            "0.6509981155395508\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0034, 0.0138, 0.0171,  ..., 0.0034, 0.0238, 0.0079],\n",
            "        [0.0236, 0.0050, 0.0126,  ..., 0.0236, 0.0480, 0.0255],\n",
            "        [0.1591, 0.0229, 0.0150,  ..., 0.1591, 0.0069, 0.0309],\n",
            "        ...,\n",
            "        [0.0034, 0.0138, 0.0171,  ..., 0.0034, 0.0238, 0.0079],\n",
            "        [0.0018, 0.0233, 0.0199,  ..., 0.0018, 0.0406, 0.0108],\n",
            "        [0.0059, 0.0094, 0.0101,  ..., 0.0059, 0.0083, 0.0100]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 7\n",
            "0.6004443168640137\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0340, 0.0173, 0.0187,  ..., 0.0187, 0.0761, 0.0898],\n",
            "        [0.0334, 0.0280, 0.1278,  ..., 0.0718, 0.0650, 0.0042],\n",
            "        [0.0171, 0.0131, 0.2909,  ..., 0.0090, 0.0093, 0.0568],\n",
            "        ...,\n",
            "        [0.0077, 0.0111, 0.0801,  ..., 0.1194, 0.0152, 0.0007],\n",
            "        [0.0036, 0.0067, 0.0026,  ..., 0.0074, 0.0112, 0.0804],\n",
            "        [0.0236, 0.0413, 0.0220,  ..., 0.0245, 0.0162, 0.0092]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 7\n",
            "0.6614827513694763\n",
            "one attention pattern developping during training\n",
            "tensor([[1.2930e-01, 2.0481e-01, 4.5967e-03,  ..., 1.0711e-02, 3.9024e-02,\n",
            "         4.5066e-03],\n",
            "        [2.5742e-03, 3.9460e-02, 1.2797e-01,  ..., 1.9084e-03, 8.9692e-03,\n",
            "         1.1449e-03],\n",
            "        [2.7269e-02, 2.9192e-02, 1.2788e-02,  ..., 2.9289e-02, 2.2836e-03,\n",
            "         8.7426e-03],\n",
            "        ...,\n",
            "        [3.0443e-02, 5.2228e-03, 7.9775e-03,  ..., 7.1914e-03, 5.1890e-02,\n",
            "         3.1940e-03],\n",
            "        [1.3621e-03, 7.2446e-04, 3.9865e-04,  ..., 1.0787e-02, 2.1925e-01,\n",
            "         2.3647e-02],\n",
            "        [2.7491e-03, 2.5944e-03, 8.3476e-04,  ..., 5.2314e-03, 1.4006e-02,\n",
            "         6.2951e-01]], grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 7\n",
            "0.6631131768226624\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0110, 0.0274, 0.0460,  ..., 0.0066, 0.0223, 0.0223],\n",
            "        [0.0638, 0.0311, 0.0083,  ..., 0.1161, 0.0101, 0.0075],\n",
            "        [0.0104, 0.0175, 0.0216,  ..., 0.0105, 0.0253, 0.0075],\n",
            "        ...,\n",
            "        [0.0400, 0.0054, 0.0016,  ..., 0.2479, 0.0028, 0.0026],\n",
            "        [0.0114, 0.0203, 0.0383,  ..., 0.0228, 0.0124, 0.0902],\n",
            "        [0.0163, 0.0139, 0.0281,  ..., 0.0151, 0.0038, 0.0060]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 7\n",
            "0.6733680367469788\n",
            "one attention pattern developping during training\n",
            "tensor([[5.0419e-03, 9.7721e-03, 8.0119e-03,  ..., 2.0539e-02, 4.8938e-03,\n",
            "         1.3487e-02],\n",
            "        [1.2551e-01, 1.2472e-01, 8.4512e-05,  ..., 1.3168e-05, 5.8339e-03,\n",
            "         1.3476e-05],\n",
            "        [2.3317e-03, 1.6453e-02, 2.2389e-03,  ..., 6.1607e-02, 5.4111e-02,\n",
            "         3.5916e-03],\n",
            "        ...,\n",
            "        [3.9249e-02, 1.2627e-02, 4.6187e-02,  ..., 1.1969e-02, 8.4439e-03,\n",
            "         9.4942e-02],\n",
            "        [1.2449e-01, 5.8429e-06, 1.0656e-03,  ..., 4.2446e-05, 7.6687e-03,\n",
            "         2.1224e-04],\n",
            "        [1.2633e-01, 5.6716e-03, 2.9401e-02,  ..., 1.7024e-02, 6.4789e-02,\n",
            "         1.4033e-02]], grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 7\n",
            "0.6806743144989014\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0083, 0.0320, 0.0113,  ..., 0.0801, 0.0050, 0.0590],\n",
            "        [0.0091, 0.0099, 0.0078,  ..., 0.0201, 0.0328, 0.0066],\n",
            "        [0.2519, 0.2499, 0.0016,  ..., 0.0371, 0.0069, 0.0044],\n",
            "        ...,\n",
            "        [0.0139, 0.0329, 0.0280,  ..., 0.0399, 0.0284, 0.0184],\n",
            "        [0.0047, 0.1708, 0.0089,  ..., 0.0197, 0.0055, 0.0157],\n",
            "        [0.0099, 0.0119, 0.0238,  ..., 0.0099, 0.0172, 0.0043]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 7\n",
            "0.7384900450706482\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0042, 0.0159, 0.0147,  ..., 0.0029, 0.0170, 0.0200],\n",
            "        [0.0180, 0.0230, 0.0081,  ..., 0.0451, 0.0073, 0.0382],\n",
            "        [0.1350, 0.0125, 0.2536,  ..., 0.0155, 0.0066, 0.0134],\n",
            "        ...,\n",
            "        [0.0065, 0.0094, 0.0060,  ..., 0.0024, 0.0062, 0.0041],\n",
            "        [0.0055, 0.0013, 0.1358,  ..., 0.0047, 0.2769, 0.0198],\n",
            "        [0.0424, 0.0273, 0.0336,  ..., 0.0235, 0.0259, 0.0121]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 7\n",
            "0.5716097354888916\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0027, 0.0080, 0.0027,  ..., 0.0020, 0.0010, 0.0179],\n",
            "        [0.0062, 0.1406, 0.0062,  ..., 0.0093, 0.0091, 0.0267],\n",
            "        [0.0027, 0.0080, 0.0027,  ..., 0.0020, 0.0010, 0.0179],\n",
            "        ...,\n",
            "        [0.0026, 0.0046, 0.0026,  ..., 0.0005, 0.0014, 0.0282],\n",
            "        [0.0174, 0.0416, 0.0174,  ..., 0.0247, 0.0190, 0.0067],\n",
            "        [0.0633, 0.0335, 0.0633,  ..., 0.0295, 0.0108, 0.0098]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 7\n",
            "0.6365466713905334\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0396, 0.0134, 0.0152,  ..., 0.0164, 0.3684, 0.0698],\n",
            "        [0.0177, 0.0421, 0.0128,  ..., 0.0104, 0.0041, 0.0102],\n",
            "        [0.0124, 0.0045, 0.2330,  ..., 0.0314, 0.0012, 0.0018],\n",
            "        ...,\n",
            "        [0.0228, 0.0037, 0.0035,  ..., 0.2221, 0.0255, 0.2202],\n",
            "        [0.2235, 0.0107, 0.0020,  ..., 0.1640, 0.1904, 0.0352],\n",
            "        [0.1045, 0.0265, 0.0211,  ..., 0.0261, 0.0264, 0.0256]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 7\n",
            "0.5960708260536194\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0596, 0.0522, 0.1842,  ..., 0.0091, 0.0072, 0.0382],\n",
            "        [0.0235, 0.2345, 0.0270,  ..., 0.0169, 0.0132, 0.0078],\n",
            "        [0.0104, 0.0085, 0.0108,  ..., 0.0204, 0.0152, 0.0134],\n",
            "        ...,\n",
            "        [0.0224, 0.0185, 0.0673,  ..., 0.0264, 0.0362, 0.0431],\n",
            "        [0.0064, 0.0012, 0.0062,  ..., 0.0056, 0.1114, 0.0109],\n",
            "        [0.0095, 0.0406, 0.0055,  ..., 0.0078, 0.0084, 0.0125]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 7\n",
            "0.6404073238372803\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0805, 0.0748, 0.0877, 0.1467, 0.0885, 0.2703, 0.1550, 0.0966],\n",
            "        [0.0567, 0.0702, 0.1636, 0.0495, 0.0858, 0.4735, 0.0488, 0.0518],\n",
            "        [0.0454, 0.2000, 0.1361, 0.0381, 0.1086, 0.3414, 0.0850, 0.0455],\n",
            "        [0.1613, 0.2785, 0.0511, 0.0682, 0.0619, 0.3115, 0.0429, 0.0246],\n",
            "        [0.0623, 0.4540, 0.1822, 0.0551, 0.0794, 0.0928, 0.0192, 0.0551],\n",
            "        [0.3255, 0.0823, 0.0344, 0.0417, 0.0458, 0.2751, 0.0595, 0.1356],\n",
            "        [0.1276, 0.2303, 0.1553, 0.0977, 0.0680, 0.1981, 0.0792, 0.0439],\n",
            "        [0.2504, 0.0107, 0.0865, 0.1103, 0.0724, 0.2546, 0.1798, 0.0352]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 8\n",
            "0.5792346596717834\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0044, 0.0090, 0.0078,  ..., 0.0161, 0.0533, 0.0205],\n",
            "        [0.0159, 0.2499, 0.0193,  ..., 0.0005, 0.0028, 0.0005],\n",
            "        [0.0022, 0.0101, 0.0146,  ..., 0.0110, 0.0638, 0.0062],\n",
            "        ...,\n",
            "        [0.0043, 0.1786, 0.0139,  ..., 0.0252, 0.0208, 0.0192],\n",
            "        [0.0252, 0.0301, 0.0238,  ..., 0.0220, 0.0132, 0.0143],\n",
            "        [0.0123, 0.2027, 0.0951,  ..., 0.0022, 0.0074, 0.0031]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 8\n",
            "0.6603944301605225\n",
            "one attention pattern developping during training\n",
            "tensor([[0.2368, 0.0107, 0.0035,  ..., 0.0059, 0.0214, 0.0110],\n",
            "        [0.0298, 0.2136, 0.0574,  ..., 0.0133, 0.0095, 0.0144],\n",
            "        [0.0042, 0.0292, 0.2505,  ..., 0.0199, 0.0044, 0.0065],\n",
            "        ...,\n",
            "        [0.2394, 0.0020, 0.1490,  ..., 0.0003, 0.0035, 0.0027],\n",
            "        [0.0125, 0.0172, 0.0148,  ..., 0.0089, 0.0452, 0.0097],\n",
            "        [0.0051, 0.0026, 0.1272,  ..., 0.0375, 0.0015, 0.0012]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 8\n",
            "0.6552180647850037\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0312, 0.0057, 0.0048,  ..., 0.0263, 0.0063, 0.0159],\n",
            "        [0.0323, 0.2199, 0.0113,  ..., 0.2114, 0.0148, 0.0112],\n",
            "        [0.0117, 0.0117, 0.0064,  ..., 0.1177, 0.0141, 0.0071],\n",
            "        ...,\n",
            "        [0.0135, 0.0065, 0.2802,  ..., 0.0077, 0.0148, 0.0206],\n",
            "        [0.0203, 0.0209, 0.0080,  ..., 0.0176, 0.0036, 0.0038],\n",
            "        [0.0874, 0.0029, 0.0074,  ..., 0.0430, 0.0301, 0.0026]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 8\n",
            "0.6697333455085754\n",
            "one attention pattern developping during training\n",
            "tensor([[1.3676e-02, 2.5450e-02, 2.7488e-02,  ..., 1.6539e-02, 2.2808e-02,\n",
            "         1.2473e-02],\n",
            "        [4.9785e-02, 1.9558e-04, 1.5462e-02,  ..., 1.1650e-05, 1.2093e-03,\n",
            "         2.8694e-05],\n",
            "        [2.0749e-02, 9.5088e-03, 2.5277e-01,  ..., 2.0080e-02, 6.3047e-03,\n",
            "         3.2622e-02],\n",
            "        ...,\n",
            "        [2.9450e-02, 6.7052e-03, 4.4086e-02,  ..., 9.3791e-03, 1.7021e-02,\n",
            "         2.2492e-02],\n",
            "        [7.6958e-03, 1.1961e-02, 1.8794e-01,  ..., 5.7973e-02, 1.2621e-02,\n",
            "         2.8208e-02],\n",
            "        [8.7995e-03, 4.8307e-03, 1.8104e-02,  ..., 6.6171e-02, 3.9256e-03,\n",
            "         1.2737e-01]], grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 8\n",
            "0.5862310528755188\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0021, 0.2505, 0.0766,  ..., 0.0072, 0.0020, 0.5056],\n",
            "        [0.0063, 0.0123, 0.0121,  ..., 0.0046, 0.0133, 0.0214],\n",
            "        [0.0922, 0.0218, 0.0255,  ..., 0.0462, 0.0153, 0.0079],\n",
            "        ...,\n",
            "        [0.0131, 0.0160, 0.0216,  ..., 0.0201, 0.0247, 0.0148],\n",
            "        [0.0058, 0.0070, 0.0126,  ..., 0.0247, 0.1521, 0.0325],\n",
            "        [0.0497, 0.0550, 0.0123,  ..., 0.0211, 0.0108, 0.0015]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 8\n",
            "0.6698218584060669\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0034, 0.0628, 0.0642,  ..., 0.0061, 0.0089, 0.1210],\n",
            "        [0.0267, 0.0267, 0.0186,  ..., 0.0464, 0.0392, 0.0932],\n",
            "        [0.0569, 0.0215, 0.0093,  ..., 0.0063, 0.0171, 0.0110],\n",
            "        ...,\n",
            "        [0.0118, 0.0237, 0.0408,  ..., 0.0276, 0.0085, 0.0045],\n",
            "        [0.0276, 0.0742, 0.0172,  ..., 0.0377, 0.0072, 0.0740],\n",
            "        [0.0423, 0.0155, 0.0166,  ..., 0.0428, 0.0080, 0.0200]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 8\n",
            "0.6689562797546387\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0118, 0.0342, 0.0166,  ..., 0.0112, 0.0081, 0.0120],\n",
            "        [0.0059, 0.0105, 0.0081,  ..., 0.0121, 0.0383, 0.0048],\n",
            "        [0.0322, 0.0526, 0.0295,  ..., 0.0164, 0.0186, 0.0122],\n",
            "        ...,\n",
            "        [0.0188, 0.0086, 0.0227,  ..., 0.0421, 0.0069, 0.0090],\n",
            "        [0.0148, 0.0191, 0.0305,  ..., 0.0265, 0.0375, 0.0231],\n",
            "        [0.0272, 0.0098, 0.0250,  ..., 0.0527, 0.0173, 0.0259]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 8\n",
            "0.627090573310852\n",
            "one attention pattern developping during training\n",
            "tensor([[0.1216, 0.0100, 0.0025,  ..., 0.0070, 0.0040, 0.0042],\n",
            "        [0.0176, 0.0124, 0.0047,  ..., 0.0054, 0.0078, 0.0245],\n",
            "        [0.0899, 0.0061, 0.0311,  ..., 0.0083, 0.0131, 0.0462],\n",
            "        ...,\n",
            "        [0.0049, 0.0091, 0.0216,  ..., 0.0300, 0.0460, 0.0062],\n",
            "        [0.0514, 0.0257, 0.0360,  ..., 0.0365, 0.0253, 0.0108],\n",
            "        [0.0029, 0.0019, 0.0079,  ..., 0.0012, 0.0009, 0.2506]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 8\n",
            "0.7525235414505005\n",
            "one attention pattern developping during training\n",
            "tensor([[2.8248e-03, 4.3863e-02, 1.4942e-02,  ..., 5.4552e-03, 1.4942e-02,\n",
            "         1.7271e-02],\n",
            "        [4.0775e-03, 2.1761e-01, 1.2788e-02,  ..., 3.1092e-03, 1.2788e-02,\n",
            "         1.6052e-03],\n",
            "        [5.8466e-03, 3.2012e-02, 1.1496e-01,  ..., 6.4536e-04, 1.1496e-01,\n",
            "         1.1317e-04],\n",
            "        ...,\n",
            "        [5.4640e-02, 2.0651e-04, 6.4558e-04,  ..., 4.5512e-02, 6.4558e-04,\n",
            "         1.3040e-03],\n",
            "        [5.8466e-03, 3.2012e-02, 1.1496e-01,  ..., 6.4536e-04, 1.1496e-01,\n",
            "         1.1317e-04],\n",
            "        [6.7186e-04, 8.2927e-03, 5.3032e-03,  ..., 4.9502e-03, 5.3032e-03,\n",
            "         9.1525e-03]], grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 8\n",
            "0.6429750919342041\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0009, 0.2609, 0.0194,  ..., 0.0434, 0.0158, 0.0340],\n",
            "        [0.0091, 0.2282, 0.1334,  ..., 0.0055, 0.0302, 0.0008],\n",
            "        [0.0480, 0.0468, 0.0150,  ..., 0.0082, 0.0497, 0.0538],\n",
            "        ...,\n",
            "        [0.0745, 0.0787, 0.0109,  ..., 0.0312, 0.1182, 0.0551],\n",
            "        [0.0167, 0.0187, 0.0034,  ..., 0.0136, 0.0031, 0.3061],\n",
            "        [0.0068, 0.0050, 0.1449,  ..., 0.0011, 0.1533, 0.2630]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 8\n",
            "0.7003545761108398\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0227, 0.2060, 0.0125,  ..., 0.0142, 0.0347, 0.0208],\n",
            "        [0.1485, 0.0127, 0.0107,  ..., 0.0082, 0.0162, 0.0141],\n",
            "        [0.0084, 0.0217, 0.2382,  ..., 0.0122, 0.0139, 0.1999],\n",
            "        ...,\n",
            "        [0.0108, 0.0111, 0.0268,  ..., 0.0927, 0.0364, 0.0169],\n",
            "        [0.0107, 0.0067, 0.0014,  ..., 0.0173, 0.0100, 0.0073],\n",
            "        [0.0075, 0.0033, 0.0014,  ..., 0.0053, 0.0093, 0.0146]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 8\n",
            "0.6649375557899475\n",
            "one attention pattern developping during training\n",
            "tensor([[2.4845e-01, 7.4829e-05, 4.8819e-06,  ..., 9.2761e-05, 2.4999e-01,\n",
            "         3.2538e-05],\n",
            "        [1.0593e-02, 5.2153e-02, 1.4426e-02,  ..., 6.9234e-03, 2.1279e-02,\n",
            "         2.7665e-02],\n",
            "        [1.5277e-02, 3.0501e-02, 1.7636e-02,  ..., 8.1386e-03, 2.3295e-02,\n",
            "         2.1173e-02],\n",
            "        ...,\n",
            "        [2.5599e-02, 1.6731e-02, 2.2653e-02,  ..., 8.0794e-03, 7.0228e-03,\n",
            "         9.9880e-03],\n",
            "        [2.2055e-02, 1.8654e-02, 9.2485e-03,  ..., 6.7383e-03, 1.0322e-02,\n",
            "         8.4968e-03],\n",
            "        [8.4141e-04, 2.4829e-01, 2.0731e-01,  ..., 2.5552e-04, 5.3696e-04,\n",
            "         1.2424e-01]], grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 8\n",
            "0.5861423015594482\n",
            "one attention pattern developping during training\n",
            "tensor([[0.1517, 0.0176, 0.0568,  ..., 0.0341, 0.0128, 0.0102],\n",
            "        [0.0230, 0.0212, 0.0767,  ..., 0.0110, 0.0171, 0.0455],\n",
            "        [0.0211, 0.0029, 0.0033,  ..., 0.0150, 0.0125, 0.0076],\n",
            "        ...,\n",
            "        [0.0312, 0.0092, 0.0600,  ..., 0.0496, 0.0223, 0.0092],\n",
            "        [0.0273, 0.0393, 0.0183,  ..., 0.0270, 0.0197, 0.0137],\n",
            "        [0.0071, 0.0207, 0.0312,  ..., 0.0190, 0.0150, 0.0341]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 8\n",
            "0.627611517906189\n",
            "one attention pattern developping during training\n",
            "tensor([[6.9837e-03, 4.8090e-03, 7.2328e-03,  ..., 2.2706e-01, 8.2735e-03,\n",
            "         4.0859e-02],\n",
            "        [1.4760e-02, 8.1603e-05, 1.1214e-02,  ..., 2.4552e-01, 4.6561e-03,\n",
            "         2.6889e-03],\n",
            "        [5.4986e-03, 3.6480e-03, 5.3311e-03,  ..., 6.6086e-03, 4.1004e-01,\n",
            "         9.3468e-03],\n",
            "        ...,\n",
            "        [5.5063e-03, 1.3209e-01, 1.9086e-03,  ..., 2.8010e-01, 2.0919e-03,\n",
            "         7.9926e-04],\n",
            "        [2.3237e-02, 1.3878e-02, 1.6348e-02,  ..., 4.7293e-02, 3.7902e-02,\n",
            "         9.4567e-03],\n",
            "        [2.4172e-02, 2.1671e-02, 9.3186e-02,  ..., 1.3818e-02, 9.5187e-02,\n",
            "         9.7328e-03]], grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 8\n",
            "0.6248845458030701\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0079, 0.0283, 0.0421,  ..., 0.0513, 0.0380, 0.0471],\n",
            "        [0.0449, 0.0093, 0.0159,  ..., 0.0406, 0.0256, 0.0171],\n",
            "        [0.0003, 0.0713, 0.0975,  ..., 0.0017, 0.0380, 0.0293],\n",
            "        ...,\n",
            "        [0.0941, 0.0164, 0.0209,  ..., 0.0107, 0.0123, 0.0048],\n",
            "        [0.0098, 0.0192, 0.0095,  ..., 0.0260, 0.1107, 0.0131],\n",
            "        [0.0485, 0.0074, 0.0467,  ..., 0.0267, 0.0470, 0.0065]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 8\n",
            "0.6411526799201965\n",
            "one attention pattern developping during training\n",
            "tensor([[0.2150, 0.0279, 0.0026,  ..., 0.0163, 0.0143, 0.0382],\n",
            "        [0.0368, 0.2552, 0.0111,  ..., 0.0103, 0.0019, 0.0128],\n",
            "        [0.0048, 0.0054, 0.0050,  ..., 0.0202, 0.0118, 0.0282],\n",
            "        ...,\n",
            "        [0.0226, 0.0852, 0.0198,  ..., 0.0007, 0.0311, 0.0036],\n",
            "        [0.0183, 0.0190, 0.0989,  ..., 0.0092, 0.0039, 0.0868],\n",
            "        [0.0305, 0.0154, 0.0432,  ..., 0.0163, 0.0132, 0.0246]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 8\n",
            "0.6982603669166565\n",
            "one attention pattern developping during training\n",
            "tensor([[1.4154e-02, 1.5577e-02, 1.5577e-02,  ..., 2.1508e-02, 8.0289e-03,\n",
            "         1.2091e-02],\n",
            "        [2.4992e-02, 1.4299e-01, 1.4299e-01,  ..., 2.4736e-02, 2.9417e-03,\n",
            "         1.9250e-02],\n",
            "        [2.4992e-02, 1.4299e-01, 1.4299e-01,  ..., 2.4736e-02, 2.9417e-03,\n",
            "         1.9250e-02],\n",
            "        ...,\n",
            "        [1.4448e-02, 6.6969e-02, 6.6969e-02,  ..., 1.2569e-02, 1.3163e-02,\n",
            "         1.5767e-02],\n",
            "        [1.3328e-03, 2.4729e-03, 2.4729e-03,  ..., 2.3300e-01, 1.7384e-03,\n",
            "         6.2895e-04],\n",
            "        [1.5531e-04, 1.2208e-01, 1.2208e-01,  ..., 1.6806e-03, 8.5973e-04,\n",
            "         1.2041e-02]], grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 8\n",
            "0.6406650543212891\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0156, 0.0096, 0.0547,  ..., 0.0060, 0.0100, 0.0041],\n",
            "        [0.0375, 0.0036, 0.0096,  ..., 0.0811, 0.0151, 0.0263],\n",
            "        [0.0181, 0.0063, 0.1184,  ..., 0.0270, 0.0203, 0.1506],\n",
            "        ...,\n",
            "        [0.0145, 0.0174, 0.0106,  ..., 0.0223, 0.0138, 0.0092],\n",
            "        [0.0336, 0.0103, 0.0228,  ..., 0.0089, 0.0227, 0.0087],\n",
            "        [0.0107, 0.0045, 0.0246,  ..., 0.0102, 0.0277, 0.0018]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 8\n",
            "0.6515539288520813\n",
            "one attention pattern developping during training\n",
            "tensor([[2.2511e-02, 7.8271e-02, 4.5811e-02,  ..., 1.6780e-02, 3.0999e-02,\n",
            "         1.2870e-02],\n",
            "        [5.4041e-04, 2.4912e-01, 2.1249e-05,  ..., 5.0942e-04, 1.6481e-04,\n",
            "         1.9514e-04],\n",
            "        [2.3829e-03, 2.0498e-03, 1.7706e-03,  ..., 1.2263e-02, 1.4833e-03,\n",
            "         3.2186e-03],\n",
            "        ...,\n",
            "        [6.5246e-03, 9.7716e-03, 1.0878e-02,  ..., 3.2447e-03, 7.7782e-03,\n",
            "         3.7329e-03],\n",
            "        [1.4011e-02, 1.0049e-01, 1.5235e-02,  ..., 5.8803e-02, 2.5961e-01,\n",
            "         1.9162e-02],\n",
            "        [1.0679e-02, 3.5486e-02, 2.2949e-02,  ..., 3.3712e-02, 1.1031e-02,\n",
            "         2.2508e-02]], grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 8\n",
            "0.573562741279602\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0049, 0.0149, 0.0149,  ..., 0.0049, 0.0145, 0.0438],\n",
            "        [0.0121, 0.0139, 0.0139,  ..., 0.0121, 0.0048, 0.0367],\n",
            "        [0.0121, 0.0139, 0.0139,  ..., 0.0121, 0.0048, 0.0367],\n",
            "        ...,\n",
            "        [0.0049, 0.0149, 0.0149,  ..., 0.0049, 0.0145, 0.0438],\n",
            "        [0.1255, 0.0068, 0.0068,  ..., 0.1255, 0.0255, 0.0124],\n",
            "        [0.0005, 0.1271, 0.1271,  ..., 0.0005, 0.0016, 0.2723]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 8\n",
            "0.6758437156677246\n",
            "one attention pattern developping during training\n",
            "tensor([[0.3014, 0.0023, 0.0049,  ..., 0.0167, 0.0031, 0.0087],\n",
            "        [0.0023, 0.2736, 0.0064,  ..., 0.0107, 0.0089, 0.0059],\n",
            "        [0.0502, 0.0174, 0.0185,  ..., 0.0590, 0.0322, 0.0561],\n",
            "        ...,\n",
            "        [0.1572, 0.0081, 0.0336,  ..., 0.0096, 0.0707, 0.0407],\n",
            "        [0.2082, 0.0172, 0.0113,  ..., 0.0078, 0.0050, 0.1828],\n",
            "        [0.0054, 0.0010, 0.0024,  ..., 0.0007, 0.0050, 0.0161]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 8\n",
            "0.5928664803504944\n",
            "one attention pattern developping during training\n",
            "tensor([[8.8919e-05, 1.3120e-02, 5.9823e-03,  ..., 2.1675e-04, 2.6822e-02,\n",
            "         1.1058e-02],\n",
            "        [2.2074e-02, 8.7709e-03, 1.5657e-02,  ..., 4.6785e-03, 9.9970e-03,\n",
            "         1.6480e-02],\n",
            "        [1.9196e-03, 1.5026e-03, 4.3919e-04,  ..., 2.8323e-02, 1.1918e-02,\n",
            "         1.0606e-02],\n",
            "        ...,\n",
            "        [3.7628e-03, 1.1263e-04, 4.4645e-04,  ..., 9.8975e-03, 1.9862e-02,\n",
            "         1.2880e-03],\n",
            "        [3.3181e-03, 6.7703e-02, 3.0026e-02,  ..., 3.4953e-03, 2.3395e-01,\n",
            "         3.2468e-02],\n",
            "        [8.6576e-03, 1.0993e-03, 2.2082e-03,  ..., 6.9165e-03, 8.7245e-02,\n",
            "         2.3241e-02]], grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 8\n",
            "0.7189128398895264\n",
            "one attention pattern developping during training\n",
            "tensor([[4.2035e-03, 2.3800e-02, 2.1029e-03,  ..., 9.0124e-03, 3.6988e-03,\n",
            "         6.5892e-03],\n",
            "        [2.9758e-02, 2.6950e-01, 3.6612e-01,  ..., 3.2118e-03, 9.6790e-03,\n",
            "         7.2413e-03],\n",
            "        [1.2535e-03, 4.8743e-05, 1.4128e-04,  ..., 2.2877e-03, 9.7402e-04,\n",
            "         2.5096e-05],\n",
            "        ...,\n",
            "        [2.5056e-03, 4.1560e-04, 5.2705e-03,  ..., 2.1834e-01, 7.0689e-03,\n",
            "         4.4949e-03],\n",
            "        [3.2604e-03, 1.8197e-02, 1.5436e-03,  ..., 1.0401e-02, 1.2613e-02,\n",
            "         3.0157e-02],\n",
            "        [8.7400e-04, 2.5421e-01, 1.2220e-02,  ..., 2.4324e-03, 2.4832e-03,\n",
            "         1.2915e-01]], grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 8\n",
            "0.5939816832542419\n",
            "one attention pattern developping during training\n",
            "tensor([[2.7218e-03, 5.9127e-03, 6.0521e-03,  ..., 5.0912e-03, 2.2933e-02,\n",
            "         2.9969e-03],\n",
            "        [9.0801e-03, 5.2036e-03, 4.0002e-02,  ..., 1.8072e-02, 1.0820e-02,\n",
            "         2.1568e-02],\n",
            "        [3.6559e-04, 1.0723e-01, 8.8163e-05,  ..., 3.4437e-05, 1.0183e-02,\n",
            "         7.2205e-02],\n",
            "        ...,\n",
            "        [7.6171e-03, 6.5412e-02, 1.6590e-02,  ..., 1.1339e-02, 2.4446e-02,\n",
            "         2.3415e-02],\n",
            "        [2.4892e-02, 1.1672e-02, 3.6778e-02,  ..., 2.4251e-02, 8.5424e-03,\n",
            "         2.5752e-02],\n",
            "        [1.1722e-04, 1.9976e-01, 7.1014e-05,  ..., 1.7823e-04, 1.1002e-02,\n",
            "         3.1417e-02]], grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 8\n",
            "0.5967283248901367\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0248, 0.0296, 0.0252,  ..., 0.0117, 0.0150, 0.0216],\n",
            "        [0.0164, 0.0120, 0.0530,  ..., 0.0358, 0.0308, 0.0676],\n",
            "        [0.0062, 0.0319, 0.0176,  ..., 0.0414, 0.0067, 0.0042],\n",
            "        ...,\n",
            "        [0.0084, 0.0041, 0.0073,  ..., 0.0032, 0.0034, 0.0090],\n",
            "        [0.0191, 0.0158, 0.0238,  ..., 0.0608, 0.0872, 0.0470],\n",
            "        [0.0008, 0.0023, 0.2105,  ..., 0.0075, 0.0005, 0.2492]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 8\n",
            "0.6569970846176147\n",
            "one attention pattern developping during training\n",
            "tensor([[0.1237, 0.0129, 0.0216,  ..., 0.0316, 0.0135, 0.0065],\n",
            "        [0.0111, 0.0519, 0.0301,  ..., 0.0091, 0.0010, 0.0027],\n",
            "        [0.0437, 0.0086, 0.0102,  ..., 0.0359, 0.0111, 0.0453],\n",
            "        ...,\n",
            "        [0.0239, 0.0026, 0.0309,  ..., 0.0372, 0.0177, 0.0133],\n",
            "        [0.0053, 0.0099, 0.0355,  ..., 0.0280, 0.0569, 0.0137],\n",
            "        [0.0253, 0.0137, 0.0255,  ..., 0.0408, 0.0078, 0.0144]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 8\n",
            "0.6264552474021912\n",
            "one attention pattern developping during training\n",
            "tensor([[2.5226e-01, 3.5338e-02, 1.7903e-02,  ..., 1.1013e-02, 9.2292e-03,\n",
            "         1.2599e-02],\n",
            "        [2.1442e-02, 1.0768e-01, 1.9068e-02,  ..., 2.6341e-02, 8.6719e-03,\n",
            "         1.1824e-02],\n",
            "        [9.7803e-02, 2.4847e-02, 8.7392e-04,  ..., 5.0514e-03, 1.6027e-03,\n",
            "         2.1860e-03],\n",
            "        ...,\n",
            "        [1.9797e-02, 1.5016e-03, 4.6341e-02,  ..., 8.7231e-04, 1.7125e-02,\n",
            "         1.0932e-01],\n",
            "        [1.3276e-01, 5.5884e-03, 6.8878e-03,  ..., 2.6221e-02, 1.0052e-02,\n",
            "         8.8595e-03],\n",
            "        [1.0669e-03, 1.6048e-05, 8.0399e-05,  ..., 4.8639e-04, 1.9413e-04,\n",
            "         7.9860e-05]], grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 8\n",
            "0.6383295059204102\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0251, 0.0298, 0.0107,  ..., 0.4332, 0.0063, 0.0237],\n",
            "        [0.0142, 0.0136, 0.0091,  ..., 0.0074, 0.0170, 0.0165],\n",
            "        [0.0253, 0.0080, 0.1635,  ..., 0.0008, 0.0949, 0.0013],\n",
            "        ...,\n",
            "        [0.0043, 0.0146, 0.0157,  ..., 0.0128, 0.0072, 0.0018],\n",
            "        [0.0079, 0.0223, 0.0195,  ..., 0.0054, 0.0125, 0.0076],\n",
            "        [0.0286, 0.0141, 0.0292,  ..., 0.0185, 0.0271, 0.0074]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 8\n",
            "0.7009559869766235\n",
            "one attention pattern developping during training\n",
            "tensor([[4.3574e-03, 7.1912e-03, 1.1688e-02,  ..., 1.8941e-02, 1.1858e-02,\n",
            "         5.9521e-03],\n",
            "        [3.2567e-02, 3.9705e-04, 2.5719e-03,  ..., 1.4331e-01, 1.3167e-02,\n",
            "         1.2387e-02],\n",
            "        [1.9926e-02, 2.8498e-02, 2.0918e-02,  ..., 4.3714e-02, 1.6997e-02,\n",
            "         8.1247e-02],\n",
            "        ...,\n",
            "        [3.0992e-02, 8.7996e-05, 7.9237e-04,  ..., 2.5231e-01, 5.4523e-05,\n",
            "         2.2435e-05],\n",
            "        [3.0525e-02, 1.5520e-01, 8.6339e-02,  ..., 2.3634e-03, 2.1044e-03,\n",
            "         1.3688e-02],\n",
            "        [1.4524e-02, 4.8460e-03, 2.5010e-03,  ..., 4.8295e-03, 3.5982e-03,\n",
            "         2.3025e-01]], grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 8\n",
            "0.7240060567855835\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0139, 0.0192, 0.0063,  ..., 0.0215, 0.0092, 0.0035],\n",
            "        [0.0079, 0.1009, 0.0132,  ..., 0.0085, 0.0087, 0.0139],\n",
            "        [0.0231, 0.0127, 0.0043,  ..., 0.0126, 0.0185, 0.0069],\n",
            "        ...,\n",
            "        [0.0275, 0.0209, 0.0086,  ..., 0.0208, 0.0454, 0.0091],\n",
            "        [0.0357, 0.0382, 0.0361,  ..., 0.0339, 0.0480, 0.0203],\n",
            "        [0.0337, 0.0172, 0.0344,  ..., 0.0362, 0.0044, 0.0045]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 8\n",
            "0.6278244256973267\n",
            "one attention pattern developping during training\n",
            "tensor([[6.4615e-01, 5.2761e-03, 4.9597e-03,  ..., 2.2846e-03, 7.8308e-03,\n",
            "         6.3839e-03],\n",
            "        [2.6758e-02, 3.6656e-04, 2.8084e-03,  ..., 1.0421e-02, 9.3726e-02,\n",
            "         2.7523e-03],\n",
            "        [2.4580e-02, 8.1041e-03, 1.7476e-02,  ..., 1.5502e-02, 1.3306e-02,\n",
            "         3.6562e-02],\n",
            "        ...,\n",
            "        [5.3210e-02, 1.2207e-02, 2.8256e-02,  ..., 2.6984e-02, 1.2473e-02,\n",
            "         1.8574e-02],\n",
            "        [2.3771e-01, 2.2339e-02, 1.3895e-02,  ..., 3.8355e-02, 1.7678e-02,\n",
            "         1.6326e-02],\n",
            "        [3.1365e-02, 7.6390e-03, 4.3072e-03,  ..., 2.1570e-02, 1.8781e-02,\n",
            "         1.2523e-01]], grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 8\n",
            "0.7917981743812561\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0392, 0.1239, 0.1838, 0.1271, 0.3106, 0.0879, 0.0576, 0.0698],\n",
            "        [0.1538, 0.0257, 0.0332, 0.0335, 0.3561, 0.0446, 0.1623, 0.1908],\n",
            "        [0.0357, 0.0641, 0.1402, 0.1477, 0.1476, 0.2068, 0.0483, 0.2094],\n",
            "        [0.1116, 0.1540, 0.1141, 0.1390, 0.1704, 0.1161, 0.0453, 0.1495],\n",
            "        [0.2001, 0.0275, 0.0706, 0.0374, 0.2014, 0.0605, 0.1356, 0.2669],\n",
            "        [0.0630, 0.1313, 0.0853, 0.1000, 0.0496, 0.2252, 0.0986, 0.2471],\n",
            "        [0.0433, 0.1222, 0.1914, 0.2414, 0.2963, 0.0441, 0.0229, 0.0384],\n",
            "        [0.1802, 0.0556, 0.0754, 0.0207, 0.1118, 0.1502, 0.0688, 0.3372]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 9\n",
            "0.6539974212646484\n",
            "one attention pattern developping during training\n",
            "tensor([[9.3602e-04, 1.7545e-03, 1.9555e-01,  ..., 1.3206e-02, 2.9467e-02,\n",
            "         2.1131e-03],\n",
            "        [6.1844e-02, 5.5978e-03, 1.5884e-02,  ..., 2.5369e-02, 2.6966e-02,\n",
            "         4.2001e-02],\n",
            "        [1.9148e-02, 6.0545e-03, 1.2722e-02,  ..., 8.1290e-03, 1.6450e-02,\n",
            "         4.9011e-03],\n",
            "        ...,\n",
            "        [1.1005e-02, 2.0727e-02, 8.0913e-02,  ..., 1.1972e-01, 3.7082e-02,\n",
            "         7.8657e-03],\n",
            "        [4.3411e-05, 2.3440e-04, 2.2243e-01,  ..., 5.6814e-04, 1.6401e-02,\n",
            "         2.8913e-04],\n",
            "        [2.2331e-02, 5.1919e-03, 1.8709e-02,  ..., 1.6971e-02, 8.9630e-02,\n",
            "         4.0845e-03]], grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 9\n",
            "0.6890177726745605\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0049, 0.0473, 0.0159,  ..., 0.0074, 0.0284, 0.0140],\n",
            "        [0.0034, 0.2451, 0.0805,  ..., 0.0021, 0.0212, 0.0060],\n",
            "        [0.0250, 0.0335, 0.0082,  ..., 0.0167, 0.0071, 0.0328],\n",
            "        ...,\n",
            "        [0.0025, 0.0300, 0.0646,  ..., 0.0007, 0.0422, 0.0094],\n",
            "        [0.0053, 0.2166, 0.0627,  ..., 0.0044, 0.1208, 0.0089],\n",
            "        [0.0202, 0.0160, 0.0159,  ..., 0.0606, 0.0234, 0.0183]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 9\n",
            "0.5955323576927185\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0251, 0.0568, 0.0379,  ..., 0.0300, 0.0176, 0.0222],\n",
            "        [0.0316, 0.0230, 0.0155,  ..., 0.0120, 0.0055, 0.0224],\n",
            "        [0.0002, 0.0002, 0.0003,  ..., 0.0005, 0.0023, 0.0007],\n",
            "        ...,\n",
            "        [0.0168, 0.0148, 0.0307,  ..., 0.0138, 0.0163, 0.0270],\n",
            "        [0.0331, 0.0364, 0.0386,  ..., 0.0307, 0.0182, 0.0327],\n",
            "        [0.0206, 0.0080, 0.0331,  ..., 0.0082, 0.0067, 0.0030]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 9\n",
            "0.525754988193512\n",
            "one attention pattern developping during training\n",
            "tensor([[1.5916e-04, 3.0050e-04, 2.8400e-04,  ..., 1.5006e-03, 5.8076e-04,\n",
            "         7.2316e-04],\n",
            "        [1.8776e-03, 2.2822e-01, 1.2473e-02,  ..., 1.2708e-01, 6.4072e-03,\n",
            "         1.9025e-02],\n",
            "        [5.9266e-05, 1.8322e-04, 2.4833e-03,  ..., 2.8482e-04, 1.5753e-04,\n",
            "         1.4685e-04],\n",
            "        ...,\n",
            "        [5.2015e-03, 7.7233e-03, 1.9147e-02,  ..., 4.8552e-03, 4.6087e-03,\n",
            "         6.0305e-03],\n",
            "        [1.3563e-02, 1.7724e-02, 2.5927e-02,  ..., 9.0449e-02, 1.8846e-02,\n",
            "         5.1705e-03],\n",
            "        [3.6227e-02, 1.5454e-02, 4.6377e-02,  ..., 1.1223e-02, 2.0189e-02,\n",
            "         1.6374e-02]], grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 9\n",
            "0.6459195613861084\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0012, 0.0023, 0.0240,  ..., 0.0038, 0.0013, 0.0034],\n",
            "        [0.0070, 0.0005, 0.0061,  ..., 0.0024, 0.0006, 0.0020],\n",
            "        [0.0082, 0.0301, 0.0011,  ..., 0.0029, 0.2563, 0.0181],\n",
            "        ...,\n",
            "        [0.0040, 0.0072, 0.0286,  ..., 0.0021, 0.0011, 0.0049],\n",
            "        [0.0080, 0.0738, 0.0278,  ..., 0.0060, 0.0054, 0.0048],\n",
            "        [0.0008, 0.0014, 0.0140,  ..., 0.0014, 0.0103, 0.0010]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 9\n",
            "0.6256670355796814\n",
            "one attention pattern developping during training\n",
            "tensor([[0.1168, 0.0143, 0.0242,  ..., 0.0140, 0.0176, 0.1932],\n",
            "        [0.0080, 0.0268, 0.0048,  ..., 0.0059, 0.0012, 0.0059],\n",
            "        [0.0111, 0.0123, 0.0055,  ..., 0.0131, 0.0080, 0.0076],\n",
            "        ...,\n",
            "        [0.0272, 0.0381, 0.0106,  ..., 0.0040, 0.0124, 0.0248],\n",
            "        [0.0538, 0.0023, 0.2506,  ..., 0.0905, 0.0023, 0.0455],\n",
            "        [0.0158, 0.0130, 0.0184,  ..., 0.0223, 0.0155, 0.1558]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 9\n",
            "0.6921731233596802\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0116, 0.0415, 0.0067,  ..., 0.0032, 0.0029, 0.0073],\n",
            "        [0.0057, 0.1060, 0.0206,  ..., 0.0011, 0.0456, 0.0007],\n",
            "        [0.0097, 0.0268, 0.0043,  ..., 0.0108, 0.0258, 0.0083],\n",
            "        ...,\n",
            "        [0.0211, 0.0154, 0.0373,  ..., 0.0072, 0.0135, 0.0143],\n",
            "        [0.0697, 0.0136, 0.0187,  ..., 0.0144, 0.0110, 0.0206],\n",
            "        [0.0091, 0.0064, 0.0117,  ..., 0.0030, 0.0160, 0.2407]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 9\n",
            "0.7091565728187561\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0055, 0.0246, 0.0131,  ..., 0.0876, 0.0105, 0.0119],\n",
            "        [0.0288, 0.0032, 0.0115,  ..., 0.2406, 0.0048, 0.0142],\n",
            "        [0.0101, 0.0028, 0.1005,  ..., 0.0594, 0.1894, 0.0009],\n",
            "        ...,\n",
            "        [0.0219, 0.0629, 0.1014,  ..., 0.0117, 0.0512, 0.0182],\n",
            "        [0.0324, 0.0110, 0.0442,  ..., 0.0011, 0.2495, 0.0004],\n",
            "        [0.0074, 0.0270, 0.0026,  ..., 0.0045, 0.0055, 0.0008]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 9\n",
            "0.630081295967102\n",
            "one attention pattern developping during training\n",
            "tensor([[2.8665e-01, 9.5260e-03, 6.2036e-03,  ..., 2.3336e-03, 9.6740e-03,\n",
            "         4.5931e-02],\n",
            "        [2.2642e-01, 5.8985e-03, 2.3428e-01,  ..., 5.5039e-03, 1.4037e-02,\n",
            "         1.0113e-02],\n",
            "        [1.5717e-01, 2.5085e-03, 2.5520e-01,  ..., 2.7273e-02, 1.8491e-03,\n",
            "         2.3328e-03],\n",
            "        ...,\n",
            "        [2.6158e-02, 4.7806e-03, 4.3070e-02,  ..., 7.4149e-02, 7.5135e-03,\n",
            "         7.7370e-03],\n",
            "        [4.0346e-03, 4.9205e-03, 8.8526e-03,  ..., 1.0109e-02, 5.0558e-03,\n",
            "         1.6175e-02],\n",
            "        [3.7890e-04, 1.1618e-02, 1.9328e-03,  ..., 1.3137e-04, 1.4979e-03,\n",
            "         2.3902e-01]], grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 9\n",
            "0.6863033175468445\n",
            "one attention pattern developping during training\n",
            "tensor([[3.1235e-03, 4.4317e-03, 9.6355e-03,  ..., 1.2753e-02, 2.0142e-01,\n",
            "         4.0399e-03],\n",
            "        [2.4856e-01, 9.4009e-03, 5.9512e-03,  ..., 1.4932e-02, 1.5568e-02,\n",
            "         1.0645e-02],\n",
            "        [2.6490e-01, 9.4152e-03, 2.1343e-02,  ..., 3.6232e-02, 2.0219e-02,\n",
            "         8.1119e-03],\n",
            "        ...,\n",
            "        [1.4661e-04, 9.2754e-06, 4.5925e-04,  ..., 2.5131e-01, 1.3122e-06,\n",
            "         3.1099e-03],\n",
            "        [3.2192e-03, 3.6745e-02, 1.5754e-02,  ..., 2.4989e-02, 5.1396e-02,\n",
            "         1.2660e-02],\n",
            "        [1.6055e-02, 5.2034e-03, 1.3862e-02,  ..., 8.2833e-02, 4.2567e-03,\n",
            "         5.5105e-03]], grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 9\n",
            "0.649918794631958\n",
            "one attention pattern developping during training\n",
            "tensor([[2.6553e-01, 1.0054e-04, 4.8081e-03,  ..., 2.4629e-02, 2.8545e-03,\n",
            "         3.9397e-03],\n",
            "        [5.0461e-03, 2.5249e-05, 2.3945e-01,  ..., 3.0810e-02, 5.4237e-04,\n",
            "         3.3484e-03],\n",
            "        [3.5252e-02, 1.0443e-04, 1.4493e-01,  ..., 5.0443e-03, 4.1782e-03,\n",
            "         3.6825e-03],\n",
            "        ...,\n",
            "        [1.5589e-03, 1.0924e-03, 1.2567e-01,  ..., 5.3454e-03, 2.8802e-04,\n",
            "         1.3366e-03],\n",
            "        [4.7635e-02, 1.8633e-02, 5.8627e-03,  ..., 2.3884e-02, 4.6732e-03,\n",
            "         2.6690e-02],\n",
            "        [2.5080e-01, 1.1819e-05, 1.2832e-01,  ..., 1.4202e-03, 1.6270e-04,\n",
            "         1.5460e-01]], grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 9\n",
            "0.6111524701118469\n",
            "one attention pattern developping during training\n",
            "tensor([[0.1744, 0.0100, 0.0057,  ..., 0.0079, 0.0135, 0.0038],\n",
            "        [0.1366, 0.0087, 0.0033,  ..., 0.0028, 0.2730, 0.0099],\n",
            "        [0.0135, 0.0051, 0.0168,  ..., 0.0202, 0.0029, 0.0118],\n",
            "        ...,\n",
            "        [0.0115, 0.0140, 0.0181,  ..., 0.0201, 0.0321, 0.0171],\n",
            "        [0.0193, 0.0325, 0.0673,  ..., 0.0033, 0.2683, 0.0235],\n",
            "        [0.0099, 0.0168, 0.0538,  ..., 0.0245, 0.0086, 0.0032]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 9\n",
            "0.5936113595962524\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0054, 0.0503, 0.0099,  ..., 0.0663, 0.0061, 0.0304],\n",
            "        [0.0361, 0.2232, 0.0101,  ..., 0.0164, 0.0084, 0.0203],\n",
            "        [0.0080, 0.0291, 0.0225,  ..., 0.0045, 0.0169, 0.0227],\n",
            "        ...,\n",
            "        [0.0153, 0.0202, 0.0084,  ..., 0.0083, 0.1365, 0.0017],\n",
            "        [0.0121, 0.0319, 0.0364,  ..., 0.0077, 0.0098, 0.0114],\n",
            "        [0.0191, 0.0096, 0.0182,  ..., 0.0054, 0.0469, 0.0037]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 9\n",
            "0.625109076499939\n",
            "one attention pattern developping during training\n",
            "tensor([[2.8286e-03, 5.6786e-03, 2.0163e-03,  ..., 3.8798e-03, 2.1378e-02,\n",
            "         1.2002e-02],\n",
            "        [3.3874e-01, 9.1758e-02, 9.6480e-04,  ..., 7.8744e-03, 1.3651e-01,\n",
            "         1.8420e-03],\n",
            "        [6.4744e-02, 1.8287e-02, 2.5498e-01,  ..., 4.3605e-03, 2.7021e-03,\n",
            "         2.6485e-02],\n",
            "        ...,\n",
            "        [1.4782e-02, 3.7694e-02, 2.8815e-01,  ..., 1.2678e-02, 9.3472e-03,\n",
            "         3.1008e-02],\n",
            "        [1.0910e-04, 5.7985e-05, 7.6843e-06,  ..., 6.6318e-05, 1.2528e-01,\n",
            "         3.6761e-05],\n",
            "        [2.2349e-01, 1.5072e-02, 1.6166e-03,  ..., 3.6731e-03, 1.1195e-02,\n",
            "         6.8610e-03]], grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 9\n",
            "0.6061668395996094\n",
            "one attention pattern developping during training\n",
            "tensor([[2.3641e-01, 3.2759e-03, 4.2505e-03,  ..., 7.1011e-04, 7.7254e-03,\n",
            "         2.0838e-02],\n",
            "        [9.4050e-04, 1.0347e-02, 3.5714e-02,  ..., 2.4690e-03, 7.6874e-03,\n",
            "         1.4917e-03],\n",
            "        [4.0715e-04, 6.4312e-03, 6.7932e-02,  ..., 1.0482e-03, 1.4913e-04,\n",
            "         2.2238e-03],\n",
            "        ...,\n",
            "        [6.1712e-03, 3.0445e-02, 4.0994e-02,  ..., 3.9929e-03, 5.2473e-03,\n",
            "         1.6246e-02],\n",
            "        [2.4569e-03, 1.0050e-02, 3.7027e-02,  ..., 3.9056e-03, 3.3606e-03,\n",
            "         3.4784e-03],\n",
            "        [5.1197e-03, 4.1874e-02, 7.3400e-02,  ..., 1.6499e-02, 1.1244e-02,\n",
            "         4.7503e-03]], grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 9\n",
            "0.6002065539360046\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0106, 0.0079, 0.0274,  ..., 0.0109, 0.0111, 0.0219],\n",
            "        [0.0113, 0.0042, 0.0133,  ..., 0.0288, 0.0204, 0.0637],\n",
            "        [0.0026, 0.2337, 0.2451,  ..., 0.0381, 0.0014, 0.0054],\n",
            "        ...,\n",
            "        [0.0286, 0.2487, 0.1970,  ..., 0.0143, 0.0138, 0.0130],\n",
            "        [0.0162, 0.0283, 0.0143,  ..., 0.0084, 0.0146, 0.0294],\n",
            "        [0.0056, 0.0139, 0.0061,  ..., 0.0053, 0.0161, 0.0063]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 9\n",
            "0.6839719414710999\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0452, 0.0132, 0.0251,  ..., 0.0452, 0.0134, 0.0217],\n",
            "        [0.0563, 0.1484, 0.0078,  ..., 0.0563, 0.0087, 0.0115],\n",
            "        [0.0470, 0.0231, 0.0049,  ..., 0.0470, 0.0303, 0.0078],\n",
            "        ...,\n",
            "        [0.0452, 0.0132, 0.0251,  ..., 0.0452, 0.0134, 0.0217],\n",
            "        [0.0340, 0.0056, 0.0010,  ..., 0.0340, 0.0609, 0.0091],\n",
            "        [0.0143, 0.0046, 0.0206,  ..., 0.0143, 0.0137, 0.0128]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 9\n",
            "0.5852329730987549\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0044, 0.0204, 0.0438,  ..., 0.0290, 0.0196, 0.0304],\n",
            "        [0.0021, 0.1528, 0.2940,  ..., 0.0122, 0.0029, 0.0142],\n",
            "        [0.0143, 0.0328, 0.0086,  ..., 0.0323, 0.0156, 0.0109],\n",
            "        ...,\n",
            "        [0.0322, 0.0062, 0.0307,  ..., 0.0906, 0.0117, 0.0121],\n",
            "        [0.0104, 0.0083, 0.2772,  ..., 0.0163, 0.0145, 0.0041],\n",
            "        [0.0226, 0.0116, 0.2376,  ..., 0.0170, 0.0220, 0.0051]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 9\n",
            "0.6143273711204529\n",
            "one attention pattern developping during training\n",
            "tensor([[0.1704, 0.0047, 0.0037,  ..., 0.0093, 0.1133, 0.0112],\n",
            "        [0.0029, 0.0101, 0.0096,  ..., 0.0505, 0.2632, 0.0166],\n",
            "        [0.0245, 0.0117, 0.0281,  ..., 0.0375, 0.0067, 0.0278],\n",
            "        ...,\n",
            "        [0.0711, 0.0217, 0.0091,  ..., 0.0114, 0.0030, 0.0355],\n",
            "        [0.0360, 0.0039, 0.0009,  ..., 0.0003, 0.2498, 0.0294],\n",
            "        [0.0204, 0.0100, 0.0034,  ..., 0.0093, 0.0049, 0.0036]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 9\n",
            "0.6165469288825989\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0295, 0.0647, 0.1148,  ..., 0.0732, 0.0131, 0.0838],\n",
            "        [0.0015, 0.0010, 0.0179,  ..., 0.0190, 0.0636, 0.0011],\n",
            "        [0.0201, 0.0044, 0.0007,  ..., 0.0129, 0.0335, 0.0994],\n",
            "        ...,\n",
            "        [0.0090, 0.0159, 0.0131,  ..., 0.0094, 0.0058, 0.1621],\n",
            "        [0.0323, 0.0120, 0.0496,  ..., 0.0116, 0.0290, 0.0205],\n",
            "        [0.0251, 0.0437, 0.0217,  ..., 0.0294, 0.0307, 0.0357]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 9\n",
            "0.6459411978721619\n",
            "one attention pattern developping during training\n",
            "tensor([[0.2882, 0.0236, 0.0275,  ..., 0.0061, 0.0060, 0.0075],\n",
            "        [0.0511, 0.0044, 0.0029,  ..., 0.0070, 0.0331, 0.0267],\n",
            "        [0.2486, 0.0455, 0.0532,  ..., 0.0046, 0.0263, 0.0063],\n",
            "        ...,\n",
            "        [0.2691, 0.0269, 0.0117,  ..., 0.0105, 0.0053, 0.0258],\n",
            "        [0.1837, 0.0209, 0.0100,  ..., 0.0268, 0.0078, 0.0905],\n",
            "        [0.1030, 0.0091, 0.0046,  ..., 0.0062, 0.0016, 0.0029]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 9\n",
            "0.6179949641227722\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0016, 0.0022, 0.0016,  ..., 0.0284, 0.0019, 0.2215],\n",
            "        [0.0236, 0.0090, 0.0236,  ..., 0.0141, 0.0220, 0.0106],\n",
            "        [0.0016, 0.0022, 0.0016,  ..., 0.0284, 0.0019, 0.2215],\n",
            "        ...,\n",
            "        [0.0261, 0.0135, 0.0261,  ..., 0.0265, 0.2351, 0.0124],\n",
            "        [0.0022, 0.0043, 0.0022,  ..., 0.0044, 0.0017, 0.2576],\n",
            "        [0.0040, 0.0044, 0.0040,  ..., 0.0055, 0.1886, 0.2914]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 9\n",
            "0.5988732576370239\n",
            "one attention pattern developping during training\n",
            "tensor([[0.2464, 0.0086, 0.0503,  ..., 0.0116, 0.0187, 0.0110],\n",
            "        [0.0131, 0.0253, 0.2661,  ..., 0.0241, 0.0134, 0.0085],\n",
            "        [0.1014, 0.0167, 0.0044,  ..., 0.0118, 0.0098, 0.0034],\n",
            "        ...,\n",
            "        [0.0200, 0.0223, 0.0181,  ..., 0.0065, 0.0389, 0.0384],\n",
            "        [0.0105, 0.0068, 0.0139,  ..., 0.2424, 0.0214, 0.0038],\n",
            "        [0.0347, 0.0054, 0.0079,  ..., 0.0009, 0.0142, 0.1185]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 9\n",
            "0.5404803156852722\n",
            "one attention pattern developping during training\n",
            "tensor([[3.0827e-02, 2.2765e-03, 1.0551e-02,  ..., 1.7222e-04, 8.4064e-03,\n",
            "         2.5360e-01],\n",
            "        [2.8986e-03, 2.4744e-01, 2.5786e-02,  ..., 4.8313e-03, 5.2450e-03,\n",
            "         3.7144e-03],\n",
            "        [5.7252e-02, 4.4989e-03, 1.6871e-01,  ..., 1.8172e-03, 5.5530e-03,\n",
            "         2.0522e-01],\n",
            "        ...,\n",
            "        [1.4715e-02, 2.7774e-01, 1.5684e-02,  ..., 1.1246e-02, 4.7348e-02,\n",
            "         3.7820e-02],\n",
            "        [5.7747e-03, 2.4415e-01, 2.4018e-02,  ..., 6.4042e-03, 3.9410e-02,\n",
            "         6.3017e-03],\n",
            "        [2.3511e-02, 5.2419e-03, 5.6286e-02,  ..., 2.1258e-02, 6.1902e-02,\n",
            "         1.3204e-02]], grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 9\n",
            "0.7469281554222107\n",
            "one attention pattern developping during training\n",
            "tensor([[1.0651e-02, 2.0809e-01, 7.1477e-02,  ..., 1.6520e-02, 2.3642e-03,\n",
            "         5.3194e-03],\n",
            "        [5.7968e-04, 2.5089e-01, 1.4354e-05,  ..., 4.5908e-03, 2.7083e-04,\n",
            "         1.1806e-04],\n",
            "        [9.0190e-03, 1.7025e-02, 1.4208e-01,  ..., 8.2943e-03, 7.4895e-03,\n",
            "         4.6478e-03],\n",
            "        ...,\n",
            "        [5.8499e-03, 1.1109e-03, 1.8335e-01,  ..., 1.2433e-02, 3.6005e-02,\n",
            "         1.0606e-02],\n",
            "        [2.2078e-02, 5.4102e-03, 1.0010e-02,  ..., 2.5322e-02, 2.2404e-01,\n",
            "         4.6543e-03],\n",
            "        [7.3167e-03, 2.5844e-02, 1.5303e-01,  ..., 1.3259e-02, 4.5186e-03,\n",
            "         1.1430e-02]], grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 9\n",
            "0.8038371801376343\n",
            "one attention pattern developping during training\n",
            "tensor([[2.8635e-04, 2.2366e-01, 2.0747e-05,  ..., 1.8988e-02, 2.0335e-02,\n",
            "         1.0858e-03],\n",
            "        [2.8497e-02, 3.4166e-02, 2.4858e-02,  ..., 5.1999e-02, 5.2355e-02,\n",
            "         2.6811e-02],\n",
            "        [4.7231e-03, 2.4251e-02, 5.9638e-02,  ..., 3.3542e-02, 4.9056e-03,\n",
            "         1.0944e-01],\n",
            "        ...,\n",
            "        [3.0487e-02, 2.0224e-02, 2.5635e-02,  ..., 1.7985e-02, 5.1440e-02,\n",
            "         1.8841e-02],\n",
            "        [2.5556e-01, 2.4391e-01, 9.6354e-03,  ..., 1.1743e-01, 2.8371e-03,\n",
            "         1.9203e-02],\n",
            "        [1.2370e-02, 3.1589e-02, 3.2400e-02,  ..., 4.0198e-02, 1.5457e-02,\n",
            "         2.4050e-02]], grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 9\n",
            "0.5909889340400696\n",
            "one attention pattern developping during training\n",
            "tensor([[3.5816e-05, 4.4095e-03, 2.1907e-01,  ..., 5.6819e-04, 1.4985e-04,\n",
            "         1.8410e-02],\n",
            "        [3.7697e-03, 8.3575e-03, 1.1986e-03,  ..., 2.4753e-01, 2.4242e-03,\n",
            "         1.7296e-03],\n",
            "        [3.5594e-04, 2.0968e-03, 2.4718e-01,  ..., 2.4625e-01, 8.4428e-04,\n",
            "         3.0850e-03],\n",
            "        ...,\n",
            "        [1.4097e-02, 6.2266e-03, 1.3974e-02,  ..., 2.7543e-01, 8.6984e-03,\n",
            "         3.3660e-02],\n",
            "        [3.1917e-02, 1.4267e-02, 1.7170e-02,  ..., 2.7744e-02, 3.7506e-02,\n",
            "         2.9695e-02],\n",
            "        [2.2571e-02, 2.0031e-02, 4.5766e-02,  ..., 3.8128e-03, 4.7152e-03,\n",
            "         1.6485e-02]], grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 9\n",
            "0.7224662899971008\n",
            "one attention pattern developping during training\n",
            "tensor([[0.1466, 0.0065, 0.0082,  ..., 0.0127, 0.0105, 0.0152],\n",
            "        [0.0130, 0.0971, 0.0752,  ..., 0.0160, 0.0146, 0.0033],\n",
            "        [0.0234, 0.0243, 0.0023,  ..., 0.0311, 0.0160, 0.0079],\n",
            "        ...,\n",
            "        [0.0471, 0.0089, 0.0268,  ..., 0.0082, 0.0047, 0.1300],\n",
            "        [0.0152, 0.0098, 0.0150,  ..., 0.0204, 0.0048, 0.0101],\n",
            "        [0.0120, 0.0092, 0.0597,  ..., 0.0134, 0.0228, 0.0305]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 9\n",
            "0.6930221319198608\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0057, 0.0158, 0.0058,  ..., 0.0078, 0.0030, 0.0138],\n",
            "        [0.0139, 0.0040, 0.0091,  ..., 0.0150, 0.1047, 0.0211],\n",
            "        [0.0128, 0.0090, 0.0076,  ..., 0.0223, 0.0223, 0.0030],\n",
            "        ...,\n",
            "        [0.0193, 0.0118, 0.2610,  ..., 0.0121, 0.0248, 0.0113],\n",
            "        [0.0959, 0.0280, 0.0202,  ..., 0.0268, 0.0055, 0.0487],\n",
            "        [0.0040, 0.0025, 0.0023,  ..., 0.0027, 0.0569, 0.0158]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 9\n",
            "0.5935760140419006\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0047, 0.0061, 0.0033,  ..., 0.0330, 0.0037, 0.0050],\n",
            "        [0.0010, 0.0010, 0.0003,  ..., 0.0019, 0.0003, 0.0002],\n",
            "        [0.0014, 0.0029, 0.0026,  ..., 0.0014, 0.0064, 0.0024],\n",
            "        ...,\n",
            "        [0.0213, 0.0127, 0.0168,  ..., 0.0091, 0.0282, 0.0119],\n",
            "        [0.0085, 0.0201, 0.0630,  ..., 0.0076, 0.0143, 0.0299],\n",
            "        [0.0100, 0.0102, 0.0211,  ..., 0.0153, 0.0338, 0.0346]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 9\n",
            "0.6745176911354065\n",
            "one attention pattern developping during training\n",
            "tensor([[0.1885, 0.0942, 0.0089,  ..., 0.0042, 0.0003, 0.0042],\n",
            "        [0.0017, 0.0008, 0.0003,  ..., 0.0093, 0.0045, 0.0093],\n",
            "        [0.0200, 0.0046, 0.1106,  ..., 0.0055, 0.0324, 0.0055],\n",
            "        ...,\n",
            "        [0.1045, 0.0335, 0.0244,  ..., 0.0340, 0.0040, 0.0340],\n",
            "        [0.0027, 0.0004, 0.0050,  ..., 0.0010, 0.0005, 0.0010],\n",
            "        [0.1045, 0.0335, 0.0244,  ..., 0.0340, 0.0040, 0.0340]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "Epoch {epoch + 1} Loss 9\n",
            "0.5117081999778748\n",
            "one attention pattern developping during training\n",
            "tensor([[0.0938, 0.0867, 0.0655, 0.2159, 0.3045, 0.1233, 0.0363, 0.0741],\n",
            "        [0.0314, 0.0144, 0.2734, 0.0479, 0.3418, 0.0548, 0.0122, 0.2242],\n",
            "        [0.0668, 0.1670, 0.2270, 0.0434, 0.0944, 0.0868, 0.2042, 0.1103],\n",
            "        [0.0812, 0.2802, 0.1370, 0.0962, 0.0963, 0.1382, 0.0746, 0.0963],\n",
            "        [0.1750, 0.0316, 0.3844, 0.0573, 0.0876, 0.0387, 0.0519, 0.1734],\n",
            "        [0.1000, 0.2506, 0.1624, 0.0363, 0.0315, 0.0753, 0.2970, 0.0468],\n",
            "        [0.0875, 0.0400, 0.2929, 0.0438, 0.1931, 0.0552, 0.0224, 0.2651],\n",
            "        [0.1206, 0.1285, 0.0266, 0.0219, 0.3287, 0.0669, 0.2029, 0.1040]],\n",
            "       grad_fn=<SelectBackward0>)\n"
          ]
        }
      ]
    }
  ]
}